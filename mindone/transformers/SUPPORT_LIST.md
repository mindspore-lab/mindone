# Support List

## [v4.50.0-v4.57.1]

mindone.transformers has been upgraded from v0.45.0 to v4.57.1 in mindone v0.5.0, adding 78 new model interfaces, aligned with ğŸ¤— Transformers v4.57.1.

Support list for new added models.
- fp32/fp16/bf16: âœ… = passed fast UT for that precision (performed on pruned models)
- Inference: âœ… = verified with official weights.
- The usage and performance details for each model can be found in the respective PR. (e.g., `arcee` in [pr#1470](https://github.com/mindspore-lab/mindone/pull/1470)).


*  **Text models**

    | model | fp32 | fp16 | bf16 | inference | notes |
    | :--- | :--- | :--- | :--- | :--- | :--- |
    | apertus | âœ… | âœ… | âœ… | âœ… | [#1462](https://github.com/mindspore-lab/mindone/pull/1462)  |
    | arcee | âœ… | âœ… | âœ… | âœ… |  [#1470](https://github.com/mindspore-lab/mindone/pull/1470) |
    | bitnet | âœ… | âœ… | âœ… | âœ–ï¸ | quantized model inference is temporarily unsupported. [#1416](https://github.com/mindspore-lab/mindone/pull/1416) |
    | blt | âœ… | âœ… | âœ… | âœ… | [#1462](https://github.com/mindspore-lab/mindone/pull/1462)  |
    | deepseek_v2 | âœ… | âœ… | âœ… | âœ… | [#1477](https://github.com/mindspore-lab/mindone/pull/1477)  |
    | deepseek_v3 | âœ… | âœ… | âœ… | âœ–ï¸ | quantized model inference is temporarily unsupported. [#1415](https://github.com/mindspore-lab/mindone/pull/1415) |
    | doge | âœ… | âœ… | âœ… | âœ… | [#1392](https://github.com/mindspore-lab/mindone/pull/1392)   |
    | dots1 | âœ… | âœ… | âœ… | âœ… |  [#1469](https://github.com/mindspore-lab/mindone/pull/1469) |
    | ernie4_5 | âœ… | âœ… | âœ… | âœ… | [#1393](https://github.com/mindspore-lab/mindone/pull/1393)  |
    | ernie4_5_moe | âœ… | âœ… | âœ… | âœ… | 21b. requires zero3 parallel inference with 2p. [#1393](https://github.com/mindspore-lab/mindone/pull/1393) |
    | exaone4 | âœ… | âœ… | âœ… | âœ… | [#1396](https://github.com/mindspore-lab/mindone/pull/1396)  |
    | falcon_h1 | âœ… | âœ… | âœ… | âœ… | [#1465](https://github.com/mindspore-lab/mindone/pull/1465) |
    | flex_olmo | âœ… | âœ… | âœ… | âœ… | 49b. requires zero3 parallel inference with 4p. [#1442](https://github.com/mindspore-lab/mindone/pull/1442) |
    | glm4 | âœ… | âœ… | âœ… | âœ… | explore detailed usage in [example](../../examples/transformers/glm4v/README.md) |
    | glm4_moe | âœ… | âœ… | âœ… | âœ–ï¸ | 108b. not validated due to large size. [#1409](https://github.com/mindspore-lab/mindone/pull/1409) (also see [llama4](https://github.com/mindspore-lab/mindone/pull/1470) as a reference for moe+zero3 inference attempts). |
    | gpt_oss | âœ–ï¸ | âœ–ï¸ | âœ–ï¸ | âœ–ï¸ | quantized models are not yet supported. [#1209](https://github.com/mindspore-lab/mindone/pull/1209) attempts to provide a temporary workaround to bypass quantization. |
    | granitemoehybrid | âœ… | âœ… | âœ… | âœ… | [#1405](https://github.com/mindspore-lab/mindone/pull/1405)   |
    | hunyuan_v1_dense | âœ… | âœ… | âœ… | âœ… | [#1401](https://github.com/mindspore-lab/mindone/pull/1401)  |
    | hunyuan_v1_moe | âœ… | âœ… | âœ… | âœ–ï¸ | not validated. official models to be released. [#1401](https://github.com/mindspore-lab/mindone/pull/1401) |
    | lfm2 | âœ… | âœ… | âœ… | âœ… | [#1456](https://github.com/mindspore-lab/mindone/pull/1456)  |
    | longcat_flash | âœ… | âœ… | âœ… | âœ–ï¸ | 560b. not validated due to large size. [#1443](https://github.com/mindspore-lab/mindone/pull/1443) |
    | minimax | âœ… | âœ… | âœ… | âœ–ï¸ | 1TB. not validated due to the large size. [#1186](https://github.com/mindspore-lab/mindone/pull/1186) |
    | ministral | âœ… | âœ… | âœ… | âœ… | [#1462](https://github.com/mindspore-lab/mindone/pull/1462)  |
    | modernbert_decoder | âœ… | âœ… | âœ… | âœ… | [#1397](https://github.com/mindspore-lab/mindone/pull/1397)   |
    | olmo3 | âœ… | âœ… | âœ… | âœ… | [#1467](https://github.com/mindspore-lab/mindone/pull/1467)  |
    | qwen3 | âœ… | âœ… | âœ… | âœ… |  explore detailed usage in [example](../../examples/transformers/qwen3/README.md)  |
    | qwen3_moe | âœ… | âœ… | âœ… | âœ–ï¸ | not validated. [#1181](https://github.com/mindspore-lab/mindone/pull/1181) |
    | qwen3_next | âœ… | âœ… | âœ… | âœ… | 80b-A3b. requires zero3 parallel inference. [#1476](https://github.com/mindspore-lab/mindone/pull/1476) |
    | seed_oss | âœ… | âœ… | âœ… | âœ… | 36b. requires zero3 parallel inference with 4p. [#1441](https://github.com/mindspore-lab/mindone/pull/1441) |
    | t5gemma | âœ… | âœ… | âœ… | âœ… |  [#1420](https://github.com/mindspore-lab/mindone/pull/1420) |
    | vaultgemma | âœ… | âœ… | âœ… | âœ… | [#1450](https://github.com/mindspore-lab/mindone/pull/1450)  |
    | xlstm | âœ… | âœ… | âœ… | âœ… | [#1466](https://github.com/mindspore-lab/mindone/pull/1466)  |

* **Vision models**

    | model | fp32 | fp16 | bf16 | inference | notes |
    | :--- | :--- | :--- | :--- | :--- | :--- |
    | aimv2 | âœ… | âœ… | âœ… | âœ… |  [#1456](https://github.com/mindspore-lab/mindone/pull/1456) |
    | d_fine | âœ–ï¸ | âœ–ï¸ | âœ–ï¸ | âœ… | the order of results returned by `ms.mint.topk()` and `torch.topk()`may differ  when tensor elements are identical. temporarily skip the comparative tests. The model remains fully functional for users. |
    | dinov3_vit | âœ… | âœ… | âœ… | âœ… | a precision gap of ~1e-3 exists in image processing due to resize implementation differences; hence the HF processor is retained. [#1439](https://github.com/mindspore-lab/mindone/pull/1439) |
    | efficientloftr | âœ… | âœ… | âœ… | âœ–ï¸ | ğŸ¤— transformers model raise error in `model.generate`. see [issue 42581](https://github.com/huggingface/transformers/issues/42581). |
    | eomt | âœ… | âœ… | âœ… | âœ… |  [#1403](https://github.com/mindspore-lab/mindone/pull/1403)   |
    | hgnet_v2 | âœ… | âœ… | âœ–ï¸ | âœ… | `mindspore.nn.MaxPool2d` does not support bf16 inputs. |
    | lightglue | âœ–ï¸ | âœ–ï¸ | âœ–ï¸ | âœ–ï¸ | depends on the unsupported legacy model `SuperPoint`, see [#1348](https://github.com/mindspore-lab/mindone/pull/1348) for attempts. |
    | mlcd | âœ… | âœ… | âœ… | âœ… | [#1472](https://github.com/mindspore-lab/mindone/pull/1472)   |
    | sam2 | âœ… | âœ… | âœ… | âœ… | [#1434](https://github.com/mindspore-lab/mindone/pull/1434)  |
    | sam_hq | âœ… | âœ… | âœ… | âœ… | [#1457](https://github.com/mindspore-lab/mindone/pull/1457)  |

* **Multimodal models**

    | model | fp32 | fp16 | bf16 | inference | notes |
    | :--- | :--- | :--- | :--- | :--- | :--- |
    | cohere2_vision | âœ… | âœ… | âœ… | âœ… | 112b. requires zero3 parallel inference with 6p. [#1473](https://github.com/mindspore-lab/mindone/pull/1473) |
    | colqwen2 | âœ… | âœ… | âœ… | âœ… | [#1414](https://github.com/mindspore-lab/mindone/pull/1414)  |
    | deepseek_vl | âœ… | âœ… | âœ… | âœ… | [#1477](https://github.com/mindspore-lab/mindone/pull/1477)  |
    | deepseek_vl_hybrid | âœ… | âœ… | âœ… | âœ… | [#1477](https://github.com/mindspore-lab/mindone/pull/1477)  |
    | edgetam | âœ–ï¸ | âœ–ï¸ | âœ–ï¸ | âœ–ï¸ | use `MobileNetV5` from `timm`. temporarily unsupported. |
    | edgetam_video | âœ–ï¸ | âœ–ï¸ | âœ–ï¸ | âœ–ï¸ | use `repvit_mi` from `timm`. temporarily unsupported. |
    | evolla | âœ… | âœ… | âœ… | âœ… |  [#1440](https://github.com/mindspore-lab/mindone/pull/1440) |
    | florence2 | âœ… | âœ… | âœ… | âœ… | [#1453](https://github.com/mindspore-lab/mindone/pull/1453)  |
    | gemma3n | âœ–ï¸ | âœ–ï¸ | âœ–ï¸ | âœ–ï¸ | use `MobileNetV5` from `timm`. temporarily unsupported. |
    | glm4v | âœ… | âœ… | âœ… | âœ… | [#1109](https://github.com/mindspore-lab/mindone/pull/1109). explore detailed usage in [examples](../../examples/transformers/glm4v/README.md) |
    | glm4v_moe | âœ… | âœ… | âœ… | âœ–ï¸ | >100b. not validated due to the large size.[#1477](https://github.com/mindspore-lab/mindone/pull/1447) |
    | internvl | âœ… | âœ… | âœ… | âœ… | [#1463](https://github.com/mindspore-lab/mindone/pull/1463)  |
    | janus | âœ… | âœ… | âœ… | âœ… | [#1463](https://github.com/mindspore-lab/mindone/pull/1463)   |
    | kosmos2_5 | âœ… | âœ… | âœ… | âœ… | [#1456](https://github.com/mindspore-lab/mindone/pull/1456)  |
    | lfm2_vl | âœ… | âœ… | âœ… | âœ… | [#1456](https://github.com/mindspore-lab/mindone/pull/1456)   |
    | llama4 | âœ… | âœ… | âœ… | âœ… | specific moe layers are adapted to zero-3 sharding. [#1470](https://github.com/mindspore-lab/mindone/pull/1470). |
    | metaclip_2 | âœ… | âœ… | âœ… | âœ… |  [#1456](https://github.com/mindspore-lab/mindone/pull/1456)  |
    | mm_grounding_dino | âœ… | âœ… | âœ… | âœ… | use fp32 for model inference. [#1486](https://github.com/mindspore-lab/mindone/pull/1486) |
    | ovis2 | âœ… | âœ… | âœ… | âœ… | [#1454](https://github.com/mindspore-lab/mindone/pull/1454)  |
    | perception_lm | âœ–ï¸ | âœ–ï¸ | âœ–ï¸ | âœ–ï¸ | use `eva` from `timm` for vision model. temporarily unsupported. |
    | phi4_multimodal | âœ… | âœ… | âœ… | âœ–ï¸ | [microsoft/Phi-4-multimodal-instruct](https://huggingface.co/microsoft/Phi-4-multimodal-instruct) requires transformers v4.48.2. temporarily unsupported. [#1468](https://github.com/mindspore-lab/mindone/pull/1468) |
    | qwen2_5_omni | âœ… | âœ… | âœ… | âœ… | also support lora fine-tune, see [examples](https://github.com/mindspore-lab/mindone/tree/master/examples/transformers/qwen2_5_omni) |
    | qwen3_omni_moe | âœ… | âœ… | âœ… | âœ… | see [#1411](https://github.com/mindspore-lab/mindone/pull/1411) for detailed usage. |
    | qwen3_vl | âœ… | âœ… | âœ… | âœ… | refer to examples/transformers/qwen3_vl for detailed usage. [#1310](https://github.com/mindspore-lab/mindone/pull/1310) |
    | qwen3_vl_moe | âœ… | âœ… | âœ… | âœ… | specific moe layers are adapted to zero-3 sharding. refer to examples/transformers/qwen3_vl for detialed usage. [#1310](https://github.com/mindspore-lab/mindone/pull/1310) |
    | smollm3 | âœ… | âœ… | âœ… | âœ… |  [#1391](https://github.com/mindspore-lab/mindone/pull/1391)  |
    | voxtral | âœ… | âœ… | âœ… | âœ… |  [#1456](https://github.com/mindspore-lab/mindone/pull/1456)   |


* **Time series models**

    | model | fp32 | fp16 | bf16 | inference | notes |
    | :--- | :--- | :--- | :--- | :--- | :--- |
    | timesfm | âœ… | âœ–ï¸ | âœ… | âœ… | fp16 infernece has `nan` ouputs in torch or mindspore. [#1403](https://github.com/mindspore-lab/mindone/pull/1403)  |

* **Audio / Video models**

    | model | fp32 | fp16 | bf16 | inference | notes |
    | :--- | :--- | :--- | :--- | :--- | :--- |
    | csm | âœ… | âœ… | âœ… | âœ… | [#1399](https://github.com/mindspore-lab/mindone/pull/1399) |
    | dia | âœ… | âœ… | âœ… | âœ… | [#1404](https://github.com/mindspore-lab/mindone/pull/1404) |
    | granite_speech | âœ… | âœ… | âœ… | âœ… | [#1406](https://github.com/mindspore-lab/mindone/pull/1406) |
    | kyutai_speech_to_text | âœ… | âœ… | âœ… | âœ… | [#1407](https://github.com/mindspore-lab/mindone/pull/1407) |
    | parakeet | âœ… | âœ… | âœ… | âœ… | [#1451](https://github.com/mindspore-lab/mindone/pull/1451) |
    | xcodec | âœ… | âœ… | âœ… | âœ… | [#1452](https://github.com/mindspore-lab/mindone/pull/1452) |
    | sam2_video | âœ… | âœ… | âœ… | âœ… | [#1434](https://github.com/mindspore-lab/mindone/pull/1434) |
    | vjepa2 | âœ… | âœ… | âœ… | âœ… | [#1125](https://github.com/mindspore-lab/mindone/pull/1125) |



## [previous version]

In the previous version (aligned with ğŸ¤— Transformers v4.50.0), 240+ models were added. Some scripts have been upgraded to ensure that all existing model interfaces pass the fast unit tests. We do not guarantee that all model scripts are fully consistent with v4.57.1.

Fast UT validates pruned models that match the ğŸ¤— Transformers' precision. For realâ€‘weight inference, please switch back to mindone v0.4.0 for attempts. Community upgrades are very welcome.


| model | fp32 | fp16 | bf16 |
| --- | --- | --- | --- |
| albert | âœ… | âœ… | âœ–ï¸ |
| align | âœ… | âœ… | âœ… |
| altclip | âœ… | âœ… | âœ… |
| aria | âœ… | âœ… | âœ… |
| audio_spectrogram_transformer | âœ… | âœ… | âœ… |
| aya_vision | âœ… | âœ… | âœ… |
| bamba | âœ… | âœ… | âœ… |
| bark | âœ… | âœ… | âœ… |
| bart | âœ… | âœ… | âœ… |
| beit | âœ… | âœ… | âœ… |
| bert | âœ… | âœ… | âœ–ï¸ |
| bert_generation | âœ… | âœ… | âœ… |
| big_bird | âœ… | âœ… | âœ… |
| bigbird_pegasus | âœ… | âœ… | âœ… |
| biogpt | âœ… | âœ… | âœ… |
| bit | âœ… | âœ… | âœ–ï¸ |
| blenderbot | âœ… | âœ… | âœ… |
| blenderbot_small | âœ… | âœ… | âœ… |
| blip | âœ… | âœ–ï¸ | âœ… |
| blip_2 | âœ… | âœ–ï¸ | âœ… |
| bloom | âœ… | âœ… | âœ… |
| bridgetower | âœ… | âœ… | âœ… |
| bros | âœ… | âœ… | âœ… |
| camembert | âœ… | âœ… | âœ… |
| canine | âœ… | âœ… | âœ… |
| chameleon | âœ… | âœ… | âœ… |
| chinese_clip | âœ… | âœ… | âœ… |
| clip | âœ… | âœ… | âœ… |
| clipseg | âœ… | âœ… | âœ… |
| clvp | âœ… | âœ… | âœ… |
| codegen | âœ… | âœ… | âœ… |
| cohere | âœ… | âœ… | âœ… |
| cohere2 | âœ… | âœ… | âœ… |
| colpali | âœ… | âœ… | âœ… |
| convbert | âœ… | âœ… | âœ… |
| convnext | âœ… | âœ… | âœ… |
| convnextv2 | âœ… | âœ… | âœ… |
| ctrl | âœ… | âœ–ï¸ | âœ–ï¸ |
| cvt | âœ… | âœ… | âœ… |
| dac | âœ… | âœ… | âœ… |
| dbrx | âœ… | âœ… | âœ… |
| deberta | âœ… | âœ… | âœ–ï¸ |
| deberta_v2 | âœ… | âœ… | âœ–ï¸ |
| deit | âœ… | âœ… | âœ… |
| depth_anything | âœ… | âœ–ï¸ | âœ… |
| depth_pro | âœ… | âœ… | âœ… |
| diffllama | âœ… | âœ… | âœ… |
| dinov2 | âœ… | âœ… | âœ… |
| dinov2_with_registers | âœ… | âœ… | âœ… |
| distilbert | âœ… | âœ… | âœ… |
| dpr | âœ… | âœ… | âœ… |
| dpt | âœ… | âœ–ï¸ | âœ–ï¸ |
| electra | âœ… | âœ… | âœ… |
| emu3 | âœ… | âœ… | âœ… |
| encodec | âœ… | âœ–ï¸ | âœ–ï¸ |
| encoder_decoder | âœ… | âœ… | âœ… |
| esm | âœ… | âœ… | âœ… |
| falcon | âœ… | âœ… | âœ… |
| falcon_mamba | âœ… | âœ… | âœ… |
| fastspeech2_conformer | âœ… | âœ–ï¸ | âœ–ï¸ |
| flaubert | âœ… | âœ… | âœ–ï¸ |
| flava | âœ… | âœ… | âœ… |
| fnet | âœ… | âœ… | âœ… |
| focalnet | âœ… | âœ… | âœ… |
| fsmt | âœ… | âœ… | âœ… |
| funnel | âœ… | âœ–ï¸ | âœ–ï¸ |
| fuyu | âœ… | âœ… | âœ… |
| gemma | âœ… | âœ… | âœ… |
| gemma2 | âœ… | âœ… | âœ… |
| gemma3 | âœ… | âœ… | âœ… |
| git | âœ… | âœ… | âœ… |
| glpn | âœ… | âœ–ï¸ | âœ–ï¸ |
| got_ocr2 | âœ… | âœ… | âœ… |
| gpt2 | âœ… | âœ… | âœ… |
| gpt_bigcode | âœ… | âœ… | âœ… |
| gpt_neo | âœ… | âœ… | âœ… |
| gpt_neox | âœ… | âœ… | âœ… |
| gpt_neox_japanese | âœ… | âœ… | âœ… |
| gptj | âœ… | âœ… | âœ… |
| granite | âœ… | âœ… | âœ… |
| granitemoe | âœ… | âœ… | âœ… |
| granitemoeshared | âœ… | âœ… | âœ… |
| grounding_dino | âœ… | âœ… | âœ… |
| groupvit | âœ… | âœ… | âœ… |
| helium | âœ… | âœ… | âœ… |
| hiera | âœ… | âœ–ï¸ | âœ–ï¸ |
| hubert | âœ… | âœ… | âœ… |
| ibert | âœ… | âœ… | âœ… |
| idefics | âœ… | âœ… | âœ… |
| idefics2 | âœ… | âœ… | âœ… |
| idefics3 | âœ… | âœ… | âœ… |
| ijepa | âœ… | âœ… | âœ… |
| imagegpt | âœ… | âœ… | âœ… |
| instructblip | âœ… | âœ… | âœ… |
| instructblipvideo | âœ… | âœ… | âœ… |
| jamba | âœ… | âœ… | âœ… |
| jetmoe | âœ… | âœ… | âœ… |
| kosmos2 | âœ… | âœ… | âœ… |
| layoutlm | âœ… | âœ… | âœ… |
| layoutlmv3 | âœ… | âœ… | âœ… |
| led | âœ… | âœ… | âœ… |
| levit | âœ… | âœ–ï¸ | âœ… |
| lilt | âœ… | âœ… | âœ… |
| llama | âœ… | âœ… | âœ… |
| llava_next | âœ… | âœ… | âœ… |
| llava_next_video | âœ… | âœ… | âœ… |
| llava_onevision | âœ… | âœ… | âœ… |
| longformer | âœ… | âœ… | âœ… |
| longt5 | âœ… | âœ–ï¸ | âœ… |
| luke | âœ… | âœ… | âœ… |
| m2m_100 | âœ… | âœ… | âœ… |
| mamba | âœ… | âœ… | âœ… |
| mamba2 | âœ… | âœ… | âœ… |
| marian | âœ… | âœ… | âœ… |
| markuplm | âœ… | âœ… | âœ… |
| mask2former | âœ… | âœ… | âœ… |
| maskformer | âœ… | âœ… | âœ… |
| mbart | âœ… | âœ… | âœ… |
| mgp_str | âœ… | âœ… | âœ… |
| mimi | âœ… | âœ… | âœ–ï¸ |
| mistral | âœ… | âœ… | âœ… |
| mistral3 | âœ… | âœ–ï¸ | âœ–ï¸ |
| mixtral | âœ… | âœ… | âœ… |
| mllama | âœ… | âœ… | âœ… |
| mobilebert | âœ… | âœ… | âœ–ï¸ |
| mobilenet_v1 | âœ… | âœ… | âœ–ï¸ |
| mobilenet_v2 | âœ… | âœ… | âœ–ï¸ |
| mobilevit | âœ… | âœ–ï¸ | âœ… |
| mobilevitv2 | âœ… | âœ–ï¸ | âœ… |
| modernbert | âœ… | âœ… | âœ–ï¸ |
| moonshine | âœ… | âœ… | âœ… |
| moshi | âœ… | âœ… | âœ… |
| mpnet | âœ… | âœ… | âœ… |
| mpt | âœ… | âœ… | âœ… |
| mra | âœ… | âœ–ï¸ | âœ–ï¸ |
| mt5 | âœ… | âœ… | âœ… |
| musicgen | âœ… | âœ… | âœ… |
| musicgen_melody | âœ… | âœ… | âœ… |
| mvp | âœ… | âœ… | âœ… |
| nemotron | âœ… | âœ… | âœ… |
| nllb_moe | âœ… | âœ… | âœ… |
| nystromformer | âœ… | âœ… | âœ–ï¸ |
| olmo | âœ… | âœ… | âœ… |
| olmoe | âœ… | âœ… | âœ… |
| oneformer | âœ… | âœ… | âœ… |
| opt | âœ… | âœ… | âœ… |
| owlv2 | âœ… | âœ… | âœ… |
| owlvit | âœ… | âœ… | âœ… |
| paligemma | âœ… | âœ… | âœ… |
| pegasus | âœ… | âœ… | âœ… |
| pegasus_x | âœ… | âœ… | âœ… |
| perceiver | âœ… | âœ… | âœ… |
| persimmon | âœ… | âœ… | âœ… |
| phi | âœ… | âœ… | âœ… |
| phi3 | âœ… | âœ… | âœ… |
| phimoe | âœ… | âœ… | âœ… |
| pix2struct | âœ… | âœ–ï¸ | âœ… |
| pixtral | âœ… | âœ… | âœ… |
| plbart | âœ… | âœ… | âœ… |
| poolformer | âœ… | âœ… | âœ… |
| pop2piano | âœ… | âœ… | âœ… |
| prompt_depth_anything | âœ… | âœ… | âœ… |
| prophetnet | âœ… | âœ… | âœ… |
| pvt | âœ… | âœ… | âœ… |
| pvt_v2 | âœ… | âœ… | âœ… |
| qwen2 | âœ… | âœ… | âœ… |
| qwen2_5_vl | âœ… | âœ… | âœ… |
| qwen2_audio | âœ… | âœ… | âœ… |
| qwen2_moe | âœ… | âœ… | âœ… |
| qwen2_vl | âœ… | âœ… | âœ… |
| rag | âœ… | âœ… | âœ… |
| recurrent_gemma | âœ… | âœ… | âœ… |
| reformer | âœ… | âœ… | âœ… |
| regnet | âœ… | âœ… | âœ… |
| rembert | âœ… | âœ… | âœ–ï¸ |
| resnet | âœ… | âœ… | âœ… |
| roberta | âœ… | âœ… | âœ… |
| roberta_prelayernorm | âœ… | âœ… | âœ… |
| roc_bert | âœ… | âœ… | âœ… |
| roformer | âœ… | âœ… | âœ… |
| rwkv | âœ… | âœ… | âœ… |
| sam | âœ… | âœ… | âœ… |
| seamless_m4t | âœ… | âœ… | âœ… |
| seamless_m4t_v2 | âœ… | âœ… | âœ… |
| segformer | âœ… | âœ… | âœ… |
| seggpt | âœ… | âœ… | âœ… |
| sew | âœ… | âœ… | âœ–ï¸ |
| sew_d | âœ… | âœ… | âœ–ï¸ |
| shieldgemma2 | âœ… | âœ… | âœ… |
| siglip | âœ… | âœ… | âœ… |
| smolvlm | âœ… | âœ–ï¸ | âœ–ï¸ |
| speech_encoder_decoder | âœ… | âœ… | âœ… |
| speech_to_text | âœ… | âœ… | âœ… |
| splinter | âœ… | âœ… | âœ… |
| squeezebert | âœ… | âœ… | âœ… |
| stablelm | âœ… | âœ… | âœ… |
| starcoder2 | âœ… | âœ… | âœ… |
| swiftformer | âœ… | âœ… | âœ… |
| swin | âœ… | âœ… | âœ… |
| swin2sr | âœ… | âœ… | âœ… |
| swinv2 | âœ… | âœ… | âœ… |
| t5 | âœ… | âœ… | âœ… |
| tapas | âœ… | âœ… | âœ… |
| textnet | âœ… | âœ… | âœ… |
| timesformer | âœ… | âœ… | âœ… |
| trocr | âœ… | âœ… | âœ… |
| tvp | âœ… | âœ… | âœ… |
| udop | âœ… | âœ… | âœ… |
| unispeech | âœ… | âœ… | âœ… |
| unispeech_sat | âœ… | âœ… | âœ… |
| univnet | âœ… | âœ–ï¸ | âœ… |
| upernet | âœ… | âœ… | âœ… |
| video_llava | âœ… | âœ… | âœ… |
| videomae | âœ… | âœ… | âœ… |
| vilt | âœ… | âœ… | âœ… |
| vipllava | âœ… | âœ… | âœ… |
| vision_text_dual_encoder | âœ… | âœ… | âœ… |
| visual_bert | âœ… | âœ… | âœ… |
| vit | âœ… | âœ… | âœ… |
| vit_mae | âœ… | âœ… | âœ… |
| vit_msn | âœ… | âœ… | âœ… |
| vitdet | âœ… | âœ… | âœ… |
| vitmatte | âœ… | âœ… | âœ–ï¸ |
| vitpose | âœ… | âœ… | âœ–ï¸ |
| vitpose_backbone | âœ… | âœ… | âœ… |
| vivit | âœ… | âœ… | âœ… |
| wav2vec2 | âœ… | âœ… | âœ… |
| wav2vec2_bert | âœ… | âœ… | âœ… |
| wavlm | âœ… | âœ–ï¸ | âœ–ï¸ |
| x_clip | âœ… | âœ… | âœ… |
| xglm | âœ… | âœ–ï¸ | âœ–ï¸ |
| xlm | âœ… | âœ… | âœ… |
| xlm_roberta_xl | âœ… | âœ… | âœ… |
| xlnet | âœ… | âœ… | âœ… |
| xmod | âœ… | âœ… | âœ… |
| yolos | âœ… | âœ… | âœ… |
| yoso | âœ… | âœ… | âœ… |
| zamba | âœ… | âœ… | âœ… |
| zamba2 | âœ… | âœ… | âœ… |
| zoedepth | âœ… | âœ… | âœ–ï¸ |
