
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://mindspore-lab.github.io/mindone/0.2/diffusers/api/pipelines/latent_consistency_models/">
      
      
        <link rel="prev" href="../kandinsky3/">
      
      
        <link rel="next" href="../latent_diffusion/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.43">
    
    
      
        <title>Latent Consistency Models - MindOne - One for All</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.0253249f.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,300i,400,400i,700,700i%7CIBM+Plex+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Source Sans Pro";--md-code-font:"IBM Plex Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#latent-consistency-models" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="MindOne - One for All" class="md-header__button md-logo" aria-label="MindOne - One for All" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            MindOne - One for All
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Latent Consistency Models
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/mindspore-lab/mindone" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindone
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../" class="md-tabs__link">
          
  
  Diffusers

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../transformers/" class="md-tabs__link">
          
  
  Transformers

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../peft/" class="md-tabs__link">
          
  
  PEFT

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="MindOne - One for All" class="md-nav__button md-logo" aria-label="MindOne - One for All" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    MindOne - One for All
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mindspore-lab/mindone" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindone
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Diffusers
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Diffusers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Get started
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            Get started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ðŸ§¨ Diffusers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../quicktour/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quicktour
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../stable_diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Effective and efficient diffusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Installation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../limitations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Limitations
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/tutorial_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/write_own_pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Understanding pipelines, models and schedulers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/basic_training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Train a diffusion model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/using_peft_for_inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Load LoRAs for inference
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Load pipelines and adapters
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            Load pipelines and adapters
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/loading_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/loading/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Load pipelines
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/schedulers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Load schedulers and models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/other-formats/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Model files and layouts
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/loading_adapters/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Load adapters
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/push_to_hub/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Push files to the Hub
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_4" >
        
          
          <label class="md-nav__link" for="__nav_2_4" id="__nav_2_4_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Generative tasks
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_4">
            <span class="md-nav__icon md-icon"></span>
            Generative tasks
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/unconditional_image_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Unconditional image generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/conditional_image_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text-to-image
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/img2img/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image-to-image
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/inpaint/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inpainting
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/text-img2vid/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text or image-to-video
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/depth2img/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Depth-to-image
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_5" >
        
          
          <label class="md-nav__link" for="__nav_2_5" id="__nav_2_5_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Inference techniques
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_5">
            <span class="md-nav__icon md-icon"></span>
            Inference techniques
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/overview_techniques/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/merge_loras/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Merge LoRAs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/scheduler_features/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Scheduler features
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/callback/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Pipeline callbacks
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/reusing_seeds/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reproducible pipelines
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_6" >
        
          
          <label class="md-nav__link" for="__nav_2_6" id="__nav_2_6_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Specific pipeline examples
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_6">
            <span class="md-nav__icon md-icon"></span>
            Specific pipeline examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/sdxl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stable Diffusion XL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/sdxl_turbo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SDXL Turbo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/kandinsky/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kandinsky
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/ip_adapter/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IP-Adapter
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/controlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/t2i_adapter/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    T2I-Adapter
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/inference_with_lcm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Latent Consistency Model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/textual_inversion_inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Textual inversion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/shap-e/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Shap-E
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/diffedit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DiffEdit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/inference_with_tcd_lora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Trajectory Consistency Distillation-LoRA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/svd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stable Video Diffusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/marigold_usage/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Marigold Computer Vision
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_7" >
        
          
          <label class="md-nav__link" for="__nav_2_7" id="__nav_2_7_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Training
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_7">
            <span class="md-nav__icon md-icon"></span>
            Training
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/create_dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Create a dataset for training
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/adapt_a_model/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Adapt a model to a new task
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_7_4" >
        
          
          <label class="md-nav__link" for="__nav_2_7_4" id="__nav_2_7_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_7_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_7_4">
            <span class="md-nav__icon md-icon"></span>
            Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/unconditional_training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Unconditional image generation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/text2image/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text-to-image
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/sdxl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stable Diffusion XL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/controlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNet
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_7_5" >
        
          
          <label class="md-nav__link" for="__nav_2_7_5" id="__nav_2_7_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Methods
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_7_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_7_5">
            <span class="md-nav__icon md-icon"></span>
            Methods
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/text_inversion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Textual Inversion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/dreambooth/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DreamBooth
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../training/lora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LoRA
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_8" >
        
          
          <label class="md-nav__link" for="__nav_2_8" id="__nav_2_8_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Accelerate inference and reduce memory
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_8_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_8">
            <span class="md-nav__icon md-icon"></span>
            Accelerate inference and reduce memory
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../optimization/fp16/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Speed up inference
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../optimization/memory/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Reduce memory usage
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../optimization/xformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    xFormers
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_9" >
        
          
          <label class="md-nav__link" for="__nav_2_9" id="__nav_2_9_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Conceptual Guides
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_9_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_9">
            <span class="md-nav__icon md-icon"></span>
            Conceptual Guides
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../conceptual/philosophy/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Philosophy
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/controlling_generation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Controlled generation
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_10" checked>
        
          
          <label class="md-nav__link" for="__nav_2_10" id="__nav_2_10_label" tabindex="">
            
  
  <span class="md-ellipsis">
    API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_10_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_10">
            <span class="md-nav__icon md-icon"></span>
            API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_10_1" >
        
          
          <label class="md-nav__link" for="__nav_2_10_1" id="__nav_2_10_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Main Classes
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_10_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_10_1">
            <span class="md-nav__icon md-icon"></span>
            Main Classes
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../configuration/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Configuration
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../logging/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Logging
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../outputs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Outputs
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_10_2" >
        
          
          <label class="md-nav__link" for="__nav_2_10_2" id="__nav_2_10_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Loaders
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_10_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_10_2">
            <span class="md-nav__icon md-icon"></span>
            Loaders
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../loaders/ip_adapter/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IP-Adapter
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../loaders/lora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LoRA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../loaders/peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PEFT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../loaders/single_file/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single file
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../loaders/textual_inversion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Textual Inversion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../loaders/unet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UNet
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_10_3" >
        
          
          <label class="md-nav__link" for="__nav_2_10_3" id="__nav_2_10_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_10_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_10_3">
            <span class="md-nav__icon md-icon"></span>
            Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/unet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UNet1DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/unet2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UNet2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/unet2d-cond/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UNet2DConditionModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/unet3d-cond/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UNet3DConditionModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/unet-motion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UNetMotionModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/uvit2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UViT2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/vq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UVQModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/autoencoderkl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AutoEncoderKL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/asymmetricautoencoderkl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AsymmetricAutoEncoderKL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/autoencoder_tiny/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tiny AutoEncoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/consistency_decoder_vae/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ConsistencyDecoderVae
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/transformer2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformer2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/pixart_transformer2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PixArtTransformer2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/dit_transformer2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DiTTransformer2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/hunyuan_transformer2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HunyuanDiT2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/transformer_temporal/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TransformerTemporalModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/sd3_transformer2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SD3Transformer2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/prior_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PriorTransformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/controlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNetModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/controlnet_sd3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SD3ControlNetModel
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_10_4" checked>
        
          
          <label class="md-nav__link" for="__nav_2_10_4" id="__nav_2_10_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Pipelines
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_10_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_10_4">
            <span class="md-nav__icon md-icon"></span>
            Pipelines
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../animatediff/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AnimateDiff
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blip_diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BLIP-Diffusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../consistency_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Consistency Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../controlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../controlnet_sd3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNet with Stable Diffusion 3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../controlnetxs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNet-XS
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../controlnetxs_sdxl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNet-XS with Stable Diffusion XL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dance_diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dance Diffusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ddim/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DDIM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ddpm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DDPM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deepfloyd_if/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DeepFloyd IF
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../diffedit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DiffEdit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DiT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hunyuandit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hunyuan-DiT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../i2vgenxl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    I2VGen-XL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pix2pix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    InstructPix2Pix
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../kandinsky/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kandinsky 2.1
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../kandinsky_v22/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kandinsky 2.2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../kandinsky3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kandinsky 3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Latent Consistency Models
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Latent Consistency Models
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mindone.diffusers.LatentConsistencyModelPipeline" class="md-nav__link">
    <span class="md-ellipsis">
      LatentConsistencyModelPipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LatentConsistencyModelPipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.LatentConsistencyModelPipeline.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.LatentConsistencyModelPipeline.encode_prompt" class="md-nav__link">
    <span class="md-ellipsis">
      encode_prompt
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.LatentConsistencyModelPipeline.get_guidance_scale_embedding" class="md-nav__link">
    <span class="md-ellipsis">
      get_guidance_scale_embedding
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindone.diffusers.LatentConsistencyModelImg2ImgPipeline" class="md-nav__link">
    <span class="md-ellipsis">
      LatentConsistencyModelImg2ImgPipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LatentConsistencyModelImg2ImgPipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.LatentConsistencyModelImg2ImgPipeline.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.LatentConsistencyModelImg2ImgPipeline.encode_prompt" class="md-nav__link">
    <span class="md-ellipsis">
      encode_prompt
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.LatentConsistencyModelImg2ImgPipeline.get_guidance_scale_embedding" class="md-nav__link">
    <span class="md-ellipsis">
      get_guidance_scale_embedding
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindone.diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput" class="md-nav__link">
    <span class="md-ellipsis">
      StableDiffusionPipelineOutput
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../latent_diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Latent Diffusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../marigold/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Marigold
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pixart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PixArt-Î±
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pixart_sigma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PixArt-Î£
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../shap_e/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Shap-E
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_cascade/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stable Cascade
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_10_4_28" >
        
          
          <label class="md-nav__link" for="__nav_2_10_4_28" id="__nav_2_10_4_28_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Stable Diffusion
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_2_10_4_28_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_10_4_28">
            <span class="md-nav__icon md-icon"></span>
            Stable Diffusion
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/text2img/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Text-to-image
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/img2img/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image-to-image
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/svd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image-to-video
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/inpaint/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inpainting
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/depth2img/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Depth-to-image
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/image_variation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Image variation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/stable_diffusion_2/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stable Diffusion 2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/stable_diffusion_3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stable Diffusion 3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/stable_diffusion_xl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stable Diffusion XL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/sdxl_turbo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SDXL Turbo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/latent_upscale/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Latent upscaler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/upscale/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Super-resolution
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/adapter/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    T2I-Adapter
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_diffusion/gligen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    GLIGEN (Grounded Language-to-Image Generation)
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unclip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    unCLIP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../wuerstchen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Wuerstchen
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_10_5" >
        
          
          <label class="md-nav__link" for="__nav_2_10_5" id="__nav_2_10_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Schedulers
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_10_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_10_5">
            <span class="md-nav__icon md-icon"></span>
            Schedulers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/cm_stochastic_iterative/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    CMStochasticIterativeScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/consistency_decoder/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ConsistencyDecoderScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/ddim_inverse/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DDIMInverseScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/ddim/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DDIMScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/ddpm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DDPMScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/deis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DEISMultistepScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/multistep_dpm_solver_inverse/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DPMSolverMultistepInverse
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/multistep_dpm_solver/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DPMSolverMultistepScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/singlestep_dpm_solver/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DPMSolverSinglestepScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/edm_multistep_dpm_solver/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    EDMDPMSolverMultistepScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/edm_euler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    EDMEulerScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/euler_ancestral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    EulerAncestralDiscreteScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/euler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    EulerDiscreteScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/flow_match_euler_discrete/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    FlowMatchEulerDiscreteScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/heun/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HeunDiscreteScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/ipndm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IPNDMScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/dpm_discrete_ancestral/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    KDPM2AncestralDiscreteScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/dpm_discrete/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    KDPM2DiscreteScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/lcm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LCMScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/lms_discrete/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LMSDiscreteScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/pndm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PNDMScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/repaint/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    RePaintScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/score_sde_ve/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ScoreSdeVeScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/score_sde_vp/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ScoreSdeVpScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/tcd/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TCDScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/unipc/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UniPCMultistepScheduler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../schedulers/vq_diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VQDiffusionScheduler
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_10_6" >
        
          
          <label class="md-nav__link" for="__nav_2_10_6" id="__nav_2_10_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Internal Class
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_10_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_10_6">
            <span class="md-nav__icon md-icon"></span>
            Internal Class
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../internal_classes_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../attnprocessor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Attention Processor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../activations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom activation functions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../normalization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom Normalization Layer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilities/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Utilities
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../image_processor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VAE Image Processor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../video_processor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Video Processor
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Transformers
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Transformers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Get started
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            Get started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ðŸ¤— Transformers
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PEFT
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            PEFT
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Get started
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            Get started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ðŸ¤— PEFT
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mindone.diffusers.LatentConsistencyModelPipeline" class="md-nav__link">
    <span class="md-ellipsis">
      LatentConsistencyModelPipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LatentConsistencyModelPipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.LatentConsistencyModelPipeline.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.LatentConsistencyModelPipeline.encode_prompt" class="md-nav__link">
    <span class="md-ellipsis">
      encode_prompt
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.LatentConsistencyModelPipeline.get_guidance_scale_embedding" class="md-nav__link">
    <span class="md-ellipsis">
      get_guidance_scale_embedding
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindone.diffusers.LatentConsistencyModelImg2ImgPipeline" class="md-nav__link">
    <span class="md-ellipsis">
      LatentConsistencyModelImg2ImgPipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="LatentConsistencyModelImg2ImgPipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.LatentConsistencyModelImg2ImgPipeline.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.LatentConsistencyModelImg2ImgPipeline.encode_prompt" class="md-nav__link">
    <span class="md-ellipsis">
      encode_prompt
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.LatentConsistencyModelImg2ImgPipeline.get_guidance_scale_embedding" class="md-nav__link">
    <span class="md-ellipsis">
      get_guidance_scale_embedding
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindone.diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput" class="md-nav__link">
    <span class="md-ellipsis">
      StableDiffusionPipelineOutput
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/mindspore-lab/mindone/edit/master/docs/diffusers/api/pipelines/latent_consistency_models.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/mindspore-lab/mindone/raw/master/docs/diffusers/api/pipelines/latent_consistency_models.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<!--Copyright 2024 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

<h1 id="latent-consistency-models">Latent Consistency Models<a class="headerlink" href="#latent-consistency-models" title="Permanent link">&para;</a></h1>
<p>Latent Consistency Models (LCMs) were proposed in <a href="https://huggingface.co/papers/2310.04378">Latent Consistency Models: Synthesizing High-Resolution Images with Few-Step Inference</a> by Simian Luo, Yiqin Tan, Longbo Huang, Jian Li, and Hang Zhao.</p>
<p>The abstract of the paper is as follows:</p>
<p><em>Latent Diffusion models (LDMs) have achieved remarkable results in synthesizing high-resolution images. However, the iterative sampling process is computationally intensive and leads to slow generation. Inspired by Consistency Models (song et al.), we propose Latent Consistency Models (LCMs), enabling swift inference with minimal steps on any pre-trained LDMs, including Stable Diffusion (rombach et al). Viewing the guided reverse diffusion process as solving an augmented probability flow ODE (PF-ODE), LCMs are designed to directly predict the solution of such ODE in latent space, mitigating the need for numerous iterations and allowing rapid, high-fidelity sampling. Efficiently distilled from pre-trained classifier-free guided diffusion models, a high-quality 768 x 768 2~4-step LCM takes only 32 A100 GPU hours for training. Furthermore, we introduce Latent Consistency Fine-tuning (LCF), a novel method that is tailored for fine-tuning LCMs on customized image datasets. Evaluation on the LAION-5B-Aesthetics dataset demonstrates that LCMs achieve state-of-the-art text-to-image generation performance with few-step inference. Project Page: <a href="https://latent-consistency-models.github.io/">this https URL</a>.</em></p>
<p>A demo for the <a href="https://huggingface.co/SimianLuo/LCM_Dreamshaper_v7">SimianLuo/LCM_Dreamshaper_v7</a> checkpoint can be found <a href="https://huggingface.co/spaces/SimianLuo/Latent_Consistency_Model">here</a>.</p>
<p>The pipelines were contributed by <a href="https://luosiallen.github.io/">luosiallen</a>, <a href="https://github.com/nagolinc">nagolinc</a>, and <a href="https://github.com/dg845">dg845</a>.</p>


<div class="doc doc-object doc-class">



<h2 id="mindone.diffusers.LatentConsistencyModelPipeline" class="doc doc-heading">
            <code>mindone.diffusers.LatentConsistencyModelPipeline</code>


<a href="#mindone.diffusers.LatentConsistencyModelPipeline" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindone.diffusers.pipelines.pipeline_utils.DiffusionPipeline" href="../overview/#mindone.diffusers.DiffusionPipeline">DiffusionPipeline</a></code>, <code><span title="mindone.diffusers.pipelines.pipeline_utils.StableDiffusionMixin">StableDiffusionMixin</span></code>, <code><a class="autorefs autorefs-internal" title="mindone.diffusers.loaders.LoraLoaderMixin" href="../../loaders/lora/#mindone.diffusers.loaders.lora.LoraLoaderMixin">LoraLoaderMixin</a></code></p>


        <p>Pipeline for text-to-image generation using a latent consistency model.</p>
<p>This model inherits from [<code>DiffusionPipeline</code>]. Check the superclass documentation for the generic methods
implemented for all pipelines (downloading, saving, running on a particular device, etc.).</p>


<details class="the-pipeline-also-inherits-the-following-loading-methods" open>
  <summary>The pipeline also inherits the following loading methods</summary>
  <ul>
<li>[<code>~loaders.TextualInversionLoaderMixin.load_textual_inversion</code>] for loading textual inversion embeddings</li>
<li>[<code>~loaders.LoraLoaderMixin.load_lora_weights</code>] for loading LoRA weights</li>
<li>[<code>~loaders.LoraLoaderMixin.save_lora_weights</code>] for saving LoRA weights</li>
<li>[<code>~loaders.FromSingleFileMixin.from_single_file</code>] for loading <code>.ckpt</code> files</li>
<li>[<code>~loaders.IPAdapterMixin.load_ip_adapter</code>] for loading IP Adapters</li>
</ul>
</details>

<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>vae</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Variational Auto-Encoder (VAE) model to encode and decode images to and from latent representations.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`AutoencoderKL`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>text_encoder</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Frozen text-encoder (<a href="https://huggingface.co/openai/clip-vit-large-patch14">clip-vit-large-patch14</a>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`~transformers.CLIPTextModel`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>tokenizer</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A <code>CLIPTokenizer</code> to tokenize text.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`~transformers.CLIPTokenizer`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>unet</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A <code>UNet2DConditionModel</code> to denoise the encoded image latents.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`UNet2DConditionModel`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scheduler</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A scheduler to be used in combination with <code>unet</code> to denoise the encoded image latents. Currently only
supports [<code>LCMScheduler</code>].</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`SchedulerMixin`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>safety_checker</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Classification module that estimates whether generated images could be considered offensive or harmful.
Please refer to the <a href="https://huggingface.co/runwayml/stable-diffusion-v1-5">model card</a> for more details
about a model's potential harms.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`StableDiffusionSafetyChecker`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>feature_extractor</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A <code>CLIPImageProcessor</code> to extract features from generated images; used as inputs to the <code>safety_checker</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`~transformers.CLIPImageProcessor`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>requires_safety_checker</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether the pipeline requires a safety checker component.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>mindone/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LatentConsistencyModelPipeline</span><span class="p">(</span>
    <span class="n">DiffusionPipeline</span><span class="p">,</span>
    <span class="n">StableDiffusionMixin</span><span class="p">,</span>
    <span class="n">LoraLoaderMixin</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Pipeline for text-to-image generation using a latent consistency model.</span>

<span class="sd">    This model inherits from [`DiffusionPipeline`]. Check the superclass documentation for the generic methods</span>
<span class="sd">    implemented for all pipelines (downloading, saving, running on a particular device, etc.).</span>

<span class="sd">    The pipeline also inherits the following loading methods:</span>
<span class="sd">        - [`~loaders.TextualInversionLoaderMixin.load_textual_inversion`] for loading textual inversion embeddings</span>
<span class="sd">        - [`~loaders.LoraLoaderMixin.load_lora_weights`] for loading LoRA weights</span>
<span class="sd">        - [`~loaders.LoraLoaderMixin.save_lora_weights`] for saving LoRA weights</span>
<span class="sd">        - [`~loaders.FromSingleFileMixin.from_single_file`] for loading `.ckpt` files</span>
<span class="sd">        - [`~loaders.IPAdapterMixin.load_ip_adapter`] for loading IP Adapters</span>

<span class="sd">    Args:</span>
<span class="sd">        vae ([`AutoencoderKL`]):</span>
<span class="sd">            Variational Auto-Encoder (VAE) model to encode and decode images to and from latent representations.</span>
<span class="sd">        text_encoder ([`~transformers.CLIPTextModel`]):</span>
<span class="sd">            Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).</span>
<span class="sd">        tokenizer ([`~transformers.CLIPTokenizer`]):</span>
<span class="sd">            A `CLIPTokenizer` to tokenize text.</span>
<span class="sd">        unet ([`UNet2DConditionModel`]):</span>
<span class="sd">            A `UNet2DConditionModel` to denoise the encoded image latents.</span>
<span class="sd">        scheduler ([`SchedulerMixin`]):</span>
<span class="sd">            A scheduler to be used in combination with `unet` to denoise the encoded image latents. Currently only</span>
<span class="sd">            supports [`LCMScheduler`].</span>
<span class="sd">        safety_checker ([`StableDiffusionSafetyChecker`]):</span>
<span class="sd">            Classification module that estimates whether generated images could be considered offensive or harmful.</span>
<span class="sd">            Please refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5) for more details</span>
<span class="sd">            about a model&#39;s potential harms.</span>
<span class="sd">        feature_extractor ([`~transformers.CLIPImageProcessor`]):</span>
<span class="sd">            A `CLIPImageProcessor` to extract features from generated images; used as inputs to the `safety_checker`.</span>
<span class="sd">        requires_safety_checker (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether the pipeline requires a safety checker component.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">model_cpu_offload_seq</span> <span class="o">=</span> <span class="s2">&quot;text_encoder-&gt;unet-&gt;vae&quot;</span>
    <span class="n">_optional_components</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;safety_checker&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_extractor&quot;</span><span class="p">,</span> <span class="s2">&quot;image_encoder&quot;</span><span class="p">]</span>
    <span class="n">_exclude_from_cpu_offload</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;safety_checker&quot;</span><span class="p">]</span>
    <span class="n">_callback_tensor_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latents&quot;</span><span class="p">,</span> <span class="s2">&quot;denoised&quot;</span><span class="p">,</span> <span class="s2">&quot;prompt_embeds&quot;</span><span class="p">,</span> <span class="s2">&quot;w_embedding&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">vae</span><span class="p">:</span> <span class="n">AutoencoderKL</span><span class="p">,</span>
        <span class="n">text_encoder</span><span class="p">:</span> <span class="n">CLIPTextModel</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">CLIPTokenizer</span><span class="p">,</span>
        <span class="n">unet</span><span class="p">:</span> <span class="n">UNet2DConditionModel</span><span class="p">,</span>
        <span class="n">scheduler</span><span class="p">:</span> <span class="n">LCMScheduler</span><span class="p">,</span>
        <span class="n">safety_checker</span><span class="p">:</span> <span class="n">StableDiffusionSafetyChecker</span><span class="p">,</span>
        <span class="n">feature_extractor</span><span class="p">:</span> <span class="n">CLIPImageProcessor</span><span class="p">,</span>
        <span class="n">image_encoder</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CLIPVisionModelWithProjection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">requires_safety_checker</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">safety_checker</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">requires_safety_checker</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;You have disabled the safety checker for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="si">}</span><span class="s2"> by passing `safety_checker=None`. Ensure&quot;</span>
                <span class="s2">&quot; that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered&quot;</span>
                <span class="s2">&quot; results in services or applications open to the public. Both the diffusers team and Hugging Face&quot;</span>
                <span class="s2">&quot; strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling&quot;</span>
                <span class="s2">&quot; it only for use-cases that involve analyzing network behavior or auditing its results. For more&quot;</span>
                <span class="s2">&quot; information, please have a look at https://github.com/huggingface/diffusers/pull/254 .&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">safety_checker</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">feature_extractor</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Make sure to define a feature extractor when loading </span><span class="si">{self.__class__}</span><span class="s2"> if you want to use the safety&quot;</span>
                <span class="s2">&quot; checker. If you do not want to use the safety checker, you can pass `&#39;safety_checker=None&#39;` instead.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">register_modules</span><span class="p">(</span>
            <span class="n">vae</span><span class="o">=</span><span class="n">vae</span><span class="p">,</span>
            <span class="n">text_encoder</span><span class="o">=</span><span class="n">text_encoder</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">unet</span><span class="o">=</span><span class="n">unet</span><span class="p">,</span>
            <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
            <span class="n">safety_checker</span><span class="o">=</span><span class="n">safety_checker</span><span class="p">,</span>
            <span class="n">feature_extractor</span><span class="o">=</span><span class="n">feature_extractor</span><span class="p">,</span>
            <span class="n">image_encoder</span><span class="o">=</span><span class="n">image_encoder</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vae_scale_factor</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">block_out_channels</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span> <span class="o">=</span> <span class="n">VaeImageProcessor</span><span class="p">(</span><span class="n">vae_scale_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vae_scale_factor</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_to_config</span><span class="p">(</span><span class="n">requires_safety_checker</span><span class="o">=</span><span class="n">requires_safety_checker</span><span class="p">)</span>

    <span class="c1"># Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline.encode_prompt</span>
    <span class="k">def</span> <span class="nf">encode_prompt</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">,</span>
        <span class="n">num_images_per_prompt</span><span class="p">,</span>
        <span class="n">do_classifier_free_guidance</span><span class="p">,</span>
        <span class="n">negative_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">negative_prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">lora_scale</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">clip_skip</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Encodes the prompt into text encoder hidden states.</span>

<span class="sd">        Args:</span>
<span class="sd">            prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">                prompt to be encoded</span>
<span class="sd">            num_images_per_prompt (`int`):</span>
<span class="sd">                number of images that should be generated per prompt</span>
<span class="sd">            do_classifier_free_guidance (`bool`):</span>
<span class="sd">                whether to use classifier free guidance or not</span>
<span class="sd">            negative_prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">                The prompt or prompts not to guide the image generation. If not defined, one has to pass</span>
<span class="sd">                `negative_prompt_embeds` instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is</span>
<span class="sd">                less than `1`).</span>
<span class="sd">            prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">                Pre-generated text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not</span>
<span class="sd">                provided, text embeddings will be generated from `prompt` input argument.</span>
<span class="sd">            negative_prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">                Pre-generated negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt</span>
<span class="sd">                weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt` input</span>
<span class="sd">                argument.</span>
<span class="sd">            lora_scale (`float`, *optional*):</span>
<span class="sd">                A LoRA scale that will be applied to all LoRA layers of the text encoder if LoRA layers are loaded.</span>
<span class="sd">            clip_skip (`int`, *optional*):</span>
<span class="sd">                Number of layers to be skipped from CLIP while computing the prompt embeddings. A value of 1 means that</span>
<span class="sd">                the output of the pre-final layer will be used for computing the prompt embeddings.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># set lora scale so that monkey patched LoRA</span>
        <span class="c1"># function of text encoder can correctly access it</span>
        <span class="k">if</span> <span class="n">lora_scale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">LoraLoaderMixin</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_lora_scale</span> <span class="o">=</span> <span class="n">lora_scale</span>

            <span class="c1"># dynamically adjust the LoRA scale</span>
            <span class="n">scale_lora_layers</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">,</span> <span class="n">lora_scale</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">prompt_embeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># textual inversion: process multi-vector tokens if necessary</span>
            <span class="n">text_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
                <span class="n">prompt</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">,</span>
                <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">text_input_ids</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">text_inputs</span><span class="o">.</span><span class="n">input_ids</span><span class="p">)</span>
            <span class="n">untruncated_ids</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;longest&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">untruncated_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">text_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">ops</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">text_input_ids</span><span class="p">,</span> <span class="n">untruncated_ids</span><span class="p">):</span>
                <span class="n">removed_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">untruncated_ids</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;The following part of your input was truncated because CLIP can only handle sequences up to&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="si">}</span><span class="s2"> tokens: </span><span class="si">{</span><span class="n">removed_text</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;use_attention_mask&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_attention_mask</span><span class="p">:</span>
                <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">text_inputs</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">attention_mask</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="n">clip_skip</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span><span class="n">text_input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
                <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span>
                    <span class="n">text_input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>
                <span class="c1"># Access the `hidden_states` first, that contains a tuple of</span>
                <span class="c1"># all the hidden states from the encoder layers. Then index into</span>
                <span class="c1"># the tuple to access the hidden states from the desired layer.</span>
                <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="p">(</span><span class="n">clip_skip</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
                <span class="c1"># We also need to apply the final LayerNorm here to not mess with the</span>
                <span class="c1"># representations. The `last_hidden_states` that we typically use for</span>
                <span class="c1"># obtaining the final prompt representations passes through the LayerNorm</span>
                <span class="c1"># layer.</span>
                <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">text_model</span><span class="o">.</span><span class="n">final_layer_norm</span><span class="p">(</span><span class="n">prompt_embeds</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prompt_embeds_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">dtype</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prompt_embeds_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">dtype</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prompt_embeds_dtype</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span>

        <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">prompt_embeds_dtype</span><span class="p">)</span>

        <span class="n">bs_embed</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span>
        <span class="c1"># duplicate text embeddings for each generation per prompt, using mps friendly method</span>
        <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">tile</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs_embed</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># get unconditional embeddings for classifier free guidance</span>
        <span class="k">if</span> <span class="n">do_classifier_free_guidance</span> <span class="ow">and</span> <span class="n">negative_prompt_embeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">uncond_tokens</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">negative_prompt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span>
            <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;`negative_prompt` should be the same type to `prompt`, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">)</span><span class="si">}</span><span class="s2"> !=&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">negative_prompt</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;`negative_prompt`: </span><span class="si">{</span><span class="n">negative_prompt</span><span class="si">}</span><span class="s2"> has batch size </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">, but `prompt`:&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2"> has batch size </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">. Please make sure that passed `negative_prompt` matches&quot;</span>
                    <span class="s2">&quot; the batch size of `prompt`.&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="n">negative_prompt</span>

            <span class="c1"># textual inversion: process multi-vector tokens if necessary</span>
            <span class="n">max_length</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">uncond_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
                <span class="n">uncond_tokens</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
                <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;use_attention_mask&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_attention_mask</span><span class="p">:</span>
                <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">uncond_input</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">attention_mask</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span>
                <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">uncond_input</span><span class="o">.</span><span class="n">input_ids</span><span class="p">),</span>
                <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">do_classifier_free_guidance</span><span class="p">:</span>
            <span class="c1"># duplicate unconditional embeddings for each generation per prompt, using mps friendly method</span>
            <span class="n">seq_len</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">prompt_embeds_dtype</span><span class="p">)</span>

            <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">tile</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">LoraLoaderMixin</span><span class="p">):</span>
                <span class="c1"># Retrieve the original scale by scaling back the LoRA layers</span>
                <span class="n">unscale_lora_layers</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">,</span> <span class="n">lora_scale</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">prompt_embeds</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span>

    <span class="c1"># Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline.run_safety_checker</span>
    <span class="k">def</span> <span class="nf">run_safety_checker</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">safety_checker</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">has_nsfw_concept</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ops</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
                <span class="n">feature_extractor_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="s2">&quot;pil&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">feature_extractor_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="o">.</span><span class="n">numpy_to_pil</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
            <span class="n">safety_checker_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_extractor</span><span class="p">(</span><span class="n">feature_extractor_input</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">)</span>
            <span class="n">image</span><span class="p">,</span> <span class="n">has_nsfw_concept</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">safety_checker</span><span class="p">(</span>
                <span class="n">images</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">clip_input</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">safety_checker_input</span><span class="o">.</span><span class="n">pixel_values</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">has_nsfw_concept</span>

    <span class="c1"># Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline.prepare_latents</span>
    <span class="k">def</span> <span class="nf">prepare_latents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_channels_latents</span><span class="p">,</span> <span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">latents</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="n">shape</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">batch_size</span><span class="p">,</span>
            <span class="n">num_channels_latents</span><span class="p">,</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">height</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae_scale_factor</span><span class="p">,</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">width</span><span class="p">)</span> <span class="o">//</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae_scale_factor</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span> <span class="o">!=</span> <span class="n">batch_size</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;You have passed a list of generators of length </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span><span class="si">}</span><span class="s2">, but requested an effective batch&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; size of </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">. Make sure the batch size matches the length of the generators.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">latents</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">latents</span> <span class="o">=</span> <span class="n">randn_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span>

        <span class="c1"># scale the initial noise by the standard deviation required by the scheduler</span>
        <span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">init_noise_sigma</span>
        <span class="k">return</span> <span class="n">latents</span>

    <span class="k">def</span> <span class="nf">get_guidance_scale_embedding</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">:</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">ms</span><span class="o">.</span><span class="n">Type</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        See https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298</span>

<span class="sd">        Args:</span>
<span class="sd">            w (`ms.Tensor`):</span>
<span class="sd">                Generate embedding vectors with a specified guidance scale to subsequently enrich timestep embeddings.</span>
<span class="sd">            embedding_dim (`int`, *optional*, defaults to 512):</span>
<span class="sd">                Dimension of the embeddings to generate.</span>
<span class="sd">            dtype (`ms.dtype`, *optional*, defaults to `ms.float32`):</span>
<span class="sd">                Data type of the generated embeddings.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `ms.Tensor`: Embedding vectors with shape `(len(w), embedding_dim)`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="mf">1000.0</span>

        <span class="n">half_dim</span> <span class="o">=</span> <span class="n">embedding_dim</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">half_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">half_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="n">emb</span><span class="p">)</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">emb</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">ops</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">emb</span><span class="p">),</span> <span class="n">ops</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">emb</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">embedding_dim</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># zero pad</span>
            <span class="n">emb</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">assert</span> <span class="n">emb</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">embedding_dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">emb</span>

    <span class="c1"># Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline.prepare_extra_step_kwargs</span>
    <span class="k">def</span> <span class="nf">prepare_extra_step_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">eta</span><span class="p">):</span>
        <span class="c1"># prepare extra kwargs for the scheduler step, since not all schedulers have the same signature</span>
        <span class="c1"># eta (Î·) is only used with the DDIMScheduler, it will be ignored for other schedulers.</span>
        <span class="c1"># eta corresponds to Î· in DDIM paper: https://arxiv.org/abs/2010.02502</span>
        <span class="c1"># and should be between [0, 1]</span>

        <span class="n">accepts_eta</span> <span class="o">=</span> <span class="s2">&quot;eta&quot;</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">extra_step_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">accepts_eta</span><span class="p">:</span>
            <span class="n">extra_step_kwargs</span><span class="p">[</span><span class="s2">&quot;eta&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">eta</span>

        <span class="c1"># check if the scheduler accepts generator</span>
        <span class="n">accepts_generator</span> <span class="o">=</span> <span class="s2">&quot;generator&quot;</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">accepts_generator</span><span class="p">:</span>
            <span class="n">extra_step_kwargs</span><span class="p">[</span><span class="s2">&quot;generator&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">generator</span>
        <span class="k">return</span> <span class="n">extra_step_kwargs</span>

    <span class="c1"># Currently StableDiffusionPipeline.check_inputs with negative prompt stuff removed</span>
    <span class="k">def</span> <span class="nf">check_inputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">height</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">width</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">callback_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ip_adapter_image</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">ip_adapter_image_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">callback_on_step_end_tensor_inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">height</span> <span class="o">%</span> <span class="mi">8</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">width</span> <span class="o">%</span> <span class="mi">8</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`height` and `width` have to be divisible by 8 but are </span><span class="si">{</span><span class="n">height</span><span class="si">}</span><span class="s2"> and </span><span class="si">{</span><span class="n">width</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">callback_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">callback_steps</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">callback_steps</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`callback_steps` has to be a positive integer but is </span><span class="si">{</span><span class="n">callback_steps</span><span class="si">}</span><span class="s2"> of type&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">callback_steps</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">callback_on_step_end_tensor_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span>
            <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">callback_on_step_end_tensor_inputs</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`callback_on_step_end_tensor_inputs` has to be in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but found </span><span class="si">{</span><span class="p">[</span><span class="n">k</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">callback_on_step_end_tensor_inputs</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">prompt_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Cannot forward both `prompt`: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2"> and `prompt_embeds`: </span><span class="si">{</span><span class="n">prompt_embeds</span><span class="si">}</span><span class="s2">. Please make sure to&quot;</span>
                <span class="s2">&quot; only forward one of the two.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">prompt_embeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Provide either `prompt` or `prompt_embeds`. Cannot leave both `prompt` and `prompt_embeds` undefined.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`prompt` has to be of type `str` or `list` but is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">ip_adapter_image</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ip_adapter_image_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Provide either `ip_adapter_image` or `ip_adapter_image_embeds`. Cannot leave both `ip_adapter_image` and `ip_adapter_image_embeds` defined.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">ip_adapter_image_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ip_adapter_image_embeds</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;`ip_adapter_image_embeds` has to be of type `list` but is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">ip_adapter_image_embeds</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">ip_adapter_image_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ndim</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;`ip_adapter_image_embeds` has to be a list of 3D or 4D tensors but is </span><span class="si">{</span><span class="n">ip_adapter_image_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">D&quot;</span>
                <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">guidance_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_guidance_scale</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">cross_attention_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cross_attention_kwargs</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">clip_skip</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_clip_skip</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">do_classifier_free_guidance</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_timesteps</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_timesteps</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">height</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">width</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">original_inference_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">timesteps</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">guidance_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">8.5</span><span class="p">,</span>
        <span class="n">num_images_per_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">generator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">latents</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ip_adapter_image</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PipelineImageInput</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ip_adapter_image_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;pil&quot;</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">cross_attention_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">clip_skip</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">callback_on_step_end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latents&quot;</span><span class="p">],</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The call function to the pipeline for generation.</span>

<span class="sd">        Args:</span>
<span class="sd">            prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">                The prompt or prompts to guide image generation. If not defined, you need to pass `prompt_embeds`.</span>
<span class="sd">            height (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`):</span>
<span class="sd">                The height in pixels of the generated image.</span>
<span class="sd">            width (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`):</span>
<span class="sd">                The width in pixels of the generated image.</span>
<span class="sd">            num_inference_steps (`int`, *optional*, defaults to 50):</span>
<span class="sd">                The number of denoising steps. More denoising steps usually lead to a higher quality image at the</span>
<span class="sd">                expense of slower inference.</span>
<span class="sd">            original_inference_steps (`int`, *optional*):</span>
<span class="sd">                The original number of inference steps use to generate a linearly-spaced timestep schedule, from which</span>
<span class="sd">                we will draw `num_inference_steps` evenly spaced timesteps from as our final timestep schedule,</span>
<span class="sd">                following the Skipping-Step method in the paper (see Section 4.3). If not set this will default to the</span>
<span class="sd">                scheduler&#39;s `original_inference_steps` attribute.</span>
<span class="sd">            timesteps (`List[int]`, *optional*):</span>
<span class="sd">                Custom timesteps to use for the denoising process. If not defined, equal spaced `num_inference_steps`</span>
<span class="sd">                timesteps on the original LCM training/distillation timestep schedule are used. Must be in descending</span>
<span class="sd">                order.</span>
<span class="sd">            guidance_scale (`float`, *optional*, defaults to 7.5):</span>
<span class="sd">                A higher guidance scale value encourages the model to generate images closely linked to the text</span>
<span class="sd">                `prompt` at the expense of lower image quality. Guidance scale is enabled when `guidance_scale &gt; 1`.</span>
<span class="sd">                Note that the original latent consistency models paper uses a different CFG formulation where the</span>
<span class="sd">                guidance scales are decreased by 1 (so in the paper formulation CFG is enabled when `guidance_scale &gt;</span>
<span class="sd">                0`).</span>
<span class="sd">            num_images_per_prompt (`int`, *optional*, defaults to 1):</span>
<span class="sd">                The number of images to generate per prompt.</span>
<span class="sd">            generator (`np.random.Generator` or `List[np.random.Generator]`, *optional*):</span>
<span class="sd">                A [`np.random.Generator`](https://numpy.org/doc/stable/reference/random/generator.html) to make</span>
<span class="sd">                generation deterministic.</span>
<span class="sd">            latents (`ms.Tensor`, *optional*):</span>
<span class="sd">                Pre-generated noisy latents sampled from a Gaussian distribution, to be used as inputs for image</span>
<span class="sd">                generation. Can be used to tweak the same generation with different prompts. If not provided, a latents</span>
<span class="sd">                tensor is generated by sampling using the supplied random `generator`.</span>
<span class="sd">            prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">                Pre-generated text embeddings. Can be used to easily tweak text inputs (prompt weighting). If not</span>
<span class="sd">                provided, text embeddings are generated from the `prompt` input argument.</span>
<span class="sd">            ip_adapter_image: (`PipelineImageInput`, *optional*):</span>
<span class="sd">                Optional image input to work with IP Adapters.</span>
<span class="sd">            ip_adapter_image_embeds (`List[ms.Tensor]`, *optional*):</span>
<span class="sd">                Pre-generated image embeddings for IP-Adapter. It should be a list of length same as number of IP-adapters.</span>
<span class="sd">                Each element should be a tensor of shape `(batch_size, num_images, emb_dim)`. It should contain the negative image embedding</span>
<span class="sd">                if `do_classifier_free_guidance` is set to `True`.</span>
<span class="sd">                If not provided, embeddings are computed from the `ip_adapter_image` input argument.</span>
<span class="sd">            output_type (`str`, *optional*, defaults to `&quot;pil&quot;`):</span>
<span class="sd">                The output format of the generated image. Choose between `PIL.Image` or `np.array`.</span>
<span class="sd">            return_dict (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                Whether or not to return a [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] instead of a</span>
<span class="sd">                plain tuple.</span>
<span class="sd">            cross_attention_kwargs (`dict`, *optional*):</span>
<span class="sd">                A kwargs dictionary that if specified is passed along to the [`AttentionProcessor`] as defined in</span>
<span class="sd">                [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).</span>
<span class="sd">            clip_skip (`int`, *optional*):</span>
<span class="sd">                Number of layers to be skipped from CLIP while computing the prompt embeddings. A value of 1 means that</span>
<span class="sd">                the output of the pre-final layer will be used for computing the prompt embeddings.</span>
<span class="sd">            callback_on_step_end (`Callable`, *optional*):</span>
<span class="sd">                A function that calls at the end of each denoising steps during the inference. The function is called</span>
<span class="sd">                with the following arguments: `callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int,</span>
<span class="sd">                callback_kwargs: Dict)`. `callback_kwargs` will include a list of all tensors as specified by</span>
<span class="sd">                `callback_on_step_end_tensor_inputs`.</span>
<span class="sd">            callback_on_step_end_tensor_inputs (`List`, *optional*):</span>
<span class="sd">                The list of tensor inputs for the `callback_on_step_end` function. The tensors specified in the list</span>
<span class="sd">                will be passed as `callback_kwargs` argument. You will only be able to include variables listed in the</span>
<span class="sd">                `._callback_tensor_inputs` attribute of your pipeline class.</span>

<span class="sd">        Examples:</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] or `tuple`:</span>
<span class="sd">                If `return_dict` is `True`, [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] is returned,</span>
<span class="sd">                otherwise a `tuple` is returned where the first element is a list with the generated images and the</span>
<span class="sd">                second element is a list of `bool`s indicating whether the corresponding generated image contains</span>
<span class="sd">                &quot;not-safe-for-work&quot; (nsfw) content.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">callback</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;callback&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">callback_steps</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;callback_steps&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">deprecate</span><span class="p">(</span>
                <span class="s2">&quot;callback&quot;</span><span class="p">,</span>
                <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Passing `callback` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">callback_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">deprecate</span><span class="p">(</span>
                <span class="s2">&quot;callback_steps&quot;</span><span class="p">,</span>
                <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Passing `callback_steps` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># 0. Default height and width to unet</span>
        <span class="n">height</span> <span class="o">=</span> <span class="n">height</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">sample_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae_scale_factor</span>
        <span class="n">width</span> <span class="o">=</span> <span class="n">width</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">sample_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae_scale_factor</span>

        <span class="c1"># 1. Check inputs. Raise error if not correct</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_inputs</span><span class="p">(</span>
            <span class="n">prompt</span><span class="p">,</span>
            <span class="n">height</span><span class="p">,</span>
            <span class="n">width</span><span class="p">,</span>
            <span class="n">callback_steps</span><span class="p">,</span>
            <span class="n">prompt_embeds</span><span class="p">,</span>
            <span class="n">ip_adapter_image</span><span class="p">,</span>
            <span class="n">ip_adapter_image_embeds</span><span class="p">,</span>
            <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_guidance_scale</span> <span class="o">=</span> <span class="n">guidance_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_clip_skip</span> <span class="o">=</span> <span class="n">clip_skip</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cross_attention_kwargs</span> <span class="o">=</span> <span class="n">cross_attention_kwargs</span>

        <span class="c1"># 2. Define call parameters</span>
        <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># 3. Encode input prompt</span>
        <span class="n">lora_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attention_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attention_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="c1"># NOTE: when a LCM is distilled from an LDM via latent consistency distillation (Algorithm 1) with guided</span>
        <span class="c1"># distillation, the forward pass of the LCM learns to approximate sampling from the LDM using CFG with the</span>
        <span class="c1"># unconditional prompt &quot;&quot; (the empty string). Due to this, LCMs currently do not support negative prompts.</span>
        <span class="n">prompt_embeds</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_prompt</span><span class="p">(</span>
            <span class="n">prompt</span><span class="p">,</span>
            <span class="n">num_images_per_prompt</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">,</span>
            <span class="n">negative_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">prompt_embeds</span><span class="o">=</span><span class="n">prompt_embeds</span><span class="p">,</span>
            <span class="n">negative_prompt_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">lora_scale</span><span class="o">=</span><span class="n">lora_scale</span><span class="p">,</span>
            <span class="n">clip_skip</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clip_skip</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># 4. Prepare timesteps</span>
        <span class="n">timesteps</span><span class="p">,</span> <span class="n">num_inference_steps</span> <span class="o">=</span> <span class="n">retrieve_timesteps</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">,</span> <span class="n">num_inference_steps</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">original_inference_steps</span><span class="o">=</span><span class="n">original_inference_steps</span>
        <span class="p">)</span>

        <span class="c1"># 5. Prepare latent variable</span>
        <span class="n">num_channels_latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">in_channels</span>
        <span class="n">latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_latents</span><span class="p">(</span>
            <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span><span class="p">,</span>
            <span class="n">num_channels_latents</span><span class="p">,</span>
            <span class="n">height</span><span class="p">,</span>
            <span class="n">width</span><span class="p">,</span>
            <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
            <span class="n">generator</span><span class="p">,</span>
            <span class="n">latents</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">bs</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span>

        <span class="c1"># 6. Get Guidance Scale Embedding</span>
        <span class="c1"># NOTE: We use the Imagen CFG formulation that StableDiffusionPipeline uses rather than the original LCM paper</span>
        <span class="c1"># CFG formulation, so we need to subtract 1 from the input guidance_scale.</span>
        <span class="c1"># LCM CFG formulation:  cfg_noise = noise_cond + cfg_scale * (noise_cond - noise_uncond), (cfg_scale &gt; 0.0 using CFG)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">guidance_scale</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">bs</span><span class="p">)</span>
        <span class="n">w_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_guidance_scale_embedding</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">time_cond_proj_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">latents</span><span class="o">.</span><span class="n">dtype</span>
        <span class="p">)</span>

        <span class="c1"># 7. Prepare extra step kwargs. TODO: Logic should ideally just be moved out of the pipeline</span>
        <span class="n">extra_step_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_extra_step_kwargs</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># 7.1 Add image embeds for IP-Adapter</span>
        <span class="n">added_cond_kwargs</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># 8. LCM MultiStep Sampling Loop:</span>
        <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span> <span class="o">-</span> <span class="n">num_inference_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">order</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_timesteps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">progress_bar</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">num_inference_steps</span><span class="p">)</span> <span class="k">as</span> <span class="n">progress_bar</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">timesteps</span><span class="p">):</span>
                <span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

                <span class="c1"># model prediction (v-prediction, eps, x)</span>
                <span class="n">model_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="p">(</span>
                    <span class="n">latents</span><span class="p">,</span>
                    <span class="n">t</span><span class="p">,</span>
                    <span class="n">timestep_cond</span><span class="o">=</span><span class="n">w_embedding</span><span class="p">,</span>
                    <span class="n">encoder_hidden_states</span><span class="o">=</span><span class="n">prompt_embeds</span><span class="p">,</span>
                    <span class="n">cross_attention_kwargs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cross_attention_kwargs</span><span class="p">,</span>
                    <span class="n">added_cond_kwargs</span><span class="o">=</span><span class="n">added_cond_kwargs</span><span class="p">,</span>
                    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

                <span class="c1"># compute the previous noisy sample x_t -&gt; x_t-1</span>
                <span class="n">latents</span><span class="p">,</span> <span class="n">denoised</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">model_pred</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">latents</span><span class="p">,</span> <span class="o">**</span><span class="n">extra_step_kwargs</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">callback_on_step_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">callback_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
                    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span>
                        <span class="n">callback_kwargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">locals</span><span class="p">()[</span><span class="n">k</span><span class="p">]</span>
                    <span class="n">callback_outputs</span> <span class="o">=</span> <span class="n">callback_on_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">callback_kwargs</span><span class="p">)</span>

                    <span class="n">latents</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;latents&quot;</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span>
                    <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;prompt_embeds&quot;</span><span class="p">,</span> <span class="n">prompt_embeds</span><span class="p">)</span>
                    <span class="n">w_embedding</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;w_embedding&quot;</span><span class="p">,</span> <span class="n">w_embedding</span><span class="p">)</span>
                    <span class="n">denoised</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;denoised&quot;</span><span class="p">,</span> <span class="n">denoised</span><span class="p">)</span>

                <span class="c1"># call the callback, if provided</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">or</span> <span class="p">((</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">num_warmup_steps</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">order</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                    <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="n">callback_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">step_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">,</span> <span class="s2">&quot;order&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                        <span class="n">callback</span><span class="p">(</span><span class="n">step_idx</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span>

        <span class="n">denoised</span> <span class="o">=</span> <span class="n">denoised</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">output_type</span> <span class="o">==</span> <span class="s2">&quot;latent&quot;</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">denoised</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">scaling_factor</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">image</span><span class="p">,</span> <span class="n">has_nsfw_concept</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_safety_checker</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">denoised</span>
            <span class="n">has_nsfw_concept</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">has_nsfw_concept</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">do_denormalize</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span><span class="p">]</span> <span class="o">*</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">do_denormalize</span> <span class="o">=</span> <span class="p">[</span><span class="ow">not</span> <span class="n">has_nsfw</span> <span class="k">for</span> <span class="n">has_nsfw</span> <span class="ow">in</span> <span class="n">has_nsfw_concept</span><span class="p">]</span>

        <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">output_type</span><span class="p">,</span> <span class="n">do_denormalize</span><span class="o">=</span><span class="n">do_denormalize</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">has_nsfw_concept</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">StableDiffusionPipelineOutput</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">nsfw_content_detected</span><span class="o">=</span><span class="n">has_nsfw_concept</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindone.diffusers.LatentConsistencyModelPipeline.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindone</span><span class="o">.</span><span class="n">diffusers</span><span class="o">.</span><span class="n">LatentConsistencyModelPipeline</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">original_inference_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">guidance_scale</span><span class="o">=</span><span class="mf">8.5</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">latents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prompt_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ip_adapter_image</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ip_adapter_image_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="s1">&#39;pil&#39;</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cross_attention_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">clip_skip</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">callback_on_step_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">callback_on_step_end_tensor_inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;latents&#39;</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindone.diffusers.LatentConsistencyModelPipeline.__call__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The call function to the pipeline for generation.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The prompt or prompts to guide image generation. If not defined, you need to pass <code>prompt_embeds</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `List[str]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>height</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The height in pixels of the generated image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>width</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The width in pixels of the generated image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_inference_steps</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of denoising steps. More denoising steps usually lead to a higher quality image at the
expense of slower inference.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 50</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>4</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>original_inference_steps</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The original number of inference steps use to generate a linearly-spaced timestep schedule, from which
we will draw <code>num_inference_steps</code> evenly spaced timesteps from as our final timestep schedule,
following the Skipping-Step method in the paper (see Section 4.3). If not set this will default to the
scheduler's <code>original_inference_steps</code> attribute.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>timesteps</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Custom timesteps to use for the denoising process. If not defined, equal spaced <code>num_inference_steps</code>
timesteps on the original LCM training/distillation timestep schedule are used. Must be in descending
order.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[int]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>guidance_scale</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A higher guidance scale value encourages the model to generate images closely linked to the text
<code>prompt</code> at the expense of lower image quality. Guidance scale is enabled when <code>guidance_scale &gt; 1</code>.
Note that the original latent consistency models paper uses a different CFG formulation where the
guidance scales are decreased by 1 (so in the paper formulation CFG is enabled when <code>guidance_scale &gt;
0</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 7.5</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>8.5</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_images_per_prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of images to generate per prompt.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 1</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>generator</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A <a href="https://numpy.org/doc/stable/reference/random/generator.html"><code>np.random.Generator</code></a> to make
generation deterministic.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`np.random.Generator` or `List[np.random.Generator]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>latents</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pre-generated noisy latents sampled from a Gaussian distribution, to be used as inputs for image
generation. Can be used to tweak the same generation with different prompts. If not provided, a latents
tensor is generated by sampling using the supplied random <code>generator</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prompt_embeds</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pre-generated text embeddings. Can be used to easily tweak text inputs (prompt weighting). If not
provided, text embeddings are generated from the <code>prompt</code> input argument.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>ip_adapter_image</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>(<code>PipelineImageInput</code>, <em>optional</em>):
Optional image input to work with IP Adapters.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="mindone.diffusers.image_processor.PipelineImageInput">PipelineImageInput</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>ip_adapter_image_embeds</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pre-generated image embeddings for IP-Adapter. It should be a list of length same as number of IP-adapters.
Each element should be a tensor of shape <code>(batch_size, num_images, emb_dim)</code>. It should contain the negative image embedding
if <code>do_classifier_free_guidance</code> is set to <code>True</code>.
If not provided, embeddings are computed from the <code>ip_adapter_image</code> input argument.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[ms.Tensor]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>output_type</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The output format of the generated image. Choose between <code>PIL.Image</code> or <code>np.array</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;pil&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;pil&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>return_dict</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to return a [<code>~pipelines.stable_diffusion.StableDiffusionPipelineOutput</code>] instead of a
plain tuple.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>cross_attention_kwargs</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A kwargs dictionary that if specified is passed along to the [<code>AttentionProcessor</code>] as defined in
<a href="https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py"><code>self.processor</code></a>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`dict`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>clip_skip</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of layers to be skipped from CLIP while computing the prompt embeddings. A value of 1 means that
the output of the pre-final layer will be used for computing the prompt embeddings.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>callback_on_step_end</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A function that calls at the end of each denoising steps during the inference. The function is called
with the following arguments: <code>callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int,
callback_kwargs: Dict)</code>. <code>callback_kwargs</code> will include a list of all tensors as specified by
<code>callback_on_step_end_tensor_inputs</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Callable`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>callback_on_step_end_tensor_inputs</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The list of tensor inputs for the <code>callback_on_step_end</code> function. The tensors specified in the list
will be passed as <code>callback_kwargs</code> argument. You will only be able to include variables listed in the
<code>._callback_tensor_inputs</code> attribute of your pipeline class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>[&#39;latents&#39;]</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>[<code>~pipelines.stable_diffusion.StableDiffusionPipelineOutput</code>] or <code>tuple</code>:
If <code>return_dict</code> is <code>True</code>, [<code>~pipelines.stable_diffusion.StableDiffusionPipelineOutput</code>] is returned,
otherwise a <code>tuple</code> is returned where the first element is a list with the generated images and the
second element is a list of <code>bool</code>s indicating whether the corresponding generated image contains
"not-safe-for-work" (nsfw) content.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindone/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">height</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">width</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_inference_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">original_inference_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">timesteps</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">guidance_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">8.5</span><span class="p">,</span>
    <span class="n">num_images_per_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">latents</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ip_adapter_image</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PipelineImageInput</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ip_adapter_image_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;pil&quot;</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">cross_attention_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">clip_skip</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">callback_on_step_end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latents&quot;</span><span class="p">],</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The call function to the pipeline for generation.</span>

<span class="sd">    Args:</span>
<span class="sd">        prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">            The prompt or prompts to guide image generation. If not defined, you need to pass `prompt_embeds`.</span>
<span class="sd">        height (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`):</span>
<span class="sd">            The height in pixels of the generated image.</span>
<span class="sd">        width (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`):</span>
<span class="sd">            The width in pixels of the generated image.</span>
<span class="sd">        num_inference_steps (`int`, *optional*, defaults to 50):</span>
<span class="sd">            The number of denoising steps. More denoising steps usually lead to a higher quality image at the</span>
<span class="sd">            expense of slower inference.</span>
<span class="sd">        original_inference_steps (`int`, *optional*):</span>
<span class="sd">            The original number of inference steps use to generate a linearly-spaced timestep schedule, from which</span>
<span class="sd">            we will draw `num_inference_steps` evenly spaced timesteps from as our final timestep schedule,</span>
<span class="sd">            following the Skipping-Step method in the paper (see Section 4.3). If not set this will default to the</span>
<span class="sd">            scheduler&#39;s `original_inference_steps` attribute.</span>
<span class="sd">        timesteps (`List[int]`, *optional*):</span>
<span class="sd">            Custom timesteps to use for the denoising process. If not defined, equal spaced `num_inference_steps`</span>
<span class="sd">            timesteps on the original LCM training/distillation timestep schedule are used. Must be in descending</span>
<span class="sd">            order.</span>
<span class="sd">        guidance_scale (`float`, *optional*, defaults to 7.5):</span>
<span class="sd">            A higher guidance scale value encourages the model to generate images closely linked to the text</span>
<span class="sd">            `prompt` at the expense of lower image quality. Guidance scale is enabled when `guidance_scale &gt; 1`.</span>
<span class="sd">            Note that the original latent consistency models paper uses a different CFG formulation where the</span>
<span class="sd">            guidance scales are decreased by 1 (so in the paper formulation CFG is enabled when `guidance_scale &gt;</span>
<span class="sd">            0`).</span>
<span class="sd">        num_images_per_prompt (`int`, *optional*, defaults to 1):</span>
<span class="sd">            The number of images to generate per prompt.</span>
<span class="sd">        generator (`np.random.Generator` or `List[np.random.Generator]`, *optional*):</span>
<span class="sd">            A [`np.random.Generator`](https://numpy.org/doc/stable/reference/random/generator.html) to make</span>
<span class="sd">            generation deterministic.</span>
<span class="sd">        latents (`ms.Tensor`, *optional*):</span>
<span class="sd">            Pre-generated noisy latents sampled from a Gaussian distribution, to be used as inputs for image</span>
<span class="sd">            generation. Can be used to tweak the same generation with different prompts. If not provided, a latents</span>
<span class="sd">            tensor is generated by sampling using the supplied random `generator`.</span>
<span class="sd">        prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">            Pre-generated text embeddings. Can be used to easily tweak text inputs (prompt weighting). If not</span>
<span class="sd">            provided, text embeddings are generated from the `prompt` input argument.</span>
<span class="sd">        ip_adapter_image: (`PipelineImageInput`, *optional*):</span>
<span class="sd">            Optional image input to work with IP Adapters.</span>
<span class="sd">        ip_adapter_image_embeds (`List[ms.Tensor]`, *optional*):</span>
<span class="sd">            Pre-generated image embeddings for IP-Adapter. It should be a list of length same as number of IP-adapters.</span>
<span class="sd">            Each element should be a tensor of shape `(batch_size, num_images, emb_dim)`. It should contain the negative image embedding</span>
<span class="sd">            if `do_classifier_free_guidance` is set to `True`.</span>
<span class="sd">            If not provided, embeddings are computed from the `ip_adapter_image` input argument.</span>
<span class="sd">        output_type (`str`, *optional*, defaults to `&quot;pil&quot;`):</span>
<span class="sd">            The output format of the generated image. Choose between `PIL.Image` or `np.array`.</span>
<span class="sd">        return_dict (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether or not to return a [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] instead of a</span>
<span class="sd">            plain tuple.</span>
<span class="sd">        cross_attention_kwargs (`dict`, *optional*):</span>
<span class="sd">            A kwargs dictionary that if specified is passed along to the [`AttentionProcessor`] as defined in</span>
<span class="sd">            [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).</span>
<span class="sd">        clip_skip (`int`, *optional*):</span>
<span class="sd">            Number of layers to be skipped from CLIP while computing the prompt embeddings. A value of 1 means that</span>
<span class="sd">            the output of the pre-final layer will be used for computing the prompt embeddings.</span>
<span class="sd">        callback_on_step_end (`Callable`, *optional*):</span>
<span class="sd">            A function that calls at the end of each denoising steps during the inference. The function is called</span>
<span class="sd">            with the following arguments: `callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int,</span>
<span class="sd">            callback_kwargs: Dict)`. `callback_kwargs` will include a list of all tensors as specified by</span>
<span class="sd">            `callback_on_step_end_tensor_inputs`.</span>
<span class="sd">        callback_on_step_end_tensor_inputs (`List`, *optional*):</span>
<span class="sd">            The list of tensor inputs for the `callback_on_step_end` function. The tensors specified in the list</span>
<span class="sd">            will be passed as `callback_kwargs` argument. You will only be able to include variables listed in the</span>
<span class="sd">            `._callback_tensor_inputs` attribute of your pipeline class.</span>

<span class="sd">    Examples:</span>

<span class="sd">    Returns:</span>
<span class="sd">        [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] or `tuple`:</span>
<span class="sd">            If `return_dict` is `True`, [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] is returned,</span>
<span class="sd">            otherwise a `tuple` is returned where the first element is a list with the generated images and the</span>
<span class="sd">            second element is a list of `bool`s indicating whether the corresponding generated image contains</span>
<span class="sd">            &quot;not-safe-for-work&quot; (nsfw) content.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">callback</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;callback&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">callback_steps</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;callback_steps&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">deprecate</span><span class="p">(</span>
            <span class="s2">&quot;callback&quot;</span><span class="p">,</span>
            <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Passing `callback` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`&quot;</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">callback_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">deprecate</span><span class="p">(</span>
            <span class="s2">&quot;callback_steps&quot;</span><span class="p">,</span>
            <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Passing `callback_steps` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># 0. Default height and width to unet</span>
    <span class="n">height</span> <span class="o">=</span> <span class="n">height</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">sample_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae_scale_factor</span>
    <span class="n">width</span> <span class="o">=</span> <span class="n">width</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">sample_size</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae_scale_factor</span>

    <span class="c1"># 1. Check inputs. Raise error if not correct</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">check_inputs</span><span class="p">(</span>
        <span class="n">prompt</span><span class="p">,</span>
        <span class="n">height</span><span class="p">,</span>
        <span class="n">width</span><span class="p">,</span>
        <span class="n">callback_steps</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="p">,</span>
        <span class="n">ip_adapter_image</span><span class="p">,</span>
        <span class="n">ip_adapter_image_embeds</span><span class="p">,</span>
        <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_guidance_scale</span> <span class="o">=</span> <span class="n">guidance_scale</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_clip_skip</span> <span class="o">=</span> <span class="n">clip_skip</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_cross_attention_kwargs</span> <span class="o">=</span> <span class="n">cross_attention_kwargs</span>

    <span class="c1"># 2. Define call parameters</span>
    <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># 3. Encode input prompt</span>
    <span class="n">lora_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attention_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attention_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="c1"># NOTE: when a LCM is distilled from an LDM via latent consistency distillation (Algorithm 1) with guided</span>
    <span class="c1"># distillation, the forward pass of the LCM learns to approximate sampling from the LDM using CFG with the</span>
    <span class="c1"># unconditional prompt &quot;&quot; (the empty string). Due to this, LCMs currently do not support negative prompts.</span>
    <span class="n">prompt_embeds</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_prompt</span><span class="p">(</span>
        <span class="n">prompt</span><span class="p">,</span>
        <span class="n">num_images_per_prompt</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">,</span>
        <span class="n">negative_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="o">=</span><span class="n">prompt_embeds</span><span class="p">,</span>
        <span class="n">negative_prompt_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">lora_scale</span><span class="o">=</span><span class="n">lora_scale</span><span class="p">,</span>
        <span class="n">clip_skip</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clip_skip</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># 4. Prepare timesteps</span>
    <span class="n">timesteps</span><span class="p">,</span> <span class="n">num_inference_steps</span> <span class="o">=</span> <span class="n">retrieve_timesteps</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">,</span> <span class="n">num_inference_steps</span><span class="p">,</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">original_inference_steps</span><span class="o">=</span><span class="n">original_inference_steps</span>
    <span class="p">)</span>

    <span class="c1"># 5. Prepare latent variable</span>
    <span class="n">num_channels_latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">in_channels</span>
    <span class="n">latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_latents</span><span class="p">(</span>
        <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span><span class="p">,</span>
        <span class="n">num_channels_latents</span><span class="p">,</span>
        <span class="n">height</span><span class="p">,</span>
        <span class="n">width</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span>
        <span class="n">generator</span><span class="p">,</span>
        <span class="n">latents</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">bs</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span>

    <span class="c1"># 6. Get Guidance Scale Embedding</span>
    <span class="c1"># NOTE: We use the Imagen CFG formulation that StableDiffusionPipeline uses rather than the original LCM paper</span>
    <span class="c1"># CFG formulation, so we need to subtract 1 from the input guidance_scale.</span>
    <span class="c1"># LCM CFG formulation:  cfg_noise = noise_cond + cfg_scale * (noise_cond - noise_uncond), (cfg_scale &gt; 0.0 using CFG)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">guidance_scale</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">bs</span><span class="p">)</span>
    <span class="n">w_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_guidance_scale_embedding</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">time_cond_proj_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">latents</span><span class="o">.</span><span class="n">dtype</span>
    <span class="p">)</span>

    <span class="c1"># 7. Prepare extra step kwargs. TODO: Logic should ideally just be moved out of the pipeline</span>
    <span class="n">extra_step_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_extra_step_kwargs</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="c1"># 7.1 Add image embeds for IP-Adapter</span>
    <span class="n">added_cond_kwargs</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># 8. LCM MultiStep Sampling Loop:</span>
    <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span> <span class="o">-</span> <span class="n">num_inference_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">order</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_num_timesteps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">progress_bar</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">num_inference_steps</span><span class="p">)</span> <span class="k">as</span> <span class="n">progress_bar</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">timesteps</span><span class="p">):</span>
            <span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

            <span class="c1"># model prediction (v-prediction, eps, x)</span>
            <span class="n">model_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="p">(</span>
                <span class="n">latents</span><span class="p">,</span>
                <span class="n">t</span><span class="p">,</span>
                <span class="n">timestep_cond</span><span class="o">=</span><span class="n">w_embedding</span><span class="p">,</span>
                <span class="n">encoder_hidden_states</span><span class="o">=</span><span class="n">prompt_embeds</span><span class="p">,</span>
                <span class="n">cross_attention_kwargs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cross_attention_kwargs</span><span class="p">,</span>
                <span class="n">added_cond_kwargs</span><span class="o">=</span><span class="n">added_cond_kwargs</span><span class="p">,</span>
                <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c1"># compute the previous noisy sample x_t -&gt; x_t-1</span>
            <span class="n">latents</span><span class="p">,</span> <span class="n">denoised</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">model_pred</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">latents</span><span class="p">,</span> <span class="o">**</span><span class="n">extra_step_kwargs</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">callback_on_step_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">callback_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span>
                    <span class="n">callback_kwargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">locals</span><span class="p">()[</span><span class="n">k</span><span class="p">]</span>
                <span class="n">callback_outputs</span> <span class="o">=</span> <span class="n">callback_on_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">callback_kwargs</span><span class="p">)</span>

                <span class="n">latents</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;latents&quot;</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span>
                <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;prompt_embeds&quot;</span><span class="p">,</span> <span class="n">prompt_embeds</span><span class="p">)</span>
                <span class="n">w_embedding</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;w_embedding&quot;</span><span class="p">,</span> <span class="n">w_embedding</span><span class="p">)</span>
                <span class="n">denoised</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;denoised&quot;</span><span class="p">,</span> <span class="n">denoised</span><span class="p">)</span>

            <span class="c1"># call the callback, if provided</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">or</span> <span class="p">((</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">num_warmup_steps</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">order</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="n">callback_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">step_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">,</span> <span class="s2">&quot;order&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="n">callback</span><span class="p">(</span><span class="n">step_idx</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span>

    <span class="n">denoised</span> <span class="o">=</span> <span class="n">denoised</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">output_type</span> <span class="o">==</span> <span class="s2">&quot;latent&quot;</span><span class="p">:</span>
        <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">denoised</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">scaling_factor</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">image</span><span class="p">,</span> <span class="n">has_nsfw_concept</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_safety_checker</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">denoised</span>
        <span class="n">has_nsfw_concept</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">has_nsfw_concept</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">do_denormalize</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span><span class="p">]</span> <span class="o">*</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">do_denormalize</span> <span class="o">=</span> <span class="p">[</span><span class="ow">not</span> <span class="n">has_nsfw</span> <span class="k">for</span> <span class="n">has_nsfw</span> <span class="ow">in</span> <span class="n">has_nsfw_concept</span><span class="p">]</span>

    <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">output_type</span><span class="p">,</span> <span class="n">do_denormalize</span><span class="o">=</span><span class="n">do_denormalize</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">has_nsfw_concept</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">StableDiffusionPipelineOutput</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">nsfw_content_detected</span><span class="o">=</span><span class="n">has_nsfw_concept</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindone.diffusers.LatentConsistencyModelPipeline.encode_prompt" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindone</span><span class="o">.</span><span class="n">diffusers</span><span class="o">.</span><span class="n">LatentConsistencyModelPipeline</span><span class="o">.</span><span class="n">encode_prompt</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="n">do_classifier_free_guidance</span><span class="p">,</span> <span class="n">negative_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prompt_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lora_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">clip_skip</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindone.diffusers.LatentConsistencyModelPipeline.encode_prompt" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Encodes the prompt into text encoder hidden states.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>prompt to be encoded</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `List[str]`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_images_per_prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>number of images that should be generated per prompt</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>do_classifier_free_guidance</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>whether to use classifier free guidance or not</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>negative_prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The prompt or prompts not to guide the image generation. If not defined, one has to pass
<code>negative_prompt_embeds</code> instead. Ignored when not using guidance (i.e., ignored if <code>guidance_scale</code> is
less than <code>1</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `List[str]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prompt_embeds</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pre-generated text embeddings. Can be used to easily tweak text inputs, <em>e.g.</em> prompt weighting. If not
provided, text embeddings will be generated from <code>prompt</code> input argument.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>negative_prompt_embeds</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pre-generated negative text embeddings. Can be used to easily tweak text inputs, <em>e.g.</em> prompt
weighting. If not provided, negative_prompt_embeds will be generated from <code>negative_prompt</code> input
argument.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>lora_scale</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A LoRA scale that will be applied to all LoRA layers of the text encoder if LoRA layers are loaded.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>clip_skip</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of layers to be skipped from CLIP while computing the prompt embeddings. A value of 1 means that
the output of the pre-final layer will be used for computing the prompt embeddings.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindone/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">encode_prompt</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">prompt</span><span class="p">,</span>
    <span class="n">num_images_per_prompt</span><span class="p">,</span>
    <span class="n">do_classifier_free_guidance</span><span class="p">,</span>
    <span class="n">negative_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">negative_prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">lora_scale</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">clip_skip</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Encodes the prompt into text encoder hidden states.</span>

<span class="sd">    Args:</span>
<span class="sd">        prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">            prompt to be encoded</span>
<span class="sd">        num_images_per_prompt (`int`):</span>
<span class="sd">            number of images that should be generated per prompt</span>
<span class="sd">        do_classifier_free_guidance (`bool`):</span>
<span class="sd">            whether to use classifier free guidance or not</span>
<span class="sd">        negative_prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">            The prompt or prompts not to guide the image generation. If not defined, one has to pass</span>
<span class="sd">            `negative_prompt_embeds` instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is</span>
<span class="sd">            less than `1`).</span>
<span class="sd">        prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">            Pre-generated text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not</span>
<span class="sd">            provided, text embeddings will be generated from `prompt` input argument.</span>
<span class="sd">        negative_prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">            Pre-generated negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt</span>
<span class="sd">            weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt` input</span>
<span class="sd">            argument.</span>
<span class="sd">        lora_scale (`float`, *optional*):</span>
<span class="sd">            A LoRA scale that will be applied to all LoRA layers of the text encoder if LoRA layers are loaded.</span>
<span class="sd">        clip_skip (`int`, *optional*):</span>
<span class="sd">            Number of layers to be skipped from CLIP while computing the prompt embeddings. A value of 1 means that</span>
<span class="sd">            the output of the pre-final layer will be used for computing the prompt embeddings.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># set lora scale so that monkey patched LoRA</span>
    <span class="c1"># function of text encoder can correctly access it</span>
    <span class="k">if</span> <span class="n">lora_scale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">LoraLoaderMixin</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_lora_scale</span> <span class="o">=</span> <span class="n">lora_scale</span>

        <span class="c1"># dynamically adjust the LoRA scale</span>
        <span class="n">scale_lora_layers</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">,</span> <span class="n">lora_scale</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">prompt_embeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># textual inversion: process multi-vector tokens if necessary</span>
        <span class="n">text_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">prompt</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">text_input_ids</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">text_inputs</span><span class="o">.</span><span class="n">input_ids</span><span class="p">)</span>
        <span class="n">untruncated_ids</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;longest&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">untruncated_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">text_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">ops</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">text_input_ids</span><span class="p">,</span> <span class="n">untruncated_ids</span><span class="p">):</span>
            <span class="n">removed_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">untruncated_ids</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;The following part of your input was truncated because CLIP can only handle sequences up to&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="si">}</span><span class="s2"> tokens: </span><span class="si">{</span><span class="n">removed_text</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;use_attention_mask&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_attention_mask</span><span class="p">:</span>
            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">text_inputs</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">attention_mask</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">clip_skip</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span><span class="n">text_input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
            <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span>
                <span class="n">text_input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="c1"># Access the `hidden_states` first, that contains a tuple of</span>
            <span class="c1"># all the hidden states from the encoder layers. Then index into</span>
            <span class="c1"># the tuple to access the hidden states from the desired layer.</span>
            <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="p">(</span><span class="n">clip_skip</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="c1"># We also need to apply the final LayerNorm here to not mess with the</span>
            <span class="c1"># representations. The `last_hidden_states` that we typically use for</span>
            <span class="c1"># obtaining the final prompt representations passes through the LayerNorm</span>
            <span class="c1"># layer.</span>
            <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">text_model</span><span class="o">.</span><span class="n">final_layer_norm</span><span class="p">(</span><span class="n">prompt_embeds</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">prompt_embeds_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">dtype</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">prompt_embeds_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">dtype</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">prompt_embeds_dtype</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span>

    <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">prompt_embeds_dtype</span><span class="p">)</span>

    <span class="n">bs_embed</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span>
    <span class="c1"># duplicate text embeddings for each generation per prompt, using mps friendly method</span>
    <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">tile</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs_embed</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># get unconditional embeddings for classifier free guidance</span>
    <span class="k">if</span> <span class="n">do_classifier_free_guidance</span> <span class="ow">and</span> <span class="n">negative_prompt_embeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">uncond_tokens</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">negative_prompt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span>
        <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`negative_prompt` should be the same type to `prompt`, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">)</span><span class="si">}</span><span class="s2"> !=&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">negative_prompt</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`negative_prompt`: </span><span class="si">{</span><span class="n">negative_prompt</span><span class="si">}</span><span class="s2"> has batch size </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">, but `prompt`:&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2"> has batch size </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">. Please make sure that passed `negative_prompt` matches&quot;</span>
                <span class="s2">&quot; the batch size of `prompt`.&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="n">negative_prompt</span>

        <span class="c1"># textual inversion: process multi-vector tokens if necessary</span>
        <span class="n">max_length</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">uncond_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">uncond_tokens</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;use_attention_mask&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_attention_mask</span><span class="p">:</span>
            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">uncond_input</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">attention_mask</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span>
            <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">uncond_input</span><span class="o">.</span><span class="n">input_ids</span><span class="p">),</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">do_classifier_free_guidance</span><span class="p">:</span>
        <span class="c1"># duplicate unconditional embeddings for each generation per prompt, using mps friendly method</span>
        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">prompt_embeds_dtype</span><span class="p">)</span>

        <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">tile</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">LoraLoaderMixin</span><span class="p">):</span>
            <span class="c1"># Retrieve the original scale by scaling back the LoRA layers</span>
            <span class="n">unscale_lora_layers</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">,</span> <span class="n">lora_scale</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">prompt_embeds</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindone.diffusers.LatentConsistencyModelPipeline.get_guidance_scale_embedding" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindone</span><span class="o">.</span><span class="n">diffusers</span><span class="o">.</span><span class="n">LatentConsistencyModelPipeline</span><span class="o">.</span><span class="n">get_guidance_scale_embedding</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span></code>

<a href="#mindone.diffusers.LatentConsistencyModelPipeline.get_guidance_scale_embedding" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>See https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>w</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Generate embedding vectors with a specified guidance scale to subsequently enrich timestep embeddings.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>embedding_dim</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimension of the embeddings to generate.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 512</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>512</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>dtype</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Data type of the generated embeddings.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.dtype`, *optional*, defaults to `ms.float32`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code><span title="mindspore.float32">float32</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="mindspore.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p><code>ms.Tensor</code>: Embedding vectors with shape <code>(len(w), embedding_dim)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindone/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_text2img.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_guidance_scale_embedding</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">:</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">ms</span><span class="o">.</span><span class="n">Type</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    See https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298</span>

<span class="sd">    Args:</span>
<span class="sd">        w (`ms.Tensor`):</span>
<span class="sd">            Generate embedding vectors with a specified guidance scale to subsequently enrich timestep embeddings.</span>
<span class="sd">        embedding_dim (`int`, *optional*, defaults to 512):</span>
<span class="sd">            Dimension of the embeddings to generate.</span>
<span class="sd">        dtype (`ms.dtype`, *optional*, defaults to `ms.float32`):</span>
<span class="sd">            Data type of the generated embeddings.</span>

<span class="sd">    Returns:</span>
<span class="sd">        `ms.Tensor`: Embedding vectors with shape `(len(w), embedding_dim)`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="mf">1000.0</span>

    <span class="n">half_dim</span> <span class="o">=</span> <span class="n">embedding_dim</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">emb</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">half_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">emb</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">half_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="n">emb</span><span class="p">)</span>
    <span class="n">emb</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">emb</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">emb</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">ops</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">emb</span><span class="p">),</span> <span class="n">ops</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">emb</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">embedding_dim</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># zero pad</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">assert</span> <span class="n">emb</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">embedding_dim</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">emb</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindone.diffusers.LatentConsistencyModelImg2ImgPipeline" class="doc doc-heading">
            <code>mindone.diffusers.LatentConsistencyModelImg2ImgPipeline</code>


<a href="#mindone.diffusers.LatentConsistencyModelImg2ImgPipeline" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindone.diffusers.pipelines.pipeline_utils.DiffusionPipeline" href="../overview/#mindone.diffusers.DiffusionPipeline">DiffusionPipeline</a></code>, <code><span title="mindone.diffusers.pipelines.pipeline_utils.StableDiffusionMixin">StableDiffusionMixin</span></code>, <code><a class="autorefs autorefs-internal" title="mindone.diffusers.loaders.LoraLoaderMixin" href="../../loaders/lora/#mindone.diffusers.loaders.lora.LoraLoaderMixin">LoraLoaderMixin</a></code></p>


        <p>Pipeline for image-to-image generation using a latent consistency model.</p>
<p>This model inherits from [<code>DiffusionPipeline</code>]. Check the superclass documentation for the generic methods
implemented for all pipelines (downloading, saving, running on a particular device, etc.).</p>


<details class="the-pipeline-also-inherits-the-following-loading-methods" open>
  <summary>The pipeline also inherits the following loading methods</summary>
  <ul>
<li>[<code>~loaders.TextualInversionLoaderMixin.load_textual_inversion</code>] for loading textual inversion embeddings</li>
<li>[<code>~loaders.LoraLoaderMixin.load_lora_weights</code>] for loading LoRA weights</li>
<li>[<code>~loaders.LoraLoaderMixin.save_lora_weights</code>] for saving LoRA weights</li>
<li>[<code>~loaders.FromSingleFileMixin.from_single_file</code>] for loading <code>.ckpt</code> files</li>
<li>[<code>~loaders.IPAdapterMixin.load_ip_adapter</code>] for loading IP Adapters</li>
</ul>
</details>

<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>vae</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Variational Auto-Encoder (VAE) model to encode and decode images to and from latent representations.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`AutoencoderKL`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>text_encoder</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Frozen text-encoder (<a href="https://huggingface.co/openai/clip-vit-large-patch14">clip-vit-large-patch14</a>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`~transformers.CLIPTextModel`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>tokenizer</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A <code>CLIPTokenizer</code> to tokenize text.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`~transformers.CLIPTokenizer`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>unet</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A <code>UNet2DConditionModel</code> to denoise the encoded image latents.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`UNet2DConditionModel`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scheduler</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A scheduler to be used in combination with <code>unet</code> to denoise the encoded image latents. Currently only
supports [<code>LCMScheduler</code>].</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`SchedulerMixin`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>safety_checker</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Classification module that estimates whether generated images could be considered offensive or harmful.
Please refer to the <a href="https://huggingface.co/runwayml/stable-diffusion-v1-5">model card</a> for more details
about a model's potential harms.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`StableDiffusionSafetyChecker`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>feature_extractor</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A <code>CLIPImageProcessor</code> to extract features from generated images; used as inputs to the <code>safety_checker</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`~transformers.CLIPImageProcessor`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>requires_safety_checker</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether the pipeline requires a safety checker component.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>mindone/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">LatentConsistencyModelImg2ImgPipeline</span><span class="p">(</span><span class="n">DiffusionPipeline</span><span class="p">,</span> <span class="n">StableDiffusionMixin</span><span class="p">,</span> <span class="n">LoraLoaderMixin</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Pipeline for image-to-image generation using a latent consistency model.</span>

<span class="sd">    This model inherits from [`DiffusionPipeline`]. Check the superclass documentation for the generic methods</span>
<span class="sd">    implemented for all pipelines (downloading, saving, running on a particular device, etc.).</span>

<span class="sd">    The pipeline also inherits the following loading methods:</span>
<span class="sd">        - [`~loaders.TextualInversionLoaderMixin.load_textual_inversion`] for loading textual inversion embeddings</span>
<span class="sd">        - [`~loaders.LoraLoaderMixin.load_lora_weights`] for loading LoRA weights</span>
<span class="sd">        - [`~loaders.LoraLoaderMixin.save_lora_weights`] for saving LoRA weights</span>
<span class="sd">        - [`~loaders.FromSingleFileMixin.from_single_file`] for loading `.ckpt` files</span>
<span class="sd">        - [`~loaders.IPAdapterMixin.load_ip_adapter`] for loading IP Adapters</span>

<span class="sd">    Args:</span>
<span class="sd">        vae ([`AutoencoderKL`]):</span>
<span class="sd">            Variational Auto-Encoder (VAE) model to encode and decode images to and from latent representations.</span>
<span class="sd">        text_encoder ([`~transformers.CLIPTextModel`]):</span>
<span class="sd">            Frozen text-encoder ([clip-vit-large-patch14](https://huggingface.co/openai/clip-vit-large-patch14)).</span>
<span class="sd">        tokenizer ([`~transformers.CLIPTokenizer`]):</span>
<span class="sd">            A `CLIPTokenizer` to tokenize text.</span>
<span class="sd">        unet ([`UNet2DConditionModel`]):</span>
<span class="sd">            A `UNet2DConditionModel` to denoise the encoded image latents.</span>
<span class="sd">        scheduler ([`SchedulerMixin`]):</span>
<span class="sd">            A scheduler to be used in combination with `unet` to denoise the encoded image latents. Currently only</span>
<span class="sd">            supports [`LCMScheduler`].</span>
<span class="sd">        safety_checker ([`StableDiffusionSafetyChecker`]):</span>
<span class="sd">            Classification module that estimates whether generated images could be considered offensive or harmful.</span>
<span class="sd">            Please refer to the [model card](https://huggingface.co/runwayml/stable-diffusion-v1-5) for more details</span>
<span class="sd">            about a model&#39;s potential harms.</span>
<span class="sd">        feature_extractor ([`~transformers.CLIPImageProcessor`]):</span>
<span class="sd">            A `CLIPImageProcessor` to extract features from generated images; used as inputs to the `safety_checker`.</span>
<span class="sd">        requires_safety_checker (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether the pipeline requires a safety checker component.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">model_cpu_offload_seq</span> <span class="o">=</span> <span class="s2">&quot;text_encoder-&gt;unet-&gt;vae&quot;</span>
    <span class="n">_optional_components</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;safety_checker&quot;</span><span class="p">,</span> <span class="s2">&quot;feature_extractor&quot;</span><span class="p">,</span> <span class="s2">&quot;image_encoder&quot;</span><span class="p">]</span>
    <span class="n">_exclude_from_cpu_offload</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;safety_checker&quot;</span><span class="p">]</span>
    <span class="n">_callback_tensor_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latents&quot;</span><span class="p">,</span> <span class="s2">&quot;denoised&quot;</span><span class="p">,</span> <span class="s2">&quot;prompt_embeds&quot;</span><span class="p">,</span> <span class="s2">&quot;w_embedding&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">vae</span><span class="p">:</span> <span class="n">AutoencoderKL</span><span class="p">,</span>
        <span class="n">text_encoder</span><span class="p">:</span> <span class="n">CLIPTextModel</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">CLIPTokenizer</span><span class="p">,</span>
        <span class="n">unet</span><span class="p">:</span> <span class="n">UNet2DConditionModel</span><span class="p">,</span>
        <span class="n">scheduler</span><span class="p">:</span> <span class="n">LCMScheduler</span><span class="p">,</span>
        <span class="n">safety_checker</span><span class="p">:</span> <span class="n">StableDiffusionSafetyChecker</span><span class="p">,</span>
        <span class="n">feature_extractor</span><span class="p">:</span> <span class="n">CLIPImageProcessor</span><span class="p">,</span>
        <span class="n">image_encoder</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">CLIPVisionModelWithProjection</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">requires_safety_checker</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">register_modules</span><span class="p">(</span>
            <span class="n">vae</span><span class="o">=</span><span class="n">vae</span><span class="p">,</span>
            <span class="n">text_encoder</span><span class="o">=</span><span class="n">text_encoder</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">unet</span><span class="o">=</span><span class="n">unet</span><span class="p">,</span>
            <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
            <span class="n">safety_checker</span><span class="o">=</span><span class="n">safety_checker</span><span class="p">,</span>
            <span class="n">feature_extractor</span><span class="o">=</span><span class="n">feature_extractor</span><span class="p">,</span>
            <span class="n">image_encoder</span><span class="o">=</span><span class="n">image_encoder</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">safety_checker</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">requires_safety_checker</span><span class="p">:</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;You have disabled the safety checker for </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="si">}</span><span class="s2"> by passing `safety_checker=None`. Ensure&quot;</span>
                <span class="s2">&quot; that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered&quot;</span>
                <span class="s2">&quot; results in services or applications open to the public. Both the diffusers team and Hugging Face&quot;</span>
                <span class="s2">&quot; strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling&quot;</span>
                <span class="s2">&quot; it only for use-cases that involve analyzing network behavior or auditing its results. For more&quot;</span>
                <span class="s2">&quot; information, please have a look at https://github.com/huggingface/diffusers/pull/254 .&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">vae_scale_factor</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">**</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">block_out_channels</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span> <span class="o">=</span> <span class="n">VaeImageProcessor</span><span class="p">(</span><span class="n">vae_scale_factor</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">vae_scale_factor</span><span class="p">)</span>

    <span class="c1"># Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline.encode_prompt</span>
    <span class="k">def</span> <span class="nf">encode_prompt</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">,</span>
        <span class="n">num_images_per_prompt</span><span class="p">,</span>
        <span class="n">do_classifier_free_guidance</span><span class="p">,</span>
        <span class="n">negative_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">negative_prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">lora_scale</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">clip_skip</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Encodes the prompt into text encoder hidden states.</span>

<span class="sd">        Args:</span>
<span class="sd">            prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">                prompt to be encoded</span>
<span class="sd">            num_images_per_prompt (`int`):</span>
<span class="sd">                number of images that should be generated per prompt</span>
<span class="sd">            do_classifier_free_guidance (`bool`):</span>
<span class="sd">                whether to use classifier free guidance or not</span>
<span class="sd">            negative_prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">                The prompt or prompts not to guide the image generation. If not defined, one has to pass</span>
<span class="sd">                `negative_prompt_embeds` instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is</span>
<span class="sd">                less than `1`).</span>
<span class="sd">            prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">                Pre-generated text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not</span>
<span class="sd">                provided, text embeddings will be generated from `prompt` input argument.</span>
<span class="sd">            negative_prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">                Pre-generated negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt</span>
<span class="sd">                weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt` input</span>
<span class="sd">                argument.</span>
<span class="sd">            lora_scale (`float`, *optional*):</span>
<span class="sd">                A LoRA scale that will be applied to all LoRA layers of the text encoder if LoRA layers are loaded.</span>
<span class="sd">            clip_skip (`int`, *optional*):</span>
<span class="sd">                Number of layers to be skipped from CLIP while computing the prompt embeddings. A value of 1 means that</span>
<span class="sd">                the output of the pre-final layer will be used for computing the prompt embeddings.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># set lora scale so that monkey patched LoRA</span>
        <span class="c1"># function of text encoder can correctly access it</span>
        <span class="k">if</span> <span class="n">lora_scale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">LoraLoaderMixin</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_lora_scale</span> <span class="o">=</span> <span class="n">lora_scale</span>

            <span class="c1"># dynamically adjust the LoRA scale</span>
            <span class="n">scale_lora_layers</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">,</span> <span class="n">lora_scale</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">prompt_embeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># textual inversion: process multi-vector tokens if necessary</span>
            <span class="n">text_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
                <span class="n">prompt</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">,</span>
                <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">text_input_ids</span> <span class="o">=</span> <span class="n">text_inputs</span><span class="o">.</span><span class="n">input_ids</span>
            <span class="n">untruncated_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;longest&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>

            <span class="k">if</span> <span class="n">untruncated_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">text_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">ops</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">text_input_ids</span><span class="p">,</span> <span class="n">untruncated_ids</span><span class="p">):</span>
                <span class="n">removed_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">untruncated_ids</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;The following part of your input was truncated because CLIP can only handle sequences up to&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="si">}</span><span class="s2"> tokens: </span><span class="si">{</span><span class="n">removed_text</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;use_attention_mask&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_attention_mask</span><span class="p">:</span>
                <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">text_inputs</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">attention_mask</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="k">if</span> <span class="n">clip_skip</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">text_input_ids</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
                <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span>
                    <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">text_input_ids</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">True</span>
                <span class="p">)</span>
                <span class="c1"># Access the `hidden_states` first, that contains a tuple of</span>
                <span class="c1"># all the hidden states from the encoder layers. Then index into</span>
                <span class="c1"># the tuple to access the hidden states from the desired layer.</span>
                <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="p">(</span><span class="n">clip_skip</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
                <span class="c1"># We also need to apply the final LayerNorm here to not mess with the</span>
                <span class="c1"># representations. The `last_hidden_states` that we typically use for</span>
                <span class="c1"># obtaining the final prompt representations passes through the LayerNorm</span>
                <span class="c1"># layer.</span>
                <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">text_model</span><span class="o">.</span><span class="n">final_layer_norm</span><span class="p">(</span><span class="n">prompt_embeds</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prompt_embeds_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">dtype</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prompt_embeds_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">dtype</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prompt_embeds_dtype</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span>

        <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">prompt_embeds_dtype</span><span class="p">)</span>

        <span class="n">bs_embed</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span>
        <span class="c1"># duplicate text embeddings for each generation per prompt, using mps friendly method</span>
        <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">tile</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs_embed</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1"># get unconditional embeddings for classifier free guidance</span>
        <span class="k">if</span> <span class="n">do_classifier_free_guidance</span> <span class="ow">and</span> <span class="n">negative_prompt_embeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">uncond_tokens</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">negative_prompt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span>
            <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;`negative_prompt` should be the same type to `prompt`, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">)</span><span class="si">}</span><span class="s2"> !=&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">negative_prompt</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;`negative_prompt`: </span><span class="si">{</span><span class="n">negative_prompt</span><span class="si">}</span><span class="s2"> has batch size </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">, but `prompt`:&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2"> has batch size </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">. Please make sure that passed `negative_prompt` matches&quot;</span>
                    <span class="s2">&quot; the batch size of `prompt`.&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="n">negative_prompt</span>

            <span class="c1"># textual inversion: process multi-vector tokens if necessary</span>
            <span class="n">max_length</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">uncond_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
                <span class="n">uncond_tokens</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
                <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;use_attention_mask&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_attention_mask</span><span class="p">:</span>
                <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">uncond_input</span><span class="o">.</span><span class="n">attention_mask</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">attention_mask</span> <span class="o">=</span> <span class="kc">None</span>

            <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span>
                <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">uncond_input</span><span class="o">.</span><span class="n">input_ids</span><span class="p">),</span>
                <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">do_classifier_free_guidance</span><span class="p">:</span>
            <span class="c1"># duplicate unconditional embeddings for each generation per prompt, using mps friendly method</span>
            <span class="n">seq_len</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">prompt_embeds_dtype</span><span class="p">)</span>

            <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">tile</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">LoraLoaderMixin</span><span class="p">):</span>
                <span class="c1"># Retrieve the original scale by scaling back the LoRA layers</span>
                <span class="n">unscale_lora_layers</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">,</span> <span class="n">lora_scale</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">prompt_embeds</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span>

    <span class="c1"># Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline.run_safety_checker</span>
    <span class="k">def</span> <span class="nf">run_safety_checker</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">dtype</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">safety_checker</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">has_nsfw_concept</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">ops</span><span class="o">.</span><span class="n">is_tensor</span><span class="p">(</span><span class="n">image</span><span class="p">):</span>
                <span class="n">feature_extractor_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="s2">&quot;pil&quot;</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">feature_extractor_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="o">.</span><span class="n">numpy_to_pil</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
            <span class="n">safety_checker_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_extractor</span><span class="p">(</span><span class="n">feature_extractor_input</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">)</span>
            <span class="n">image</span><span class="p">,</span> <span class="n">has_nsfw_concept</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">safety_checker</span><span class="p">(</span>
                <span class="n">images</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">clip_input</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">safety_checker_input</span><span class="o">.</span><span class="n">pixel_values</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">has_nsfw_concept</span>

    <span class="c1"># Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline.prepare_latents</span>
    <span class="k">def</span> <span class="nf">prepare_latents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">image</span><span class="p">,</span> <span class="n">timestep</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`image` has to be of type `ms.Tensor`, `PIL.Image.Image` or list but is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">image</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span>

        <span class="k">if</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="mi">4</span><span class="p">:</span>
            <span class="n">init_latents</span> <span class="o">=</span> <span class="n">image</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span> <span class="o">!=</span> <span class="n">batch_size</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;You have passed a list of generators of length </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">generator</span><span class="p">)</span><span class="si">}</span><span class="s2">, but requested an effective batch&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; size of </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">. Make sure the batch size matches the length of the generators.&quot;</span>
                <span class="p">)</span>

            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="n">init_latents</span> <span class="o">=</span> <span class="p">[</span>
                    <span class="n">retrieve_latents</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="n">i</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])[</span><span class="mi">0</span><span class="p">],</span> <span class="n">generator</span><span class="p">)</span>
                    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
                <span class="p">]</span>
                <span class="n">init_latents</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">init_latents</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">init_latents</span> <span class="o">=</span> <span class="n">retrieve_latents</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="n">image</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">generator</span><span class="p">)</span>

            <span class="n">init_latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">scaling_factor</span> <span class="o">*</span> <span class="n">init_latents</span>

        <span class="k">if</span> <span class="n">batch_size</span> <span class="o">&gt;</span> <span class="n">init_latents</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">batch_size</span> <span class="o">%</span> <span class="n">init_latents</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="c1"># expand init_latents for batch_size</span>
            <span class="n">deprecation_message</span> <span class="o">=</span> <span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;You have passed </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2"> text prompts (`prompt`), but only </span><span class="si">{</span><span class="n">init_latents</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> initial&quot;</span>
                <span class="s2">&quot; images (`image`). Initial images are now duplicating to match the number of text prompts. Note&quot;</span>
                <span class="s2">&quot; that this behavior is deprecated and will be removed in a version 1.0.0. Please make sure to update&quot;</span>
                <span class="s2">&quot; your script to pass as many initial images as text prompts to suppress this warning.&quot;</span>
            <span class="p">)</span>
            <span class="n">deprecate</span><span class="p">(</span><span class="s2">&quot;len(prompt) != len(image)&quot;</span><span class="p">,</span> <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span> <span class="n">deprecation_message</span><span class="p">,</span> <span class="n">standard_warn</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">additional_image_per_prompt</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">//</span> <span class="n">init_latents</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">init_latents</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">init_latents</span><span class="p">]</span> <span class="o">*</span> <span class="n">additional_image_per_prompt</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">batch_size</span> <span class="o">&gt;</span> <span class="n">init_latents</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">and</span> <span class="n">batch_size</span> <span class="o">%</span> <span class="n">init_latents</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Cannot duplicate `image` of batch size </span><span class="si">{</span><span class="n">init_latents</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> to </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2"> text prompts.&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">init_latents</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">init_latents</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">shape</span> <span class="o">=</span> <span class="n">init_latents</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">noise</span> <span class="o">=</span> <span class="n">randn_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c1"># get latents</span>
        <span class="n">init_latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">add_noise</span><span class="p">(</span><span class="n">init_latents</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">timestep</span><span class="p">)</span>
        <span class="n">latents</span> <span class="o">=</span> <span class="n">init_latents</span>

        <span class="k">return</span> <span class="n">latents</span>

    <span class="c1"># Copied from diffusers.pipelines.latent_consistency_models.pipeline_latent_consistency_text2img.LatentConsistencyModelPipeline.get_guidance_scale_embedding</span>
    <span class="k">def</span> <span class="nf">get_guidance_scale_embedding</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">:</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">ms</span><span class="o">.</span><span class="n">Type</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        See https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298</span>

<span class="sd">        Args:</span>
<span class="sd">            w (`ms.Tensor`):</span>
<span class="sd">                Generate embedding vectors with a specified guidance scale to subsequently enrich timestep embeddings.</span>
<span class="sd">            embedding_dim (`int`, *optional*, defaults to 512):</span>
<span class="sd">                Dimension of the embeddings to generate.</span>
<span class="sd">            dtype (`ms.dtype`, *optional*, defaults to `ms.float32`):</span>
<span class="sd">                Data type of the generated embeddings.</span>

<span class="sd">        Returns:</span>
<span class="sd">            `ms.Tensor`: Embedding vectors with shape `(len(w), embedding_dim)`.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="mf">1000.0</span>

        <span class="n">half_dim</span> <span class="o">=</span> <span class="n">embedding_dim</span> <span class="o">//</span> <span class="mi">2</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">half_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">half_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="n">emb</span><span class="p">)</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">emb</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">ops</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">emb</span><span class="p">),</span> <span class="n">ops</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">emb</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">embedding_dim</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># zero pad</span>
            <span class="n">emb</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="k">assert</span> <span class="n">emb</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">embedding_dim</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">emb</span>

    <span class="c1"># Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion.StableDiffusionPipeline.prepare_extra_step_kwargs</span>
    <span class="k">def</span> <span class="nf">prepare_extra_step_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">eta</span><span class="p">):</span>
        <span class="c1"># prepare extra kwargs for the scheduler step, since not all schedulers have the same signature</span>
        <span class="c1"># eta (Î·) is only used with the DDIMScheduler, it will be ignored for other schedulers.</span>
        <span class="c1"># eta corresponds to Î· in DDIM paper: https://arxiv.org/abs/2010.02502</span>
        <span class="c1"># and should be between [0, 1]</span>

        <span class="n">accepts_eta</span> <span class="o">=</span> <span class="s2">&quot;eta&quot;</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">extra_step_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">accepts_eta</span><span class="p">:</span>
            <span class="n">extra_step_kwargs</span><span class="p">[</span><span class="s2">&quot;eta&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">eta</span>

        <span class="c1"># check if the scheduler accepts generator</span>
        <span class="n">accepts_generator</span> <span class="o">=</span> <span class="s2">&quot;generator&quot;</span> <span class="ow">in</span> <span class="nb">set</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="k">if</span> <span class="n">accepts_generator</span><span class="p">:</span>
            <span class="n">extra_step_kwargs</span><span class="p">[</span><span class="s2">&quot;generator&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">generator</span>
        <span class="k">return</span> <span class="n">extra_step_kwargs</span>

    <span class="c1"># Copied from diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline.get_timesteps</span>
    <span class="k">def</span> <span class="nf">get_timesteps</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inference_steps</span><span class="p">,</span> <span class="n">strength</span><span class="p">):</span>
        <span class="c1"># get the original timestep using init_timestep</span>
        <span class="n">init_timestep</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">num_inference_steps</span> <span class="o">*</span> <span class="n">strength</span><span class="p">),</span> <span class="n">num_inference_steps</span><span class="p">)</span>

        <span class="n">t_start</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">num_inference_steps</span> <span class="o">-</span> <span class="n">init_timestep</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">timesteps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">timesteps</span><span class="p">[</span><span class="n">t_start</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">order</span> <span class="p">:]</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">,</span> <span class="s2">&quot;set_begin_index&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">set_begin_index</span><span class="p">(</span><span class="n">t_start</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">order</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">timesteps</span><span class="p">,</span> <span class="n">num_inference_steps</span> <span class="o">-</span> <span class="n">t_start</span>

    <span class="k">def</span> <span class="nf">check_inputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
        <span class="n">strength</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">callback_steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ip_adapter_image</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">ip_adapter_image_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">callback_on_step_end_tensor_inputs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">strength</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">strength</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The value of strength should in [0.0, 1.0] but is </span><span class="si">{</span><span class="n">strength</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">callback_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">callback_steps</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">or</span> <span class="n">callback_steps</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`callback_steps` has to be a positive integer but is </span><span class="si">{</span><span class="n">callback_steps</span><span class="si">}</span><span class="s2"> of type&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">callback_steps</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">callback_on_step_end_tensor_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span>
            <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">callback_on_step_end_tensor_inputs</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`callback_on_step_end_tensor_inputs` has to be in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but found </span><span class="si">{</span><span class="p">[</span><span class="n">k</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">callback_on_step_end_tensor_inputs</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">prompt_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Cannot forward both `prompt`: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2"> and `prompt_embeds`: </span><span class="si">{</span><span class="n">prompt_embeds</span><span class="si">}</span><span class="s2">. Please make sure to&quot;</span>
                <span class="s2">&quot; only forward one of the two.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">prompt_embeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Provide either `prompt` or `prompt_embeds`. Cannot leave both `prompt` and `prompt_embeds` undefined.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`prompt` has to be of type `str` or `list` but is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">ip_adapter_image</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">ip_adapter_image_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Provide either `ip_adapter_image` or `ip_adapter_image_embeds`. Cannot leave both `ip_adapter_image` and `ip_adapter_image_embeds` defined.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">ip_adapter_image_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">ip_adapter_image_embeds</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;`ip_adapter_image_embeds` has to be of type `list` but is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">ip_adapter_image_embeds</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="n">ip_adapter_image_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ndim</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;`ip_adapter_image_embeds` has to be a list of 3D or 4D tensors but is </span><span class="si">{</span><span class="n">ip_adapter_image_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ndim</span><span class="si">}</span><span class="s2">D&quot;</span>
                <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">guidance_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_guidance_scale</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">cross_attention_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_cross_attention_kwargs</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">clip_skip</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_clip_skip</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">do_classifier_free_guidance</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="kc">False</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_timesteps</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_timesteps</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">image</span><span class="p">:</span> <span class="n">PipelineImageInput</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
        <span class="n">strength</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
        <span class="n">original_inference_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">timesteps</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">guidance_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">8.5</span><span class="p">,</span>
        <span class="n">num_images_per_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">generator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">latents</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ip_adapter_image</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PipelineImageInput</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ip_adapter_image_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;pil&quot;</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">cross_attention_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">clip_skip</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">callback_on_step_end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latents&quot;</span><span class="p">],</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        The call function to the pipeline for generation.</span>

<span class="sd">        Args:</span>
<span class="sd">            prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">                The prompt or prompts to guide image generation. If not defined, you need to pass `prompt_embeds`.</span>
<span class="sd">            height (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`):</span>
<span class="sd">                The height in pixels of the generated image.</span>
<span class="sd">            width (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`):</span>
<span class="sd">                The width in pixels of the generated image.</span>
<span class="sd">            num_inference_steps (`int`, *optional*, defaults to 50):</span>
<span class="sd">                The number of denoising steps. More denoising steps usually lead to a higher quality image at the</span>
<span class="sd">                expense of slower inference.</span>
<span class="sd">            original_inference_steps (`int`, *optional*):</span>
<span class="sd">                The original number of inference steps use to generate a linearly-spaced timestep schedule, from which</span>
<span class="sd">                we will draw `num_inference_steps` evenly spaced timesteps from as our final timestep schedule,</span>
<span class="sd">                following the Skipping-Step method in the paper (see Section 4.3). If not set this will default to the</span>
<span class="sd">                scheduler&#39;s `original_inference_steps` attribute.</span>
<span class="sd">            timesteps (`List[int]`, *optional*):</span>
<span class="sd">                Custom timesteps to use for the denoising process. If not defined, equal spaced `num_inference_steps`</span>
<span class="sd">                timesteps on the original LCM training/distillation timestep schedule are used. Must be in descending</span>
<span class="sd">                order.</span>
<span class="sd">            guidance_scale (`float`, *optional*, defaults to 7.5):</span>
<span class="sd">                A higher guidance scale value encourages the model to generate images closely linked to the text</span>
<span class="sd">                `prompt` at the expense of lower image quality. Guidance scale is enabled when `guidance_scale &gt; 1`.</span>
<span class="sd">                Note that the original latent consistency models paper uses a different CFG formulation where the</span>
<span class="sd">                guidance scales are decreased by 1 (so in the paper formulation CFG is enabled when `guidance_scale &gt;</span>
<span class="sd">                0`).</span>
<span class="sd">            num_images_per_prompt (`int`, *optional*, defaults to 1):</span>
<span class="sd">                The number of images to generate per prompt.</span>
<span class="sd">            generator (`np.random.Generator` or `List[np.random.Generator]`, *optional*):</span>
<span class="sd">                A [`np.random.Generator`](https://numpy.org/doc/stable/reference/random/generator.html) to make</span>
<span class="sd">                generation deterministic.</span>
<span class="sd">            latents (`ms.Tensor`, *optional*):</span>
<span class="sd">                Pre-generated noisy latents sampled from a Gaussian distribution, to be used as inputs for image</span>
<span class="sd">                generation. Can be used to tweak the same generation with different prompts. If not provided, a latents</span>
<span class="sd">                tensor is generated by sampling using the supplied random `generator`.</span>
<span class="sd">            prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">                Pre-generated text embeddings. Can be used to easily tweak text inputs (prompt weighting). If not</span>
<span class="sd">                provided, text embeddings are generated from the `prompt` input argument.</span>
<span class="sd">            ip_adapter_image: (`PipelineImageInput`, *optional*):</span>
<span class="sd">                Optional image input to work with IP Adapters.</span>
<span class="sd">            ip_adapter_image_embeds (`List[ms.Tensor]`, *optional*):</span>
<span class="sd">                Pre-generated image embeddings for IP-Adapter. It should be a list of length same as number of IP-adapters.</span>
<span class="sd">                Each element should be a tensor of shape `(batch_size, num_images, emb_dim)`. It should contain the negative image embedding</span>
<span class="sd">                if `do_classifier_free_guidance` is set to `True`.</span>
<span class="sd">                If not provided, embeddings are computed from the `ip_adapter_image` input argument.</span>
<span class="sd">            output_type (`str`, *optional*, defaults to `&quot;pil&quot;`):</span>
<span class="sd">                The output format of the generated image. Choose between `PIL.Image` or `np.array`.</span>
<span class="sd">            return_dict (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                Whether or not to return a [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] instead of a</span>
<span class="sd">                plain tuple.</span>
<span class="sd">            cross_attention_kwargs (`dict`, *optional*):</span>
<span class="sd">                A kwargs dictionary that if specified is passed along to the [`AttentionProcessor`] as defined in</span>
<span class="sd">                [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).</span>
<span class="sd">            clip_skip (`int`, *optional*):</span>
<span class="sd">                Number of layers to be skipped from CLIP while computing the prompt embeddings. A value of 1 means that</span>
<span class="sd">                the output of the pre-final layer will be used for computing the prompt embeddings.</span>
<span class="sd">            callback_on_step_end (`Callable`, *optional*):</span>
<span class="sd">                A function that calls at the end of each denoising steps during the inference. The function is called</span>
<span class="sd">                with the following arguments: `callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int,</span>
<span class="sd">                callback_kwargs: Dict)`. `callback_kwargs` will include a list of all tensors as specified by</span>
<span class="sd">                `callback_on_step_end_tensor_inputs`.</span>
<span class="sd">            callback_on_step_end_tensor_inputs (`List`, *optional*):</span>
<span class="sd">                The list of tensor inputs for the `callback_on_step_end` function. The tensors specified in the list</span>
<span class="sd">                will be passed as `callback_kwargs` argument. You will only be able to include variables listed in the</span>
<span class="sd">                `._callback_tensor_inputs` attribute of your pipeline class.</span>

<span class="sd">        Examples:</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] or `tuple`:</span>
<span class="sd">                If `return_dict` is `True`, [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] is returned,</span>
<span class="sd">                otherwise a `tuple` is returned where the first element is a list with the generated images and the</span>
<span class="sd">                second element is a list of `bool`s indicating whether the corresponding generated image contains</span>
<span class="sd">                &quot;not-safe-for-work&quot; (nsfw) content.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">callback</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;callback&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">callback_steps</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;callback_steps&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">deprecate</span><span class="p">(</span>
                <span class="s2">&quot;callback&quot;</span><span class="p">,</span>
                <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Passing `callback` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">callback_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">deprecate</span><span class="p">(</span>
                <span class="s2">&quot;callback_steps&quot;</span><span class="p">,</span>
                <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Passing `callback_steps` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="c1"># 1. Check inputs. Raise error if not correct</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">check_inputs</span><span class="p">(</span>
            <span class="n">prompt</span><span class="p">,</span>
            <span class="n">strength</span><span class="p">,</span>
            <span class="n">callback_steps</span><span class="p">,</span>
            <span class="n">prompt_embeds</span><span class="p">,</span>
            <span class="n">ip_adapter_image</span><span class="p">,</span>
            <span class="n">ip_adapter_image_embeds</span><span class="p">,</span>
            <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_guidance_scale</span> <span class="o">=</span> <span class="n">guidance_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_clip_skip</span> <span class="o">=</span> <span class="n">clip_skip</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_cross_attention_kwargs</span> <span class="o">=</span> <span class="n">cross_attention_kwargs</span>

        <span class="c1"># 2. Define call parameters</span>
        <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># 3. Encode input prompt</span>
        <span class="n">lora_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attention_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attention_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="c1"># NOTE: when a LCM is distilled from an LDM via latent consistency distillation (Algorithm 1) with guided</span>
        <span class="c1"># distillation, the forward pass of the LCM learns to approximate sampling from the LDM using CFG with the</span>
        <span class="c1"># unconditional prompt &quot;&quot; (the empty string). Due to this, LCMs currently do not support negative prompts.</span>
        <span class="n">prompt_embeds</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_prompt</span><span class="p">(</span>
            <span class="n">prompt</span><span class="p">,</span>
            <span class="n">num_images_per_prompt</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">,</span>
            <span class="n">negative_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">prompt_embeds</span><span class="o">=</span><span class="n">prompt_embeds</span><span class="p">,</span>
            <span class="n">negative_prompt_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">lora_scale</span><span class="o">=</span><span class="n">lora_scale</span><span class="p">,</span>
            <span class="n">clip_skip</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clip_skip</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># 4. Encode image</span>
        <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

        <span class="c1"># 5. Prepare timesteps</span>
        <span class="n">timesteps</span><span class="p">,</span> <span class="n">num_inference_steps</span> <span class="o">=</span> <span class="n">retrieve_timesteps</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">,</span>
            <span class="n">num_inference_steps</span><span class="p">,</span>
            <span class="n">timesteps</span><span class="p">,</span>
            <span class="n">original_inference_steps</span><span class="o">=</span><span class="n">original_inference_steps</span><span class="p">,</span>
            <span class="n">strength</span><span class="o">=</span><span class="n">strength</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># 6. Prepare latent variables</span>
        <span class="n">original_inference_steps</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">original_inference_steps</span>
            <span class="k">if</span> <span class="n">original_inference_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
            <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">original_inference_steps</span>
        <span class="p">)</span>
        <span class="n">latent_timestep</span> <span class="o">=</span> <span class="n">timesteps</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">latents</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_latents</span><span class="p">(</span>
                <span class="n">image</span><span class="p">,</span> <span class="n">latent_timestep</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">generator</span>
            <span class="p">)</span>
        <span class="n">bs</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span>

        <span class="c1"># 6. Get Guidance Scale Embedding</span>
        <span class="c1"># NOTE: We use the Imagen CFG formulation that StableDiffusionPipeline uses rather than the original LCM paper</span>
        <span class="c1"># CFG formulation, so we need to subtract 1 from the input guidance_scale.</span>
        <span class="c1"># LCM CFG formulation:  cfg_noise = noise_cond + cfg_scale * (noise_cond - noise_uncond), (cfg_scale &gt; 0.0 using CFG)</span>
        <span class="n">w</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">guidance_scale</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">bs</span><span class="p">)</span>
        <span class="n">w_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_guidance_scale_embedding</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">time_cond_proj_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
            <span class="n">dtype</span><span class="o">=</span><span class="n">latents</span><span class="o">.</span><span class="n">dtype</span>
        <span class="p">)</span>

        <span class="c1"># 7. Prepare extra step kwargs. TODO: Logic should ideally just be moved out of the pipeline</span>
        <span class="n">extra_step_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_extra_step_kwargs</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="c1"># 7.1 Add image embeds for IP-Adapter</span>
        <span class="n">added_cond_kwargs</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="c1"># 8. LCM Multistep Sampling Loop</span>
        <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span> <span class="o">-</span> <span class="n">num_inference_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">order</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_timesteps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span>
        <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">progress_bar</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">num_inference_steps</span><span class="p">)</span> <span class="k">as</span> <span class="n">progress_bar</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">timesteps</span><span class="p">):</span>
                <span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

                <span class="c1"># model prediction (v-prediction, eps, x)</span>
                <span class="n">model_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="p">(</span>
                    <span class="n">latents</span><span class="p">,</span>
                    <span class="n">t</span><span class="p">,</span>
                    <span class="n">timestep_cond</span><span class="o">=</span><span class="n">w_embedding</span><span class="p">,</span>
                    <span class="n">encoder_hidden_states</span><span class="o">=</span><span class="n">prompt_embeds</span><span class="p">,</span>
                    <span class="n">cross_attention_kwargs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cross_attention_kwargs</span><span class="p">,</span>
                    <span class="n">added_cond_kwargs</span><span class="o">=</span><span class="n">added_cond_kwargs</span><span class="p">,</span>
                    <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

                <span class="c1"># compute the previous noisy sample x_t -&gt; x_t-1</span>
                <span class="n">latents</span><span class="p">,</span> <span class="n">denoised</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">model_pred</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">latents</span><span class="p">,</span> <span class="o">**</span><span class="n">extra_step_kwargs</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">callback_on_step_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">callback_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
                    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span>
                        <span class="n">callback_kwargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">locals</span><span class="p">()[</span><span class="n">k</span><span class="p">]</span>
                    <span class="n">callback_outputs</span> <span class="o">=</span> <span class="n">callback_on_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">callback_kwargs</span><span class="p">)</span>

                    <span class="n">latents</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;latents&quot;</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span>
                    <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;prompt_embeds&quot;</span><span class="p">,</span> <span class="n">prompt_embeds</span><span class="p">)</span>
                    <span class="n">w_embedding</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;w_embedding&quot;</span><span class="p">,</span> <span class="n">w_embedding</span><span class="p">)</span>
                    <span class="n">denoised</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;denoised&quot;</span><span class="p">,</span> <span class="n">denoised</span><span class="p">)</span>

                <span class="c1"># call the callback, if provided</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">or</span> <span class="p">((</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">num_warmup_steps</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">order</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                    <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
                    <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="n">callback_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                        <span class="n">step_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">,</span> <span class="s2">&quot;order&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                        <span class="n">callback</span><span class="p">(</span><span class="n">step_idx</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span>

        <span class="n">denoised</span> <span class="o">=</span> <span class="n">denoised</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">output_type</span> <span class="o">==</span> <span class="s2">&quot;latent&quot;</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">denoised</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">scaling_factor</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">image</span><span class="p">,</span> <span class="n">has_nsfw_concept</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_safety_checker</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">denoised</span>
            <span class="n">has_nsfw_concept</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">has_nsfw_concept</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">do_denormalize</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span><span class="p">]</span> <span class="o">*</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">do_denormalize</span> <span class="o">=</span> <span class="p">[</span><span class="ow">not</span> <span class="n">has_nsfw</span> <span class="k">for</span> <span class="n">has_nsfw</span> <span class="ow">in</span> <span class="n">has_nsfw_concept</span><span class="p">]</span>

        <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">output_type</span><span class="p">,</span> <span class="n">do_denormalize</span><span class="o">=</span><span class="n">do_denormalize</span><span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">has_nsfw_concept</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">StableDiffusionPipelineOutput</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">nsfw_content_detected</span><span class="o">=</span><span class="n">has_nsfw_concept</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindone.diffusers.LatentConsistencyModelImg2ImgPipeline.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindone</span><span class="o">.</span><span class="n">diffusers</span><span class="o">.</span><span class="n">LatentConsistencyModelImg2ImgPipeline</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">image</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">strength</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">original_inference_steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">guidance_scale</span><span class="o">=</span><span class="mf">8.5</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">latents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prompt_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ip_adapter_image</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ip_adapter_image_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="s1">&#39;pil&#39;</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">cross_attention_kwargs</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">clip_skip</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">callback_on_step_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">callback_on_step_end_tensor_inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;latents&#39;</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindone.diffusers.LatentConsistencyModelImg2ImgPipeline.__call__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>The call function to the pipeline for generation.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The prompt or prompts to guide image generation. If not defined, you need to pass <code>prompt_embeds</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `List[str]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>height</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The height in pixels of the generated image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>width</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The width in pixels of the generated image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_inference_steps</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of denoising steps. More denoising steps usually lead to a higher quality image at the
expense of slower inference.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 50</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>4</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>original_inference_steps</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The original number of inference steps use to generate a linearly-spaced timestep schedule, from which
we will draw <code>num_inference_steps</code> evenly spaced timesteps from as our final timestep schedule,
following the Skipping-Step method in the paper (see Section 4.3). If not set this will default to the
scheduler's <code>original_inference_steps</code> attribute.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>timesteps</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Custom timesteps to use for the denoising process. If not defined, equal spaced <code>num_inference_steps</code>
timesteps on the original LCM training/distillation timestep schedule are used. Must be in descending
order.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[int]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>guidance_scale</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A higher guidance scale value encourages the model to generate images closely linked to the text
<code>prompt</code> at the expense of lower image quality. Guidance scale is enabled when <code>guidance_scale &gt; 1</code>.
Note that the original latent consistency models paper uses a different CFG formulation where the
guidance scales are decreased by 1 (so in the paper formulation CFG is enabled when <code>guidance_scale &gt;
0</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 7.5</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>8.5</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_images_per_prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of images to generate per prompt.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 1</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>generator</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A <a href="https://numpy.org/doc/stable/reference/random/generator.html"><code>np.random.Generator</code></a> to make
generation deterministic.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`np.random.Generator` or `List[np.random.Generator]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>latents</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pre-generated noisy latents sampled from a Gaussian distribution, to be used as inputs for image
generation. Can be used to tweak the same generation with different prompts. If not provided, a latents
tensor is generated by sampling using the supplied random <code>generator</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prompt_embeds</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pre-generated text embeddings. Can be used to easily tweak text inputs (prompt weighting). If not
provided, text embeddings are generated from the <code>prompt</code> input argument.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>ip_adapter_image</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>(<code>PipelineImageInput</code>, <em>optional</em>):
Optional image input to work with IP Adapters.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code><span title="typing.Optional">Optional</span>[<span title="mindone.diffusers.image_processor.PipelineImageInput">PipelineImageInput</span>]</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>ip_adapter_image_embeds</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pre-generated image embeddings for IP-Adapter. It should be a list of length same as number of IP-adapters.
Each element should be a tensor of shape <code>(batch_size, num_images, emb_dim)</code>. It should contain the negative image embedding
if <code>do_classifier_free_guidance</code> is set to <code>True</code>.
If not provided, embeddings are computed from the <code>ip_adapter_image</code> input argument.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[ms.Tensor]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>output_type</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The output format of the generated image. Choose between <code>PIL.Image</code> or <code>np.array</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;pil&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;pil&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>return_dict</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to return a [<code>~pipelines.stable_diffusion.StableDiffusionPipelineOutput</code>] instead of a
plain tuple.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>cross_attention_kwargs</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A kwargs dictionary that if specified is passed along to the [<code>AttentionProcessor</code>] as defined in
<a href="https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py"><code>self.processor</code></a>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`dict`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>clip_skip</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of layers to be skipped from CLIP while computing the prompt embeddings. A value of 1 means that
the output of the pre-final layer will be used for computing the prompt embeddings.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>callback_on_step_end</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A function that calls at the end of each denoising steps during the inference. The function is called
with the following arguments: <code>callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int,
callback_kwargs: Dict)</code>. <code>callback_kwargs</code> will include a list of all tensors as specified by
<code>callback_on_step_end_tensor_inputs</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Callable`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>callback_on_step_end_tensor_inputs</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The list of tensor inputs for the <code>callback_on_step_end</code> function. The tensors specified in the list
will be passed as <code>callback_kwargs</code> argument. You will only be able to include variables listed in the
<code>._callback_tensor_inputs</code> attribute of your pipeline class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>[&#39;latents&#39;]</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>[<code>~pipelines.stable_diffusion.StableDiffusionPipelineOutput</code>] or <code>tuple</code>:
If <code>return_dict</code> is <code>True</code>, [<code>~pipelines.stable_diffusion.StableDiffusionPipelineOutput</code>] is returned,
otherwise a <code>tuple</code> is returned where the first element is a list with the generated images and the
second element is a list of <code>bool</code>s indicating whether the corresponding generated image contains
"not-safe-for-work" (nsfw) content.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindone/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">image</span><span class="p">:</span> <span class="n">PipelineImageInput</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_inference_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">strength</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span>
    <span class="n">original_inference_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">timesteps</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">guidance_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">8.5</span><span class="p">,</span>
    <span class="n">num_images_per_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">latents</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ip_adapter_image</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PipelineImageInput</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">ip_adapter_image_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;pil&quot;</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">cross_attention_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">clip_skip</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">callback_on_step_end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latents&quot;</span><span class="p">],</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    The call function to the pipeline for generation.</span>

<span class="sd">    Args:</span>
<span class="sd">        prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">            The prompt or prompts to guide image generation. If not defined, you need to pass `prompt_embeds`.</span>
<span class="sd">        height (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`):</span>
<span class="sd">            The height in pixels of the generated image.</span>
<span class="sd">        width (`int`, *optional*, defaults to `self.unet.config.sample_size * self.vae_scale_factor`):</span>
<span class="sd">            The width in pixels of the generated image.</span>
<span class="sd">        num_inference_steps (`int`, *optional*, defaults to 50):</span>
<span class="sd">            The number of denoising steps. More denoising steps usually lead to a higher quality image at the</span>
<span class="sd">            expense of slower inference.</span>
<span class="sd">        original_inference_steps (`int`, *optional*):</span>
<span class="sd">            The original number of inference steps use to generate a linearly-spaced timestep schedule, from which</span>
<span class="sd">            we will draw `num_inference_steps` evenly spaced timesteps from as our final timestep schedule,</span>
<span class="sd">            following the Skipping-Step method in the paper (see Section 4.3). If not set this will default to the</span>
<span class="sd">            scheduler&#39;s `original_inference_steps` attribute.</span>
<span class="sd">        timesteps (`List[int]`, *optional*):</span>
<span class="sd">            Custom timesteps to use for the denoising process. If not defined, equal spaced `num_inference_steps`</span>
<span class="sd">            timesteps on the original LCM training/distillation timestep schedule are used. Must be in descending</span>
<span class="sd">            order.</span>
<span class="sd">        guidance_scale (`float`, *optional*, defaults to 7.5):</span>
<span class="sd">            A higher guidance scale value encourages the model to generate images closely linked to the text</span>
<span class="sd">            `prompt` at the expense of lower image quality. Guidance scale is enabled when `guidance_scale &gt; 1`.</span>
<span class="sd">            Note that the original latent consistency models paper uses a different CFG formulation where the</span>
<span class="sd">            guidance scales are decreased by 1 (so in the paper formulation CFG is enabled when `guidance_scale &gt;</span>
<span class="sd">            0`).</span>
<span class="sd">        num_images_per_prompt (`int`, *optional*, defaults to 1):</span>
<span class="sd">            The number of images to generate per prompt.</span>
<span class="sd">        generator (`np.random.Generator` or `List[np.random.Generator]`, *optional*):</span>
<span class="sd">            A [`np.random.Generator`](https://numpy.org/doc/stable/reference/random/generator.html) to make</span>
<span class="sd">            generation deterministic.</span>
<span class="sd">        latents (`ms.Tensor`, *optional*):</span>
<span class="sd">            Pre-generated noisy latents sampled from a Gaussian distribution, to be used as inputs for image</span>
<span class="sd">            generation. Can be used to tweak the same generation with different prompts. If not provided, a latents</span>
<span class="sd">            tensor is generated by sampling using the supplied random `generator`.</span>
<span class="sd">        prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">            Pre-generated text embeddings. Can be used to easily tweak text inputs (prompt weighting). If not</span>
<span class="sd">            provided, text embeddings are generated from the `prompt` input argument.</span>
<span class="sd">        ip_adapter_image: (`PipelineImageInput`, *optional*):</span>
<span class="sd">            Optional image input to work with IP Adapters.</span>
<span class="sd">        ip_adapter_image_embeds (`List[ms.Tensor]`, *optional*):</span>
<span class="sd">            Pre-generated image embeddings for IP-Adapter. It should be a list of length same as number of IP-adapters.</span>
<span class="sd">            Each element should be a tensor of shape `(batch_size, num_images, emb_dim)`. It should contain the negative image embedding</span>
<span class="sd">            if `do_classifier_free_guidance` is set to `True`.</span>
<span class="sd">            If not provided, embeddings are computed from the `ip_adapter_image` input argument.</span>
<span class="sd">        output_type (`str`, *optional*, defaults to `&quot;pil&quot;`):</span>
<span class="sd">            The output format of the generated image. Choose between `PIL.Image` or `np.array`.</span>
<span class="sd">        return_dict (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether or not to return a [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] instead of a</span>
<span class="sd">            plain tuple.</span>
<span class="sd">        cross_attention_kwargs (`dict`, *optional*):</span>
<span class="sd">            A kwargs dictionary that if specified is passed along to the [`AttentionProcessor`] as defined in</span>
<span class="sd">            [`self.processor`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py).</span>
<span class="sd">        clip_skip (`int`, *optional*):</span>
<span class="sd">            Number of layers to be skipped from CLIP while computing the prompt embeddings. A value of 1 means that</span>
<span class="sd">            the output of the pre-final layer will be used for computing the prompt embeddings.</span>
<span class="sd">        callback_on_step_end (`Callable`, *optional*):</span>
<span class="sd">            A function that calls at the end of each denoising steps during the inference. The function is called</span>
<span class="sd">            with the following arguments: `callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int,</span>
<span class="sd">            callback_kwargs: Dict)`. `callback_kwargs` will include a list of all tensors as specified by</span>
<span class="sd">            `callback_on_step_end_tensor_inputs`.</span>
<span class="sd">        callback_on_step_end_tensor_inputs (`List`, *optional*):</span>
<span class="sd">            The list of tensor inputs for the `callback_on_step_end` function. The tensors specified in the list</span>
<span class="sd">            will be passed as `callback_kwargs` argument. You will only be able to include variables listed in the</span>
<span class="sd">            `._callback_tensor_inputs` attribute of your pipeline class.</span>

<span class="sd">    Examples:</span>

<span class="sd">    Returns:</span>
<span class="sd">        [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] or `tuple`:</span>
<span class="sd">            If `return_dict` is `True`, [`~pipelines.stable_diffusion.StableDiffusionPipelineOutput`] is returned,</span>
<span class="sd">            otherwise a `tuple` is returned where the first element is a list with the generated images and the</span>
<span class="sd">            second element is a list of `bool`s indicating whether the corresponding generated image contains</span>
<span class="sd">            &quot;not-safe-for-work&quot; (nsfw) content.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">callback</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;callback&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">callback_steps</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;callback_steps&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">deprecate</span><span class="p">(</span>
            <span class="s2">&quot;callback&quot;</span><span class="p">,</span>
            <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Passing `callback` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`&quot;</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">callback_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">deprecate</span><span class="p">(</span>
            <span class="s2">&quot;callback_steps&quot;</span><span class="p">,</span>
            <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Passing `callback_steps` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="c1"># 1. Check inputs. Raise error if not correct</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">check_inputs</span><span class="p">(</span>
        <span class="n">prompt</span><span class="p">,</span>
        <span class="n">strength</span><span class="p">,</span>
        <span class="n">callback_steps</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="p">,</span>
        <span class="n">ip_adapter_image</span><span class="p">,</span>
        <span class="n">ip_adapter_image_embeds</span><span class="p">,</span>
        <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_guidance_scale</span> <span class="o">=</span> <span class="n">guidance_scale</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_clip_skip</span> <span class="o">=</span> <span class="n">clip_skip</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_cross_attention_kwargs</span> <span class="o">=</span> <span class="n">cross_attention_kwargs</span>

    <span class="c1"># 2. Define call parameters</span>
    <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># 3. Encode input prompt</span>
    <span class="n">lora_scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attention_kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;scale&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cross_attention_kwargs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="c1"># NOTE: when a LCM is distilled from an LDM via latent consistency distillation (Algorithm 1) with guided</span>
    <span class="c1"># distillation, the forward pass of the LCM learns to approximate sampling from the LDM using CFG with the</span>
    <span class="c1"># unconditional prompt &quot;&quot; (the empty string). Due to this, LCMs currently do not support negative prompts.</span>
    <span class="n">prompt_embeds</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_prompt</span><span class="p">(</span>
        <span class="n">prompt</span><span class="p">,</span>
        <span class="n">num_images_per_prompt</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">,</span>
        <span class="n">negative_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="o">=</span><span class="n">prompt_embeds</span><span class="p">,</span>
        <span class="n">negative_prompt_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">lora_scale</span><span class="o">=</span><span class="n">lora_scale</span><span class="p">,</span>
        <span class="n">clip_skip</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">clip_skip</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># 4. Encode image</span>
    <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="o">.</span><span class="n">preprocess</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>

    <span class="c1"># 5. Prepare timesteps</span>
    <span class="n">timesteps</span><span class="p">,</span> <span class="n">num_inference_steps</span> <span class="o">=</span> <span class="n">retrieve_timesteps</span><span class="p">(</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="p">,</span>
        <span class="n">timesteps</span><span class="p">,</span>
        <span class="n">original_inference_steps</span><span class="o">=</span><span class="n">original_inference_steps</span><span class="p">,</span>
        <span class="n">strength</span><span class="o">=</span><span class="n">strength</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># 6. Prepare latent variables</span>
    <span class="n">original_inference_steps</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">original_inference_steps</span>
        <span class="k">if</span> <span class="n">original_inference_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
        <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">original_inference_steps</span>
    <span class="p">)</span>
    <span class="n">latent_timestep</span> <span class="o">=</span> <span class="n">timesteps</span><span class="p">[:</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">latents</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_latents</span><span class="p">(</span>
            <span class="n">image</span><span class="p">,</span> <span class="n">latent_timestep</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">generator</span>
        <span class="p">)</span>
    <span class="n">bs</span> <span class="o">=</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span>

    <span class="c1"># 6. Get Guidance Scale Embedding</span>
    <span class="c1"># NOTE: We use the Imagen CFG formulation that StableDiffusionPipeline uses rather than the original LCM paper</span>
    <span class="c1"># CFG formulation, so we need to subtract 1 from the input guidance_scale.</span>
    <span class="c1"># LCM CFG formulation:  cfg_noise = noise_cond + cfg_scale * (noise_cond - noise_uncond), (cfg_scale &gt; 0.0 using CFG)</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">guidance_scale</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">bs</span><span class="p">)</span>
    <span class="n">w_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_guidance_scale_embedding</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">time_cond_proj_dim</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span>
        <span class="n">dtype</span><span class="o">=</span><span class="n">latents</span><span class="o">.</span><span class="n">dtype</span>
    <span class="p">)</span>

    <span class="c1"># 7. Prepare extra step kwargs. TODO: Logic should ideally just be moved out of the pipeline</span>
    <span class="n">extra_step_kwargs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_extra_step_kwargs</span><span class="p">(</span><span class="n">generator</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="c1"># 7.1 Add image embeds for IP-Adapter</span>
    <span class="n">added_cond_kwargs</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="c1"># 8. LCM Multistep Sampling Loop</span>
    <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span> <span class="o">-</span> <span class="n">num_inference_steps</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">order</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_num_timesteps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span>
    <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">progress_bar</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="n">num_inference_steps</span><span class="p">)</span> <span class="k">as</span> <span class="n">progress_bar</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">timesteps</span><span class="p">):</span>
            <span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

            <span class="c1"># model prediction (v-prediction, eps, x)</span>
            <span class="n">model_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="p">(</span>
                <span class="n">latents</span><span class="p">,</span>
                <span class="n">t</span><span class="p">,</span>
                <span class="n">timestep_cond</span><span class="o">=</span><span class="n">w_embedding</span><span class="p">,</span>
                <span class="n">encoder_hidden_states</span><span class="o">=</span><span class="n">prompt_embeds</span><span class="p">,</span>
                <span class="n">cross_attention_kwargs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">cross_attention_kwargs</span><span class="p">,</span>
                <span class="n">added_cond_kwargs</span><span class="o">=</span><span class="n">added_cond_kwargs</span><span class="p">,</span>
                <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c1"># compute the previous noisy sample x_t -&gt; x_t-1</span>
            <span class="n">latents</span><span class="p">,</span> <span class="n">denoised</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">model_pred</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">latents</span><span class="p">,</span> <span class="o">**</span><span class="n">extra_step_kwargs</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">callback_on_step_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">callback_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span>
                    <span class="n">callback_kwargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">locals</span><span class="p">()[</span><span class="n">k</span><span class="p">]</span>
                <span class="n">callback_outputs</span> <span class="o">=</span> <span class="n">callback_on_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">callback_kwargs</span><span class="p">)</span>

                <span class="n">latents</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;latents&quot;</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span>
                <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;prompt_embeds&quot;</span><span class="p">,</span> <span class="n">prompt_embeds</span><span class="p">)</span>
                <span class="n">w_embedding</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;w_embedding&quot;</span><span class="p">,</span> <span class="n">w_embedding</span><span class="p">)</span>
                <span class="n">denoised</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;denoised&quot;</span><span class="p">,</span> <span class="n">denoised</span><span class="p">)</span>

            <span class="c1"># call the callback, if provided</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="ow">or</span> <span class="p">((</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">num_warmup_steps</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">order</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
                <span class="n">progress_bar</span><span class="o">.</span><span class="n">update</span><span class="p">()</span>
                <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="n">callback_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                    <span class="n">step_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">,</span> <span class="s2">&quot;order&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="n">callback</span><span class="p">(</span><span class="n">step_idx</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span>

    <span class="n">denoised</span> <span class="o">=</span> <span class="n">denoised</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">output_type</span> <span class="o">==</span> <span class="s2">&quot;latent&quot;</span><span class="p">:</span>
        <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">denoised</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">vae</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">scaling_factor</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">image</span><span class="p">,</span> <span class="n">has_nsfw_concept</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">run_safety_checker</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">denoised</span>
        <span class="n">has_nsfw_concept</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">has_nsfw_concept</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">do_denormalize</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span><span class="p">]</span> <span class="o">*</span> <span class="n">image</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">do_denormalize</span> <span class="o">=</span> <span class="p">[</span><span class="ow">not</span> <span class="n">has_nsfw</span> <span class="k">for</span> <span class="n">has_nsfw</span> <span class="ow">in</span> <span class="n">has_nsfw_concept</span><span class="p">]</span>

    <span class="n">image</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">image_processor</span><span class="o">.</span><span class="n">postprocess</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="n">output_type</span><span class="p">,</span> <span class="n">do_denormalize</span><span class="o">=</span><span class="n">do_denormalize</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">has_nsfw_concept</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">StableDiffusionPipelineOutput</span><span class="p">(</span><span class="n">images</span><span class="o">=</span><span class="n">image</span><span class="p">,</span> <span class="n">nsfw_content_detected</span><span class="o">=</span><span class="n">has_nsfw_concept</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindone.diffusers.LatentConsistencyModelImg2ImgPipeline.encode_prompt" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindone</span><span class="o">.</span><span class="n">diffusers</span><span class="o">.</span><span class="n">LatentConsistencyModelImg2ImgPipeline</span><span class="o">.</span><span class="n">encode_prompt</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="n">do_classifier_free_guidance</span><span class="p">,</span> <span class="n">negative_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prompt_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">lora_scale</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">clip_skip</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindone.diffusers.LatentConsistencyModelImg2ImgPipeline.encode_prompt" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Encodes the prompt into text encoder hidden states.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>prompt to be encoded</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `List[str]`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_images_per_prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>number of images that should be generated per prompt</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>do_classifier_free_guidance</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>whether to use classifier free guidance or not</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>negative_prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The prompt or prompts not to guide the image generation. If not defined, one has to pass
<code>negative_prompt_embeds</code> instead. Ignored when not using guidance (i.e., ignored if <code>guidance_scale</code> is
less than <code>1</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `List[str]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prompt_embeds</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pre-generated text embeddings. Can be used to easily tweak text inputs, <em>e.g.</em> prompt weighting. If not
provided, text embeddings will be generated from <code>prompt</code> input argument.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>negative_prompt_embeds</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pre-generated negative text embeddings. Can be used to easily tweak text inputs, <em>e.g.</em> prompt
weighting. If not provided, negative_prompt_embeds will be generated from <code>negative_prompt</code> input
argument.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>lora_scale</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A LoRA scale that will be applied to all LoRA layers of the text encoder if LoRA layers are loaded.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>clip_skip</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Number of layers to be skipped from CLIP while computing the prompt embeddings. A value of 1 means that
the output of the pre-final layer will be used for computing the prompt embeddings.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindone/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">encode_prompt</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">prompt</span><span class="p">,</span>
    <span class="n">num_images_per_prompt</span><span class="p">,</span>
    <span class="n">do_classifier_free_guidance</span><span class="p">,</span>
    <span class="n">negative_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">negative_prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">lora_scale</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">clip_skip</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Encodes the prompt into text encoder hidden states.</span>

<span class="sd">    Args:</span>
<span class="sd">        prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">            prompt to be encoded</span>
<span class="sd">        num_images_per_prompt (`int`):</span>
<span class="sd">            number of images that should be generated per prompt</span>
<span class="sd">        do_classifier_free_guidance (`bool`):</span>
<span class="sd">            whether to use classifier free guidance or not</span>
<span class="sd">        negative_prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">            The prompt or prompts not to guide the image generation. If not defined, one has to pass</span>
<span class="sd">            `negative_prompt_embeds` instead. Ignored when not using guidance (i.e., ignored if `guidance_scale` is</span>
<span class="sd">            less than `1`).</span>
<span class="sd">        prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">            Pre-generated text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not</span>
<span class="sd">            provided, text embeddings will be generated from `prompt` input argument.</span>
<span class="sd">        negative_prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">            Pre-generated negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt</span>
<span class="sd">            weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt` input</span>
<span class="sd">            argument.</span>
<span class="sd">        lora_scale (`float`, *optional*):</span>
<span class="sd">            A LoRA scale that will be applied to all LoRA layers of the text encoder if LoRA layers are loaded.</span>
<span class="sd">        clip_skip (`int`, *optional*):</span>
<span class="sd">            Number of layers to be skipped from CLIP while computing the prompt embeddings. A value of 1 means that</span>
<span class="sd">            the output of the pre-final layer will be used for computing the prompt embeddings.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># set lora scale so that monkey patched LoRA</span>
    <span class="c1"># function of text encoder can correctly access it</span>
    <span class="k">if</span> <span class="n">lora_scale</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">LoraLoaderMixin</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_lora_scale</span> <span class="o">=</span> <span class="n">lora_scale</span>

        <span class="c1"># dynamically adjust the LoRA scale</span>
        <span class="n">scale_lora_layers</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">,</span> <span class="n">lora_scale</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">prompt_embeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># textual inversion: process multi-vector tokens if necessary</span>
        <span class="n">text_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">prompt</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">text_input_ids</span> <span class="o">=</span> <span class="n">text_inputs</span><span class="o">.</span><span class="n">input_ids</span>
        <span class="n">untruncated_ids</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;longest&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span>

        <span class="k">if</span> <span class="n">untruncated_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">text_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">ops</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">text_input_ids</span><span class="p">,</span> <span class="n">untruncated_ids</span><span class="p">):</span>
            <span class="n">removed_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">untruncated_ids</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;The following part of your input was truncated because CLIP can only handle sequences up to&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="si">}</span><span class="s2"> tokens: </span><span class="si">{</span><span class="n">removed_text</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;use_attention_mask&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_attention_mask</span><span class="p">:</span>
            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">text_inputs</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">attention_mask</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">clip_skip</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">text_input_ids</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
            <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span>
                <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">text_input_ids</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span> <span class="n">output_hidden_states</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="c1"># Access the `hidden_states` first, that contains a tuple of</span>
            <span class="c1"># all the hidden states from the encoder layers. Then index into</span>
            <span class="c1"># the tuple to access the hidden states from the desired layer.</span>
            <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="p">(</span><span class="n">clip_skip</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="c1"># We also need to apply the final LayerNorm here to not mess with the</span>
            <span class="c1"># representations. The `last_hidden_states` that we typically use for</span>
            <span class="c1"># obtaining the final prompt representations passes through the LayerNorm</span>
            <span class="c1"># layer.</span>
            <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">text_model</span><span class="o">.</span><span class="n">final_layer_norm</span><span class="p">(</span><span class="n">prompt_embeds</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">prompt_embeds_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">dtype</span>
    <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">prompt_embeds_dtype</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">dtype</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">prompt_embeds_dtype</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">dtype</span>

    <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">prompt_embeds_dtype</span><span class="p">)</span>

    <span class="n">bs_embed</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span>
    <span class="c1"># duplicate text embeddings for each generation per prompt, using mps friendly method</span>
    <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">tile</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bs_embed</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="c1"># get unconditional embeddings for classifier free guidance</span>
    <span class="k">if</span> <span class="n">do_classifier_free_guidance</span> <span class="ow">and</span> <span class="n">negative_prompt_embeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">uncond_tokens</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">negative_prompt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span>
        <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`negative_prompt` should be the same type to `prompt`, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">)</span><span class="si">}</span><span class="s2"> !=&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">negative_prompt</span><span class="p">]</span>
        <span class="k">elif</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`negative_prompt`: </span><span class="si">{</span><span class="n">negative_prompt</span><span class="si">}</span><span class="s2"> has batch size </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">, but `prompt`:&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2"> has batch size </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">. Please make sure that passed `negative_prompt` matches&quot;</span>
                <span class="s2">&quot; the batch size of `prompt`.&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="n">negative_prompt</span>

        <span class="c1"># textual inversion: process multi-vector tokens if necessary</span>
        <span class="n">max_length</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">uncond_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">uncond_tokens</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="n">max_length</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">config</span><span class="p">,</span> <span class="s2">&quot;use_attention_mask&quot;</span><span class="p">)</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">use_attention_mask</span><span class="p">:</span>
            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">uncond_input</span><span class="o">.</span><span class="n">attention_mask</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">attention_mask</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span>
            <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">uncond_input</span><span class="o">.</span><span class="n">input_ids</span><span class="p">),</span>
            <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">do_classifier_free_guidance</span><span class="p">:</span>
        <span class="c1"># duplicate unconditional embeddings for each generation per prompt, using mps friendly method</span>
        <span class="n">seq_len</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">prompt_embeds_dtype</span><span class="p">)</span>

        <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">tile</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
        <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">LoraLoaderMixin</span><span class="p">):</span>
            <span class="c1"># Retrieve the original scale by scaling back the LoRA layers</span>
            <span class="n">unscale_lora_layers</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">,</span> <span class="n">lora_scale</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">prompt_embeds</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindone.diffusers.LatentConsistencyModelImg2ImgPipeline.get_guidance_scale_embedding" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindone</span><span class="o">.</span><span class="n">diffusers</span><span class="o">.</span><span class="n">LatentConsistencyModelImg2ImgPipeline</span><span class="o">.</span><span class="n">get_guidance_scale_embedding</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span></code>

<a href="#mindone.diffusers.LatentConsistencyModelImg2ImgPipeline.get_guidance_scale_embedding" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>See https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>w</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Generate embedding vectors with a specified guidance scale to subsequently enrich timestep embeddings.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>embedding_dim</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Dimension of the embeddings to generate.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 512</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>512</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>dtype</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Data type of the generated embeddings.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.dtype`, *optional*, defaults to `ms.float32`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code><span title="mindspore.float32">float32</span></code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <span class="doc-returns-annotation">
                    <code><span title="mindspore.Tensor">Tensor</span></code>
                </span>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p><code>ms.Tensor</code>: Embedding vectors with shape <code>(len(w), embedding_dim)</code>.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindone/diffusers/pipelines/latent_consistency_models/pipeline_latent_consistency_img2img.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">get_guidance_scale_embedding</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">w</span><span class="p">:</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="n">ms</span><span class="o">.</span><span class="n">Type</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float32</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    See https://github.com/google-research/vdm/blob/dc27b98a554f65cdc654b800da5aa1846545d41b/model_vdm.py#L298</span>

<span class="sd">    Args:</span>
<span class="sd">        w (`ms.Tensor`):</span>
<span class="sd">            Generate embedding vectors with a specified guidance scale to subsequently enrich timestep embeddings.</span>
<span class="sd">        embedding_dim (`int`, *optional*, defaults to 512):</span>
<span class="sd">            Dimension of the embeddings to generate.</span>
<span class="sd">        dtype (`ms.dtype`, *optional*, defaults to `ms.float32`):</span>
<span class="sd">            Data type of the generated embeddings.</span>

<span class="sd">    Returns:</span>
<span class="sd">        `ms.Tensor`: Embedding vectors with shape `(len(w), embedding_dim)`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">w</span> <span class="o">*</span> <span class="mf">1000.0</span>

    <span class="n">half_dim</span> <span class="o">=</span> <span class="n">embedding_dim</span> <span class="o">//</span> <span class="mi">2</span>
    <span class="n">emb</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">ms</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">half_dim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">emb</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">ops</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">half_dim</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span> <span class="o">*</span> <span class="o">-</span><span class="n">emb</span><span class="p">)</span>
    <span class="n">emb</span> <span class="o">=</span> <span class="n">w</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">)[:,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">emb</span><span class="p">[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">emb</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">ops</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">emb</span><span class="p">),</span> <span class="n">ops</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">emb</span><span class="p">)],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">embedding_dim</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># zero pad</span>
        <span class="n">emb</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">pad</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">assert</span> <span class="n">emb</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">embedding_dim</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">emb</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindone.diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput" class="doc doc-heading">
            <code>mindone.diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

<a href="#mindone.diffusers.pipelines.stable_diffusion.StableDiffusionPipelineOutput" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindone.diffusers.utils.BaseOutput" href="../../outputs/#mindone.diffusers.utils.BaseOutput">BaseOutput</a></code></p>


        <p>Output class for Stable Diffusion pipelines.</p>

              <details class="quote">
                <summary>Source code in <code>mindone/diffusers/pipelines/stable_diffusion/pipeline_output.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">StableDiffusionPipelineOutput</span><span class="p">(</span><span class="n">BaseOutput</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Output class for Stable Diffusion pipelines.</span>

<span class="sd">    Args:</span>
<span class="sd">        images (`List[PIL.Image.Image]` or `np.ndarray`)</span>
<span class="sd">            List of denoised PIL images of length `batch_size` or NumPy array of shape `(batch_size, height, width,</span>
<span class="sd">            num_channels)`.</span>
<span class="sd">        nsfw_content_detected (`List[bool]`)</span>
<span class="sd">            List indicating whether the corresponding generated image contains &quot;not-safe-for-work&quot; (nsfw) content or</span>
<span class="sd">            `None` if safety checking could not be performed.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">images</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">Image</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span>
    <span class="n">nsfw_content_detected</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 1, 2024</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 1, 2024</span>
  </span>

    
    
      
  
  <span class="md-source-file__fact">
    <span class="md-icon" title="Contributors">
      
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 4a4 4 0 0 1 4 4 4 4 0 0 1-4 4 4 4 0 0 1-4-4 4 4 0 0 1 4-4m0 10c4.42 0 8 1.79 8 4v2H4v-2c0-2.21 3.58-4 8-4"/></svg>
      
    </span>
    <nav>
      
        <a href="mailto:77485245+wcrzlh@users.noreply.github.com">Chaoran Wei</a>
    </nav>
  </span>

    
    
  </aside>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../kandinsky3/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Kandinsky 3">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Kandinsky 3
              </div>
            </div>
          </a>
        
        
          
          <a href="../latent_diffusion/" class="md-footer__link md-footer__link--next" aria-label="Next: Latent Diffusion">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Latent Diffusion
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 - 2024 MindSpore Lab
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="mailto:mindspore-lab@huawei.com" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/mindspore-lab/mindone" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.zhihu.com/people/mindsporelab" target="_blank" rel="noopener" title="www.zhihu.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M170.54 148.13v217.54l23.43.01 7.71 26.37 42.01-26.37h49.53V148.13zm97.75 193.93h-27.94l-27.9 17.51-5.08-17.47-11.9-.04V171.75h72.82zm-118.46-94.39H97.5c1.74-27.1 2.2-51.59 2.2-73.46h51.16s1.97-22.56-8.58-22.31h-88.5c3.49-13.12 7.87-26.66 13.12-40.67 0 0-24.07 0-32.27 21.57-3.39 8.9-13.21 43.14-30.7 78.12 5.89-.64 25.37-1.18 36.84-22.21 2.11-5.89 2.51-6.66 5.14-14.53h28.87c0 10.5-1.2 66.88-1.68 73.44H20.83c-11.74 0-15.56 23.62-15.56 23.62h65.58C66.45 321.1 42.83 363.12 0 396.34c20.49 5.85 40.91-.93 51-9.9 0 0 22.98-20.9 35.59-69.25l53.96 64.94s7.91-26.89-1.24-39.99c-7.58-8.92-28.06-33.06-36.79-41.81L87.9 311.95c4.36-13.98 6.99-27.55 7.87-40.67h61.65s-.09-23.62-7.59-23.62zm412.02-1.6c20.83-25.64 44.98-58.57 44.98-58.57s-18.65-14.8-27.38-4.06c-6 8.15-36.83 48.2-36.83 48.2zm-150.09-59.09c-9.01-8.25-25.91 2.13-25.91 2.13s39.52 55.04 41.12 57.45l19.46-13.73s-25.67-37.61-34.66-45.86h-.01zM640 258.35c-19.78 0-130.91.93-131.06.93v-101c4.81 0 12.42-.4 22.85-1.2 40.88-2.41 70.13-4 87.77-4.81 0 0 12.22-27.19-.59-33.44-3.07-1.18-23.17 4.58-23.17 4.58s-165.22 16.49-232.36 18.05c1.6 8.82 7.62 17.08 15.78 19.55 13.31 3.48 22.69 1.7 49.15.89 24.83-1.6 43.68-2.43 56.51-2.43v99.81H351.41s2.82 22.31 25.51 22.85h107.94v70.92c0 13.97-11.19 21.99-24.48 21.12-14.08.11-26.08-1.15-41.69-1.81 1.99 3.97 6.33 14.39 19.31 21.84 9.88 4.81 16.17 6.57 26.02 6.57 29.56 0 45.67-17.28 44.89-45.31v-73.32h122.36c9.68 0 8.7-23.78 8.7-23.78z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.top", "navigation.footer", "toc.follow", "search.highlight", "search.share", "search.suggest", "content.action.view", "content.action.edit", "content.tabs.link", "content.code.copy", "content.code.select", "content.code.annotations"], "search": "../../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>