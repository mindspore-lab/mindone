
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://mindspore-lab.github.io/mindone/0.2/diffusers/api/pipelines/wuerstchen/">
      
      
        <link rel="prev" href="../unclip/">
      
      
        <link rel="next" href="../../internal_classes_overview/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.43">
    
    
      
        <title>Wuerstchen - MindOne - One for All</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.0253249f.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,300i,400,400i,700,700i%7CIBM+Plex+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Source Sans Pro";--md-code-font:"IBM Plex Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#wurstchen" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="MindOne - One for All" class="md-header__button md-logo" aria-label="MindOne - One for All" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            MindOne - One for All
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Wuerstchen
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/mindspore-lab/mindone" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindone
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../" class="md-tabs__link">
          
  
  Diffusers

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../transformers/" class="md-tabs__link">
          
  
  Transformers

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../peft/" class="md-tabs__link">
          
  
  PEFT

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="MindOne - One for All" class="md-nav__button md-logo" aria-label="MindOne - One for All" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    MindOne - One for All
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mindspore-lab/mindone" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindone
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Diffusers
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Diffusers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Get started
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            Get started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ðŸ§¨ Diffusers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../quicktour/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quicktour
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../stable_diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Effective and efficient diffusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Installation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../limitations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Limitations
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/tutorial_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/write_own_pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Understanding pipelines, models and schedulers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/basic_training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Train a diffusion model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/using_peft_for_inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Load LoRAs for inference
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" checked>
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3_1" >
        
          
          <label class="md-nav__link" for="__nav_2_3_1" id="__nav_2_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Loaders
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3_1">
            <span class="md-nav__icon md-icon"></span>
            Loaders
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../loaders/ip_adapter/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IP-Adapter
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../loaders/lora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LoRA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../loaders/peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PEFT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../loaders/single_file/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single file
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../loaders/textual_inversion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Textual Inversion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../loaders/unet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UNet
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3_2" >
        
          
          <label class="md-nav__link" for="__nav_2_3_2" id="__nav_2_3_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3_2">
            <span class="md-nav__icon md-icon"></span>
            Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/unet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UNet1DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/unet2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UNet2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/unet2d-cond/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UNet2DConditionModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/unet3d-cond/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UNet3DConditionModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/unet-motion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UNetMotionModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/uvit2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UViT2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/vq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UVQModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/autoencoderkl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AutoEncoderKL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/asymmetricautoencoderkl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AsymmetricAutoEncoderKL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/autoencoder_tiny/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tiny AutoEncoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/consistency_decoder_vae/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ConsistencyDecoderVae
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/transformer2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformer2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/pixart_transformer2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PixArtTransformer2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/dit_transformer2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DiTTransformer2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/hunyuan_transformer2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HunyuanDiT2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/transformer_temporal/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TransformerTemporalModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/sd3_transformer2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SD3Transformer2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/prior_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PriorTransformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/controlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNetModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/controlnet_sd3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SD3ControlNetModel
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3_3" checked>
        
          
          <label class="md-nav__link" for="__nav_2_3_3" id="__nav_2_3_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Pipelines
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_3_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_3_3">
            <span class="md-nav__icon md-icon"></span>
            Pipelines
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../animatediff/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AnimateDiff
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../blip_diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BLIP-Diffusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../consistency_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Consistency Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../controlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../controlnet_sd3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNet with Stable Diffusion 3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../controlnetxs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNet-XS
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../controlnetxs_sdxl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNet-XS with Stable Diffusion XL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dance_diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dance Diffusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ddim/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DDIM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ddpm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DDPM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../deepfloyd_if/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DeepFloyd IF
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../diffedit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DiffEdit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../dit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DiT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../hunyuandit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hunyuan-DiT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../i2vgenxl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    I2VGen-XL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pix2pix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    InstructPix2Pix
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../kandinsky/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kandinsky 2.1
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../kandinsky_v22/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kandinsky 2.2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../kandinsky3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kandinsky 3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../latent_consistency_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Latent Consistency Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../latent_diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Latent Diffusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../marigold/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Marigold
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pixart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PixArt-Î±
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../pixart_sigma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PixArt-Î£
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../shap_e/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Shap-E
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../stable_cascade/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stable Cascade
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../unclip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    unCLIP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Wuerstchen
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Wuerstchen
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#wurstchen-overview" class="md-nav__link">
    <span class="md-ellipsis">
      WÃ¼rstchen Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#wurstchen-v2-comes-to-diffusers" class="md-nav__link">
    <span class="md-ellipsis">
      WÃ¼rstchen v2 comes to Diffusers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-to-image-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Text-to-Image Generation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#limitations" class="md-nav__link">
    <span class="md-ellipsis">
      Limitations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindone.diffusers.WuerstchenCombinedPipeline" class="md-nav__link">
    <span class="md-ellipsis">
      WuerstchenCombinedPipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="WuerstchenCombinedPipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.WuerstchenCombinedPipeline.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindone.diffusers.WuerstchenPriorPipeline" class="md-nav__link">
    <span class="md-ellipsis">
      WuerstchenPriorPipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="WuerstchenPriorPipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.WuerstchenPriorPipeline.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindone.diffusers.pipelines.wuerstchen.pipeline_wuerstchen_prior.WuerstchenPriorPipelineOutput" class="md-nav__link">
    <span class="md-ellipsis">
      WuerstchenPriorPipelineOutput
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindone.diffusers.WuerstchenDecoderPipeline" class="md-nav__link">
    <span class="md-ellipsis">
      WuerstchenDecoderPipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="WuerstchenDecoderPipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.WuerstchenDecoderPipeline.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#citation" class="md-nav__link">
    <span class="md-ellipsis">
      Citation
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3_4" >
        
          
          <label class="md-nav__link" for="__nav_2_3_4" id="__nav_2_3_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Internal Class
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3_4">
            <span class="md-nav__icon md-icon"></span>
            Internal Class
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../internal_classes_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../attnprocessor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Attention Processor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../activations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom activation functions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../normalization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom Normalization Layer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilities/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Utilities
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../image_processor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VAE Image Processor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../video_processor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Video Processor
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Transformers
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Transformers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Get started
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            Get started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ðŸ¤— Transformers
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PEFT
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            PEFT
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Get started
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            Get started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ðŸ¤— PEFT
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#wurstchen-overview" class="md-nav__link">
    <span class="md-ellipsis">
      WÃ¼rstchen Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#wurstchen-v2-comes-to-diffusers" class="md-nav__link">
    <span class="md-ellipsis">
      WÃ¼rstchen v2 comes to Diffusers
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#text-to-image-generation" class="md-nav__link">
    <span class="md-ellipsis">
      Text-to-Image Generation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#limitations" class="md-nav__link">
    <span class="md-ellipsis">
      Limitations
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindone.diffusers.WuerstchenCombinedPipeline" class="md-nav__link">
    <span class="md-ellipsis">
      WuerstchenCombinedPipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="WuerstchenCombinedPipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.WuerstchenCombinedPipeline.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindone.diffusers.WuerstchenPriorPipeline" class="md-nav__link">
    <span class="md-ellipsis">
      WuerstchenPriorPipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="WuerstchenPriorPipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.WuerstchenPriorPipeline.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindone.diffusers.pipelines.wuerstchen.pipeline_wuerstchen_prior.WuerstchenPriorPipelineOutput" class="md-nav__link">
    <span class="md-ellipsis">
      WuerstchenPriorPipelineOutput
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#mindone.diffusers.WuerstchenDecoderPipeline" class="md-nav__link">
    <span class="md-ellipsis">
      WuerstchenDecoderPipeline
    </span>
  </a>
  
    <nav class="md-nav" aria-label="WuerstchenDecoderPipeline">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.WuerstchenDecoderPipeline.__call__" class="md-nav__link">
    <span class="md-ellipsis">
      __call__
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#citation" class="md-nav__link">
    <span class="md-ellipsis">
      Citation
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/mindspore-lab/mindone/edit/master/docs/diffusers/api/pipelines/wuerstchen.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/mindspore-lab/mindone/raw/master/docs/diffusers/api/pipelines/wuerstchen.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<!--Copyright 2024 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

<h1 id="wurstchen">WÃ¼rstchen<a class="headerlink" href="#wurstchen" title="Permanent link">&para;</a></h1>
<p><img src="https://github.com/dome272/Wuerstchen/assets/61938694/0617c863-165a-43ee-9303-2a17299a0cf9"></p>
<p><a href="https://huggingface.co/papers/2306.00637">Wuerstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models</a> is by Pablo Pernias, Dominic Rampas, Mats L. Richter and Christopher Pal and Marc Aubreville.</p>
<p>The abstract from the paper is:</p>
<p><em>We introduce WÃ¼rstchen, a novel architecture for text-to-image synthesis that combines competitive performance with unprecedented cost-effectiveness for large-scale text-to-image diffusion models. A key contribution of our work is to develop a latent diffusion technique in which we learn a detailed but extremely compact semantic image representation used to guide the diffusion process. This highly compressed representation of an image provides much more detailed guidance compared to latent representations of language and this significantly reduces the computational requirements to achieve state-of-the-art results. Our approach also improves the quality of text-conditioned image generation based on our user preference study. The training requirements of our approach consists of 24,602 A100-GPU hours - compared to Stable Diffusion 2.1's 200,000 GPU hours. Our approach also requires less training data to achieve these results. Furthermore, our compact latent representations allows us to perform inference over twice as fast, slashing the usual costs and carbon footprint of a state-of-the-art (SOTA) diffusion model significantly, without compromising the end performance. In a broader comparison against SOTA models our approach is substantially more efficient and compares favorably in terms of image quality. We believe that this work motivates more emphasis on the prioritization of both performance and computational accessibility.</em></p>
<h2 id="wurstchen-overview">WÃ¼rstchen Overview<a class="headerlink" href="#wurstchen-overview" title="Permanent link">&para;</a></h2>
<p>WÃ¼rstchen is a diffusion model, whose text-conditional model works in a highly compressed latent space of images. Why is this important? Compressing data can reduce computational costs for both training and inference by magnitudes. Training on 1024x1024 images is way more expensive than training on 32x32. Usually, other works make use of a relatively small compression, in the range of 4x - 8x spatial compression. WÃ¼rstchen takes this to an extreme. Through its novel design, we achieve a 42x spatial compression. This was unseen before because common methods fail to faithfully reconstruct detailed images after 16x spatial compression. WÃ¼rstchen employs a two-stage compression, what we call Stage A and Stage B. Stage A is a VQGAN, and Stage B is a Diffusion Autoencoder (more details can be found in the <a href="https://huggingface.co/papers/2306.00637">paper</a>). A third model, Stage C, is learned in that highly compressed latent space. This training requires fractions of the compute used for current top-performing models, while also allowing cheaper and faster inference.</p>
<h2 id="wurstchen-v2-comes-to-diffusers">WÃ¼rstchen v2 comes to Diffusers<a class="headerlink" href="#wurstchen-v2-comes-to-diffusers" title="Permanent link">&para;</a></h2>
<p>After the initial paper release, we have improved numerous things in the architecture, training and sampling, making WÃ¼rstchen competitive to current state-of-the-art models in many ways. We are excited to release this new version together with Diffusers. Here is a list of the improvements.</p>
<ul>
<li>Higher resolution (1024x1024 up to 2048x2048)</li>
<li>Faster inference</li>
<li>Multi Aspect Resolution Sampling</li>
<li>Better quality</li>
</ul>
<p>We are releasing 3 checkpoints for the text-conditional image generation model (Stage C). Those are:</p>
<ul>
<li>v2-base</li>
<li>v2-aesthetic</li>
<li><strong>(default)</strong> v2-interpolated (50% interpolation between v2-base and v2-aesthetic)</li>
</ul>
<p>We recommend using v2-interpolated, as it has a nice touch of both photorealism and aesthetics. Use v2-base for finetunings as it does not have a style bias and use v2-aesthetic for very artistic generations.
A comparison can be seen here:</p>
<p><img src="https://github.com/dome272/Wuerstchen/assets/61938694/2914830f-cbd3-461c-be64-d50734f4b49d" width=500></p>
<h2 id="text-to-image-generation">Text-to-Image Generation<a class="headerlink" href="#text-to-image-generation" title="Permanent link">&para;</a></h2>
<p>For the sake of usability, WÃ¼rstchen can be used with a single pipeline. This pipeline can be used as follows:</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindone.diffusers</span> <span class="kn">import</span> <span class="n">WuerstchenCombinedPipeline</span>
<span class="kn">from</span> <span class="nn">mindone.diffusers.pipelines.wuerstchen</span> <span class="kn">import</span> <span class="n">DEFAULT_STAGE_C_TIMESTEPS</span>

<span class="n">pipe</span> <span class="o">=</span> <span class="n">WuerstchenCombinedPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;warp-ai/wuerstchen&quot;</span><span class="p">,</span>
    <span class="n">mindspore_dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>
<span class="n">caption</span> <span class="o">=</span> <span class="s2">&quot;Anthropomorphic cat dressed as a fire fighter&quot;</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">pipe</span><span class="p">(</span>
    <span class="n">caption</span><span class="p">,</span>
    <span class="n">width</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
    <span class="n">height</span> <span class="o">=</span> <span class="mi">1536</span><span class="p">,</span>
    <span class="n">prior_timesteps</span> <span class="o">=</span> <span class="n">DEFAULT_STAGE_C_TIMESTEPS</span><span class="p">,</span>
    <span class="n">prior_gudiance_scale</span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
    <span class="n">num_images_per_prompt</span> <span class="o">=</span> <span class="mi">2</span><span class="p">,</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div>
<p>For explanation purposes, we can also initialize the two main pipelines of WÃ¼rstchen individually. WÃ¼rstchen consists of 3 stages: Stage C, Stage B, Stage A. They all have different jobs and work only together. When generating text-conditional images, Stage C will first generate the latents in a very compressed latent space. This is what happens in the <code>prior_pipeline</code>. Afterwards, the generated latents will be passed to Stage B, which decompresses the latents into a bigger latent space of a VQGAN. These latents can then be decoded by Stage A, which is a VQGAN, into the pixel-space. Stage B &amp; Stage A are both encapsulated in the <code>decoder_pipeline</code>. For more details, take a look at the <a href="https://arxiv.org/abs/2306.00637">paper</a>.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>
<span class="kn">from</span> <span class="nn">mindone.diffusers</span> <span class="kn">import</span> <span class="n">WuerstchenDecoderPipeline</span><span class="p">,</span> <span class="n">WuerstchenPriorPipeline</span>
<span class="kn">from</span> <span class="nn">mindone.diffusers.pipelines.wuerstchen</span> <span class="kn">import</span> <span class="n">DEFAULT_STAGE_C_TIMESTEPS</span>

<span class="n">dtype</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">float16</span>
<span class="n">num_images_per_prompt</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">prior_pipeline</span> <span class="o">=</span> <span class="n">WuerstchenPriorPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;warp-ai/wuerstchen-prior&quot;</span><span class="p">,</span>
    <span class="n">mindspore_dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>
<span class="n">decoder_pipeline</span> <span class="o">=</span> <span class="n">WuerstchenDecoderPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;warp-ai/wuerstchen&quot;</span><span class="p">,</span>
    <span class="n">mindspore_dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>

<span class="n">caption</span> <span class="o">=</span> <span class="s2">&quot;Anthropomorphic cat dressed as a fire fighter&quot;</span>
<span class="n">negative_prompt</span> <span class="o">=</span> <span class="s2">&quot;&quot;</span>

<span class="n">prior_output</span> <span class="o">=</span> <span class="n">prior_pipeline</span><span class="p">(</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">caption</span><span class="p">,</span>
    <span class="n">height</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
    <span class="n">width</span> <span class="o">=</span> <span class="mi">1536</span><span class="p">,</span>
    <span class="n">timesteps</span> <span class="o">=</span> <span class="n">DEFAULT_STAGE_C_TIMESTEPS</span><span class="p">,</span>
    <span class="n">negative_prompt</span> <span class="o">=</span> <span class="n">negative_prompt</span><span class="p">,</span>
    <span class="n">gudiance_scale</span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
    <span class="n">num_images_per_prompt</span> <span class="o">=</span> <span class="n">num_images_per_prompt</span>
<span class="p">)</span>

<span class="n">decoder_output</span> <span class="o">=</span> <span class="n">decoder_pipeline</span><span class="p">(</span>
    <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">prior_output</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
    <span class="n">prompt</span> <span class="o">=</span> <span class="n">caption</span><span class="p">,</span>
    <span class="n">negative_prompt</span> <span class="o">=</span> <span class="n">negative_prompt</span><span class="p">,</span>
    <span class="n">guidance_scale</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">output_type</span> <span class="o">=</span> <span class="s2">&quot;pil&quot;</span><span class="p">,</span>
<span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">decoder_output</span>
</code></pre></div>
<h2 id="limitations">Limitations<a class="headerlink" href="#limitations" title="Permanent link">&para;</a></h2>
<ul>
<li>Due to the high compression employed by WÃ¼rstchen, generations can lack a good amount
of detail. To our human eye, this is especially noticeable in faces, hands etc.</li>
<li><strong>Images can only be generated in 128-pixel steps</strong>, e.g. the next higher resolution
after 1024x1024 is 1152x1152</li>
<li>The model lacks the ability to render correct text in images</li>
<li>The model often does not achieve photorealism</li>
<li>Difficult compositional prompts are hard for the model</li>
</ul>
<p>The original codebase, as well as experimental ideas, can be found at <a href="https://github.com/dome272/Wuerstchen">dome272/Wuerstchen</a>.</p>


<div class="doc doc-object doc-class">



<h2 id="mindone.diffusers.WuerstchenCombinedPipeline" class="doc doc-heading">
            <code>mindone.diffusers.WuerstchenCombinedPipeline</code>


<a href="#mindone.diffusers.WuerstchenCombinedPipeline" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindone.diffusers.pipelines.pipeline_utils.DiffusionPipeline" href="../overview/#mindone.diffusers.DiffusionPipeline">DiffusionPipeline</a></code></p>


        <p>Combined Pipeline for text-to-image generation using Wuerstchen</p>
<p>This model inherits from [<code>DiffusionPipeline</code>]. Check the superclass documentation for the generic methods the
library implements for all the pipelines (such as downloading or saving, running on a particular device, etc.)</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>tokenizer</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The decoder tokenizer to be used for text inputs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`CLIPTokenizer`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>text_encoder</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The decoder text encoder to be used for text inputs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`CLIPTextModel`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>decoder</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The decoder model to be used for decoder image generation pipeline.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`WuerstchenDiffNeXt`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scheduler</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The scheduler to be used for decoder image generation pipeline.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`DDPMWuerstchenScheduler`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>vqgan</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The VQGAN model to be used for decoder image generation pipeline.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`PaellaVQModel`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prior_tokenizer</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The prior tokenizer to be used for text inputs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`CLIPTokenizer`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prior_text_encoder</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The prior text encoder to be used for text inputs.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`CLIPTextModel`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prior_prior</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The prior model to be used for prior pipeline.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`WuerstchenPrior`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prior_scheduler</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The scheduler to be used for prior pipeline.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`DDPMWuerstchenScheduler`</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>mindone/diffusers/pipelines/wuerstchen/pipeline_wuerstchen_combined.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">WuerstchenCombinedPipeline</span><span class="p">(</span><span class="n">DiffusionPipeline</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Combined Pipeline for text-to-image generation using Wuerstchen</span>

<span class="sd">    This model inherits from [`DiffusionPipeline`]. Check the superclass documentation for the generic methods the</span>
<span class="sd">    library implements for all the pipelines (such as downloading or saving, running on a particular device, etc.)</span>

<span class="sd">    Args:</span>
<span class="sd">        tokenizer (`CLIPTokenizer`):</span>
<span class="sd">            The decoder tokenizer to be used for text inputs.</span>
<span class="sd">        text_encoder (`CLIPTextModel`):</span>
<span class="sd">            The decoder text encoder to be used for text inputs.</span>
<span class="sd">        decoder (`WuerstchenDiffNeXt`):</span>
<span class="sd">            The decoder model to be used for decoder image generation pipeline.</span>
<span class="sd">        scheduler (`DDPMWuerstchenScheduler`):</span>
<span class="sd">            The scheduler to be used for decoder image generation pipeline.</span>
<span class="sd">        vqgan (`PaellaVQModel`):</span>
<span class="sd">            The VQGAN model to be used for decoder image generation pipeline.</span>
<span class="sd">        prior_tokenizer (`CLIPTokenizer`):</span>
<span class="sd">            The prior tokenizer to be used for text inputs.</span>
<span class="sd">        prior_text_encoder (`CLIPTextModel`):</span>
<span class="sd">            The prior text encoder to be used for text inputs.</span>
<span class="sd">        prior_prior (`WuerstchenPrior`):</span>
<span class="sd">            The prior model to be used for prior pipeline.</span>
<span class="sd">        prior_scheduler (`DDPMWuerstchenScheduler`):</span>
<span class="sd">            The scheduler to be used for prior pipeline.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_load_connected_pipes</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">CLIPTokenizer</span><span class="p">,</span>
        <span class="n">text_encoder</span><span class="p">:</span> <span class="n">CLIPTextModel</span><span class="p">,</span>
        <span class="n">decoder</span><span class="p">:</span> <span class="n">WuerstchenDiffNeXt</span><span class="p">,</span>
        <span class="n">scheduler</span><span class="p">:</span> <span class="n">DDPMWuerstchenScheduler</span><span class="p">,</span>
        <span class="n">vqgan</span><span class="p">:</span> <span class="n">PaellaVQModel</span><span class="p">,</span>
        <span class="n">prior_tokenizer</span><span class="p">:</span> <span class="n">CLIPTokenizer</span><span class="p">,</span>
        <span class="n">prior_text_encoder</span><span class="p">:</span> <span class="n">CLIPTextModel</span><span class="p">,</span>
        <span class="n">prior_prior</span><span class="p">:</span> <span class="n">WuerstchenPrior</span><span class="p">,</span>
        <span class="n">prior_scheduler</span><span class="p">:</span> <span class="n">DDPMWuerstchenScheduler</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">register_modules</span><span class="p">(</span>
            <span class="n">text_encoder</span><span class="o">=</span><span class="n">text_encoder</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
            <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
            <span class="n">vqgan</span><span class="o">=</span><span class="n">vqgan</span><span class="p">,</span>
            <span class="n">prior_prior</span><span class="o">=</span><span class="n">prior_prior</span><span class="p">,</span>
            <span class="n">prior_text_encoder</span><span class="o">=</span><span class="n">prior_text_encoder</span><span class="p">,</span>
            <span class="n">prior_tokenizer</span><span class="o">=</span><span class="n">prior_tokenizer</span><span class="p">,</span>
            <span class="n">prior_scheduler</span><span class="o">=</span><span class="n">prior_scheduler</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_pipe</span> <span class="o">=</span> <span class="n">WuerstchenPriorPipeline</span><span class="p">(</span>
            <span class="n">prior</span><span class="o">=</span><span class="n">prior_prior</span><span class="p">,</span>
            <span class="n">text_encoder</span><span class="o">=</span><span class="n">prior_text_encoder</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="n">prior_tokenizer</span><span class="p">,</span>
            <span class="n">scheduler</span><span class="o">=</span><span class="n">prior_scheduler</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_pipe</span> <span class="o">=</span> <span class="n">WuerstchenDecoderPipeline</span><span class="p">(</span>
            <span class="n">text_encoder</span><span class="o">=</span><span class="n">text_encoder</span><span class="p">,</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
            <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
            <span class="n">vqgan</span><span class="o">=</span><span class="n">vqgan</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">enable_xformers_memory_efficient_attention</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">attention_op</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_pipe</span><span class="o">.</span><span class="n">enable_xformers_memory_efficient_attention</span><span class="p">(</span><span class="n">attention_op</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">progress_bar</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">iterable</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_pipe</span><span class="o">.</span><span class="n">progress_bar</span><span class="p">(</span><span class="n">iterable</span><span class="o">=</span><span class="n">iterable</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">total</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_pipe</span><span class="o">.</span><span class="n">progress_bar</span><span class="p">(</span><span class="n">iterable</span><span class="o">=</span><span class="n">iterable</span><span class="p">,</span> <span class="n">total</span><span class="o">=</span><span class="n">total</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">set_progress_bar_config</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prior_pipe</span><span class="o">.</span><span class="n">set_progress_bar_config</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder_pipe</span><span class="o">.</span><span class="n">set_progress_bar_config</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">height</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
        <span class="n">width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
        <span class="n">prior_num_inference_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">60</span><span class="p">,</span>
        <span class="n">prior_timesteps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prior_guidance_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span>
        <span class="n">decoder_timesteps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">decoder_guidance_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">negative_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">negative_prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_images_per_prompt</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">generator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">latents</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;pil&quot;</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">prior_callback_on_step_end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prior_callback_on_step_end_tensor_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latents&quot;</span><span class="p">],</span>
        <span class="n">callback_on_step_end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latents&quot;</span><span class="p">],</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function invoked when calling the pipeline for generation.</span>

<span class="sd">        Args:</span>
<span class="sd">            prompt (`str` or `List[str]`):</span>
<span class="sd">                The prompt or prompts to guide the image generation for the prior and decoder.</span>
<span class="sd">            negative_prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">                The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored</span>
<span class="sd">                if `guidance_scale` is less than `1`).</span>
<span class="sd">            prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">                Pre-generated text embeddings for the prior. Can be used to easily tweak text inputs, *e.g.* prompt</span>
<span class="sd">                weighting. If not provided, text embeddings will be generated from `prompt` input argument.</span>
<span class="sd">            negative_prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">                Pre-generated negative text embeddings for the prior. Can be used to easily tweak text inputs, *e.g.*</span>
<span class="sd">                prompt weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`</span>
<span class="sd">                input argument.</span>
<span class="sd">            num_images_per_prompt (`int`, *optional*, defaults to 1):</span>
<span class="sd">                The number of images to generate per prompt.</span>
<span class="sd">            height (`int`, *optional*, defaults to 512):</span>
<span class="sd">                The height in pixels of the generated image.</span>
<span class="sd">            width (`int`, *optional*, defaults to 512):</span>
<span class="sd">                The width in pixels of the generated image.</span>
<span class="sd">            prior_guidance_scale (`float`, *optional*, defaults to 4.0):</span>
<span class="sd">                Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).</span>
<span class="sd">                `prior_guidance_scale` is defined as `w` of equation 2. of [Imagen</span>
<span class="sd">                Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting</span>
<span class="sd">                `prior_guidance_scale &gt; 1`. Higher guidance scale encourages to generate images that are closely linked</span>
<span class="sd">                to the text `prompt`, usually at the expense of lower image quality.</span>
<span class="sd">            prior_num_inference_steps (`Union[int, Dict[float, int]]`, *optional*, defaults to 60):</span>
<span class="sd">                The number of prior denoising steps. More denoising steps usually lead to a higher quality image at the</span>
<span class="sd">                expense of slower inference. For more specific timestep spacing, you can pass customized</span>
<span class="sd">                `prior_timesteps`</span>
<span class="sd">            num_inference_steps (`int`, *optional*, defaults to 12):</span>
<span class="sd">                The number of decoder denoising steps. More denoising steps usually lead to a higher quality image at</span>
<span class="sd">                the expense of slower inference. For more specific timestep spacing, you can pass customized</span>
<span class="sd">                `timesteps`</span>
<span class="sd">            prior_timesteps (`List[float]`, *optional*):</span>
<span class="sd">                Custom timesteps to use for the denoising process for the prior. If not defined, equal spaced</span>
<span class="sd">                `prior_num_inference_steps` timesteps are used. Must be in descending order.</span>
<span class="sd">            decoder_timesteps (`List[float]`, *optional*):</span>
<span class="sd">                Custom timesteps to use for the denoising process for the decoder. If not defined, equal spaced</span>
<span class="sd">                `num_inference_steps` timesteps are used. Must be in descending order.</span>
<span class="sd">            decoder_guidance_scale (`float`, *optional*, defaults to 0.0):</span>
<span class="sd">                Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).</span>
<span class="sd">                `guidance_scale` is defined as `w` of equation 2. of [Imagen</span>
<span class="sd">                Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale &gt;</span>
<span class="sd">                1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,</span>
<span class="sd">                usually at the expense of lower image quality.</span>
<span class="sd">            generator (`np.random.Generator` or `List[np.random.Generator]`, *optional*):</span>
<span class="sd">                One or a list of [np.random.Generator(s)](https://numpy.org/doc/stable/reference/random/generator.html)</span>
<span class="sd">                to make generation deterministic.</span>
<span class="sd">            latents (`ms.Tensor`, *optional*):</span>
<span class="sd">                Pre-generated noisy latents, sampled from a Gaussian distribution, to be used as inputs for image</span>
<span class="sd">                generation. Can be used to tweak the same generation with different prompts. If not provided, a latents</span>
<span class="sd">                tensor will ge generated by sampling using the supplied random `generator`.</span>
<span class="sd">            output_type (`str`, *optional*, defaults to `&quot;pil&quot;`):</span>
<span class="sd">                The output format of the generate image. Choose between: `&quot;pil&quot;` (`PIL.Image.Image`), `&quot;np&quot;`</span>
<span class="sd">                (`np.array`) or `&quot;ms&quot;` (`ms.Tensor`).</span>
<span class="sd">            return_dict (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                Whether or not to return a [`~pipelines.ImagePipelineOutput`] instead of a plain tuple.</span>
<span class="sd">            prior_callback_on_step_end (`Callable`, *optional*):</span>
<span class="sd">                A function that calls at the end of each denoising steps during the inference. The function is called</span>
<span class="sd">                with the following arguments: `prior_callback_on_step_end(self: DiffusionPipeline, step: int, timestep:</span>
<span class="sd">                int, callback_kwargs: Dict)`.</span>
<span class="sd">            prior_callback_on_step_end_tensor_inputs (`List`, *optional*):</span>
<span class="sd">                The list of tensor inputs for the `prior_callback_on_step_end` function. The tensors specified in the</span>
<span class="sd">                list will be passed as `callback_kwargs` argument. You will only be able to include variables listed in</span>
<span class="sd">                the `._callback_tensor_inputs` attribute of your pipeline class.</span>
<span class="sd">            callback_on_step_end (`Callable`, *optional*):</span>
<span class="sd">                A function that calls at the end of each denoising steps during the inference. The function is called</span>
<span class="sd">                with the following arguments: `callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int,</span>
<span class="sd">                callback_kwargs: Dict)`. `callback_kwargs` will include a list of all tensors as specified by</span>
<span class="sd">                `callback_on_step_end_tensor_inputs`.</span>
<span class="sd">            callback_on_step_end_tensor_inputs (`List`, *optional*):</span>
<span class="sd">                The list of tensor inputs for the `callback_on_step_end` function. The tensors specified in the list</span>
<span class="sd">                will be passed as `callback_kwargs` argument. You will only be able to include variables listed in the</span>
<span class="sd">                `._callback_tensor_inputs` attribute of your pipeline class.</span>

<span class="sd">        Examples:</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`~pipelines.ImagePipelineOutput`] or `tuple` [`~pipelines.ImagePipelineOutput`] if `return_dict` is True,</span>
<span class="sd">            otherwise a `tuple`. When returning a tuple, the first element is a list with the generated images.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">prior_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prior_callback&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">prior_kwargs</span><span class="p">[</span><span class="s2">&quot;callback&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;prior_callback&quot;</span><span class="p">)</span>
            <span class="n">deprecate</span><span class="p">(</span>
                <span class="s2">&quot;prior_callback&quot;</span><span class="p">,</span>
                <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Passing `prior_callback` as an input argument to `__call__` is deprecated, consider use `prior_callback_on_step_end`&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prior_callback_steps&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">deprecate</span><span class="p">(</span>
                <span class="s2">&quot;prior_callback_steps&quot;</span><span class="p">,</span>
                <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Passing `prior_callback_steps` as an input argument to `__call__` is deprecated, consider use `prior_callback_on_step_end`&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">prior_kwargs</span><span class="p">[</span><span class="s2">&quot;callback_steps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;prior_callback_steps&quot;</span><span class="p">)</span>

        <span class="n">prior_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_pipe</span><span class="p">(</span>
            <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span> <span class="k">if</span> <span class="n">prompt_embeds</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">height</span><span class="o">=</span><span class="n">height</span><span class="p">,</span>
            <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span>
            <span class="n">num_inference_steps</span><span class="o">=</span><span class="n">prior_num_inference_steps</span><span class="p">,</span>
            <span class="n">timesteps</span><span class="o">=</span><span class="n">prior_timesteps</span><span class="p">,</span>
            <span class="n">guidance_scale</span><span class="o">=</span><span class="n">prior_guidance_scale</span><span class="p">,</span>
            <span class="n">negative_prompt</span><span class="o">=</span><span class="n">negative_prompt</span> <span class="k">if</span> <span class="n">negative_prompt_embeds</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">prompt_embeds</span><span class="o">=</span><span class="n">prompt_embeds</span><span class="p">,</span>
            <span class="n">negative_prompt_embeds</span><span class="o">=</span><span class="n">negative_prompt_embeds</span><span class="p">,</span>
            <span class="n">num_images_per_prompt</span><span class="o">=</span><span class="n">num_images_per_prompt</span><span class="p">,</span>
            <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span>
            <span class="n">latents</span><span class="o">=</span><span class="n">latents</span><span class="p">,</span>
            <span class="n">output_type</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">callback_on_step_end</span><span class="o">=</span><span class="n">prior_callback_on_step_end</span><span class="p">,</span>
            <span class="n">callback_on_step_end_tensor_inputs</span><span class="o">=</span><span class="n">prior_callback_on_step_end_tensor_inputs</span><span class="p">,</span>
            <span class="o">**</span><span class="n">prior_kwargs</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">prior_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_pipe</span><span class="p">(</span>
            <span class="n">image_embeddings</span><span class="o">=</span><span class="n">image_embeddings</span><span class="p">,</span>
            <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span> <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
            <span class="n">num_inference_steps</span><span class="o">=</span><span class="n">num_inference_steps</span><span class="p">,</span>
            <span class="n">timesteps</span><span class="o">=</span><span class="n">decoder_timesteps</span><span class="p">,</span>
            <span class="n">guidance_scale</span><span class="o">=</span><span class="n">decoder_guidance_scale</span><span class="p">,</span>
            <span class="n">negative_prompt</span><span class="o">=</span><span class="n">negative_prompt</span><span class="p">,</span>
            <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span>
            <span class="n">output_type</span><span class="o">=</span><span class="n">output_type</span><span class="p">,</span>
            <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
            <span class="n">callback_on_step_end</span><span class="o">=</span><span class="n">callback_on_step_end</span><span class="p">,</span>
            <span class="n">callback_on_step_end_tensor_inputs</span><span class="o">=</span><span class="n">callback_on_step_end_tensor_inputs</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindone.diffusers.WuerstchenCombinedPipeline.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindone</span><span class="o">.</span><span class="n">diffusers</span><span class="o">.</span><span class="n">WuerstchenCombinedPipeline</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">prior_num_inference_steps</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">prior_timesteps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_guidance_scale</span><span class="o">=</span><span class="mf">4.0</span><span class="p">,</span> <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">decoder_timesteps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">decoder_guidance_scale</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">negative_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prompt_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">latents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="s1">&#39;pil&#39;</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">prior_callback_on_step_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prior_callback_on_step_end_tensor_inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;latents&#39;</span><span class="p">],</span> <span class="n">callback_on_step_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">callback_on_step_end_tensor_inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;latents&#39;</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindone.diffusers.WuerstchenCombinedPipeline.__call__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Function invoked when calling the pipeline for generation.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The prompt or prompts to guide the image generation for the prior and decoder.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `List[str]`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>negative_prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored
if <code>guidance_scale</code> is less than <code>1</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `List[str]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prompt_embeds</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pre-generated text embeddings for the prior. Can be used to easily tweak text inputs, <em>e.g.</em> prompt
weighting. If not provided, text embeddings will be generated from <code>prompt</code> input argument.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>negative_prompt_embeds</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pre-generated negative text embeddings for the prior. Can be used to easily tweak text inputs, <em>e.g.</em>
prompt weighting. If not provided, negative_prompt_embeds will be generated from <code>negative_prompt</code>
input argument.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_images_per_prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of images to generate per prompt.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 1</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>height</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The height in pixels of the generated image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 512</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>512</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>width</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The width in pixels of the generated image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 512</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>512</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prior_guidance_scale</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Guidance scale as defined in <a href="https://arxiv.org/abs/2207.12598">Classifier-Free Diffusion Guidance</a>.
<code>prior_guidance_scale</code> is defined as <code>w</code> of equation 2. of <a href="https://arxiv.org/pdf/2205.11487.pdf">Imagen
Paper</a>. Guidance scale is enabled by setting
<code>prior_guidance_scale &gt; 1</code>. Higher guidance scale encourages to generate images that are closely linked
to the text <code>prompt</code>, usually at the expense of lower image quality.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 4.0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>4.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prior_num_inference_steps</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of prior denoising steps. More denoising steps usually lead to a higher quality image at the
expense of slower inference. For more specific timestep spacing, you can pass customized
<code>prior_timesteps</code></p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Union[int, Dict[float, int]]`, *optional*, defaults to 60</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>60</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_inference_steps</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of decoder denoising steps. More denoising steps usually lead to a higher quality image at
the expense of slower inference. For more specific timestep spacing, you can pass customized
<code>timesteps</code></p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 12</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>12</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prior_timesteps</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Custom timesteps to use for the denoising process for the prior. If not defined, equal spaced
<code>prior_num_inference_steps</code> timesteps are used. Must be in descending order.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[float]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>decoder_timesteps</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Custom timesteps to use for the denoising process for the decoder. If not defined, equal spaced
<code>num_inference_steps</code> timesteps are used. Must be in descending order.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[float]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>decoder_guidance_scale</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Guidance scale as defined in <a href="https://arxiv.org/abs/2207.12598">Classifier-Free Diffusion Guidance</a>.
<code>guidance_scale</code> is defined as <code>w</code> of equation 2. of <a href="https://arxiv.org/pdf/2205.11487.pdf">Imagen
Paper</a>. Guidance scale is enabled by setting <code>guidance_scale &gt;
1</code>. Higher guidance scale encourages to generate images that are closely linked to the text <code>prompt</code>,
usually at the expense of lower image quality.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0.0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>generator</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>One or a list of <a href="https://numpy.org/doc/stable/reference/random/generator.html">np.random.Generator(s)</a>
to make generation deterministic.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`np.random.Generator` or `List[np.random.Generator]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>latents</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pre-generated noisy latents, sampled from a Gaussian distribution, to be used as inputs for image
generation. Can be used to tweak the same generation with different prompts. If not provided, a latents
tensor will ge generated by sampling using the supplied random <code>generator</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>output_type</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The output format of the generate image. Choose between: <code>"pil"</code> (<code>PIL.Image.Image</code>), <code>"np"</code>
(<code>np.array</code>) or <code>"ms"</code> (<code>ms.Tensor</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;pil&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;pil&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>return_dict</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to return a [<code>~pipelines.ImagePipelineOutput</code>] instead of a plain tuple.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prior_callback_on_step_end</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A function that calls at the end of each denoising steps during the inference. The function is called
with the following arguments: <code>prior_callback_on_step_end(self: DiffusionPipeline, step: int, timestep:
int, callback_kwargs: Dict)</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Callable`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prior_callback_on_step_end_tensor_inputs</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The list of tensor inputs for the <code>prior_callback_on_step_end</code> function. The tensors specified in the
list will be passed as <code>callback_kwargs</code> argument. You will only be able to include variables listed in
the <code>._callback_tensor_inputs</code> attribute of your pipeline class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>[&#39;latents&#39;]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>callback_on_step_end</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A function that calls at the end of each denoising steps during the inference. The function is called
with the following arguments: <code>callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int,
callback_kwargs: Dict)</code>. <code>callback_kwargs</code> will include a list of all tensors as specified by
<code>callback_on_step_end_tensor_inputs</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Callable`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>callback_on_step_end_tensor_inputs</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The list of tensor inputs for the <code>callback_on_step_end</code> function. The tensors specified in the list
will be passed as <code>callback_kwargs</code> argument. You will only be able to include variables listed in the
<code>._callback_tensor_inputs</code> attribute of your pipeline class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>[&#39;latents&#39;]</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>[<code>~pipelines.ImagePipelineOutput</code>] or <code>tuple</code> [<code>~pipelines.ImagePipelineOutput</code>] if <code>return_dict</code> is True,</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>otherwise a <code>tuple</code>. When returning a tuple, the first element is a list with the generated images.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindone/diffusers/pipelines/wuerstchen/pipeline_wuerstchen_combined.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">height</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
    <span class="n">width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span>
    <span class="n">prior_num_inference_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">60</span><span class="p">,</span>
    <span class="n">prior_timesteps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">prior_guidance_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">4.0</span><span class="p">,</span>
    <span class="n">num_inference_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span>
    <span class="n">decoder_timesteps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">decoder_guidance_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">negative_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">negative_prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_images_per_prompt</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">latents</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;pil&quot;</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">prior_callback_on_step_end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">prior_callback_on_step_end_tensor_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latents&quot;</span><span class="p">],</span>
    <span class="n">callback_on_step_end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latents&quot;</span><span class="p">],</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function invoked when calling the pipeline for generation.</span>

<span class="sd">    Args:</span>
<span class="sd">        prompt (`str` or `List[str]`):</span>
<span class="sd">            The prompt or prompts to guide the image generation for the prior and decoder.</span>
<span class="sd">        negative_prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">            The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored</span>
<span class="sd">            if `guidance_scale` is less than `1`).</span>
<span class="sd">        prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">            Pre-generated text embeddings for the prior. Can be used to easily tweak text inputs, *e.g.* prompt</span>
<span class="sd">            weighting. If not provided, text embeddings will be generated from `prompt` input argument.</span>
<span class="sd">        negative_prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">            Pre-generated negative text embeddings for the prior. Can be used to easily tweak text inputs, *e.g.*</span>
<span class="sd">            prompt weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt`</span>
<span class="sd">            input argument.</span>
<span class="sd">        num_images_per_prompt (`int`, *optional*, defaults to 1):</span>
<span class="sd">            The number of images to generate per prompt.</span>
<span class="sd">        height (`int`, *optional*, defaults to 512):</span>
<span class="sd">            The height in pixels of the generated image.</span>
<span class="sd">        width (`int`, *optional*, defaults to 512):</span>
<span class="sd">            The width in pixels of the generated image.</span>
<span class="sd">        prior_guidance_scale (`float`, *optional*, defaults to 4.0):</span>
<span class="sd">            Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).</span>
<span class="sd">            `prior_guidance_scale` is defined as `w` of equation 2. of [Imagen</span>
<span class="sd">            Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting</span>
<span class="sd">            `prior_guidance_scale &gt; 1`. Higher guidance scale encourages to generate images that are closely linked</span>
<span class="sd">            to the text `prompt`, usually at the expense of lower image quality.</span>
<span class="sd">        prior_num_inference_steps (`Union[int, Dict[float, int]]`, *optional*, defaults to 60):</span>
<span class="sd">            The number of prior denoising steps. More denoising steps usually lead to a higher quality image at the</span>
<span class="sd">            expense of slower inference. For more specific timestep spacing, you can pass customized</span>
<span class="sd">            `prior_timesteps`</span>
<span class="sd">        num_inference_steps (`int`, *optional*, defaults to 12):</span>
<span class="sd">            The number of decoder denoising steps. More denoising steps usually lead to a higher quality image at</span>
<span class="sd">            the expense of slower inference. For more specific timestep spacing, you can pass customized</span>
<span class="sd">            `timesteps`</span>
<span class="sd">        prior_timesteps (`List[float]`, *optional*):</span>
<span class="sd">            Custom timesteps to use for the denoising process for the prior. If not defined, equal spaced</span>
<span class="sd">            `prior_num_inference_steps` timesteps are used. Must be in descending order.</span>
<span class="sd">        decoder_timesteps (`List[float]`, *optional*):</span>
<span class="sd">            Custom timesteps to use for the denoising process for the decoder. If not defined, equal spaced</span>
<span class="sd">            `num_inference_steps` timesteps are used. Must be in descending order.</span>
<span class="sd">        decoder_guidance_scale (`float`, *optional*, defaults to 0.0):</span>
<span class="sd">            Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).</span>
<span class="sd">            `guidance_scale` is defined as `w` of equation 2. of [Imagen</span>
<span class="sd">            Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting `guidance_scale &gt;</span>
<span class="sd">            1`. Higher guidance scale encourages to generate images that are closely linked to the text `prompt`,</span>
<span class="sd">            usually at the expense of lower image quality.</span>
<span class="sd">        generator (`np.random.Generator` or `List[np.random.Generator]`, *optional*):</span>
<span class="sd">            One or a list of [np.random.Generator(s)](https://numpy.org/doc/stable/reference/random/generator.html)</span>
<span class="sd">            to make generation deterministic.</span>
<span class="sd">        latents (`ms.Tensor`, *optional*):</span>
<span class="sd">            Pre-generated noisy latents, sampled from a Gaussian distribution, to be used as inputs for image</span>
<span class="sd">            generation. Can be used to tweak the same generation with different prompts. If not provided, a latents</span>
<span class="sd">            tensor will ge generated by sampling using the supplied random `generator`.</span>
<span class="sd">        output_type (`str`, *optional*, defaults to `&quot;pil&quot;`):</span>
<span class="sd">            The output format of the generate image. Choose between: `&quot;pil&quot;` (`PIL.Image.Image`), `&quot;np&quot;`</span>
<span class="sd">            (`np.array`) or `&quot;ms&quot;` (`ms.Tensor`).</span>
<span class="sd">        return_dict (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether or not to return a [`~pipelines.ImagePipelineOutput`] instead of a plain tuple.</span>
<span class="sd">        prior_callback_on_step_end (`Callable`, *optional*):</span>
<span class="sd">            A function that calls at the end of each denoising steps during the inference. The function is called</span>
<span class="sd">            with the following arguments: `prior_callback_on_step_end(self: DiffusionPipeline, step: int, timestep:</span>
<span class="sd">            int, callback_kwargs: Dict)`.</span>
<span class="sd">        prior_callback_on_step_end_tensor_inputs (`List`, *optional*):</span>
<span class="sd">            The list of tensor inputs for the `prior_callback_on_step_end` function. The tensors specified in the</span>
<span class="sd">            list will be passed as `callback_kwargs` argument. You will only be able to include variables listed in</span>
<span class="sd">            the `._callback_tensor_inputs` attribute of your pipeline class.</span>
<span class="sd">        callback_on_step_end (`Callable`, *optional*):</span>
<span class="sd">            A function that calls at the end of each denoising steps during the inference. The function is called</span>
<span class="sd">            with the following arguments: `callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int,</span>
<span class="sd">            callback_kwargs: Dict)`. `callback_kwargs` will include a list of all tensors as specified by</span>
<span class="sd">            `callback_on_step_end_tensor_inputs`.</span>
<span class="sd">        callback_on_step_end_tensor_inputs (`List`, *optional*):</span>
<span class="sd">            The list of tensor inputs for the `callback_on_step_end` function. The tensors specified in the list</span>
<span class="sd">            will be passed as `callback_kwargs` argument. You will only be able to include variables listed in the</span>
<span class="sd">            `._callback_tensor_inputs` attribute of your pipeline class.</span>

<span class="sd">    Examples:</span>

<span class="sd">    Returns:</span>
<span class="sd">        [`~pipelines.ImagePipelineOutput`] or `tuple` [`~pipelines.ImagePipelineOutput`] if `return_dict` is True,</span>
<span class="sd">        otherwise a `tuple`. When returning a tuple, the first element is a list with the generated images.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">prior_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prior_callback&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">prior_kwargs</span><span class="p">[</span><span class="s2">&quot;callback&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;prior_callback&quot;</span><span class="p">)</span>
        <span class="n">deprecate</span><span class="p">(</span>
            <span class="s2">&quot;prior_callback&quot;</span><span class="p">,</span>
            <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Passing `prior_callback` as an input argument to `__call__` is deprecated, consider use `prior_callback_on_step_end`&quot;</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;prior_callback_steps&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">deprecate</span><span class="p">(</span>
            <span class="s2">&quot;prior_callback_steps&quot;</span><span class="p">,</span>
            <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Passing `prior_callback_steps` as an input argument to `__call__` is deprecated, consider use `prior_callback_on_step_end`&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">prior_kwargs</span><span class="p">[</span><span class="s2">&quot;callback_steps&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;prior_callback_steps&quot;</span><span class="p">)</span>

    <span class="n">prior_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior_pipe</span><span class="p">(</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span> <span class="k">if</span> <span class="n">prompt_embeds</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">height</span><span class="o">=</span><span class="n">height</span><span class="p">,</span>
        <span class="n">width</span><span class="o">=</span><span class="n">width</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="o">=</span><span class="n">prior_num_inference_steps</span><span class="p">,</span>
        <span class="n">timesteps</span><span class="o">=</span><span class="n">prior_timesteps</span><span class="p">,</span>
        <span class="n">guidance_scale</span><span class="o">=</span><span class="n">prior_guidance_scale</span><span class="p">,</span>
        <span class="n">negative_prompt</span><span class="o">=</span><span class="n">negative_prompt</span> <span class="k">if</span> <span class="n">negative_prompt_embeds</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="o">=</span><span class="n">prompt_embeds</span><span class="p">,</span>
        <span class="n">negative_prompt_embeds</span><span class="o">=</span><span class="n">negative_prompt_embeds</span><span class="p">,</span>
        <span class="n">num_images_per_prompt</span><span class="o">=</span><span class="n">num_images_per_prompt</span><span class="p">,</span>
        <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span>
        <span class="n">latents</span><span class="o">=</span><span class="n">latents</span><span class="p">,</span>
        <span class="n">output_type</span><span class="o">=</span><span class="s2">&quot;ms&quot;</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">callback_on_step_end</span><span class="o">=</span><span class="n">prior_callback_on_step_end</span><span class="p">,</span>
        <span class="n">callback_on_step_end_tensor_inputs</span><span class="o">=</span><span class="n">prior_callback_on_step_end_tensor_inputs</span><span class="p">,</span>
        <span class="o">**</span><span class="n">prior_kwargs</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">prior_outputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder_pipe</span><span class="p">(</span>
        <span class="n">image_embeddings</span><span class="o">=</span><span class="n">image_embeddings</span><span class="p">,</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span> <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="s2">&quot;&quot;</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="o">=</span><span class="n">num_inference_steps</span><span class="p">,</span>
        <span class="n">timesteps</span><span class="o">=</span><span class="n">decoder_timesteps</span><span class="p">,</span>
        <span class="n">guidance_scale</span><span class="o">=</span><span class="n">decoder_guidance_scale</span><span class="p">,</span>
        <span class="n">negative_prompt</span><span class="o">=</span><span class="n">negative_prompt</span><span class="p">,</span>
        <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span>
        <span class="n">output_type</span><span class="o">=</span><span class="n">output_type</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="o">=</span><span class="n">return_dict</span><span class="p">,</span>
        <span class="n">callback_on_step_end</span><span class="o">=</span><span class="n">callback_on_step_end</span><span class="p">,</span>
        <span class="n">callback_on_step_end_tensor_inputs</span><span class="o">=</span><span class="n">callback_on_step_end_tensor_inputs</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">outputs</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindone.diffusers.WuerstchenPriorPipeline" class="doc doc-heading">
            <code>mindone.diffusers.WuerstchenPriorPipeline</code>


<a href="#mindone.diffusers.WuerstchenPriorPipeline" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindone.diffusers.pipelines.pipeline_utils.DiffusionPipeline" href="../overview/#mindone.diffusers.DiffusionPipeline">DiffusionPipeline</a></code>, <code><a class="autorefs autorefs-internal" title="mindone.diffusers.loaders.LoraLoaderMixin" href="../../loaders/lora/#mindone.diffusers.loaders.lora.LoraLoaderMixin">LoraLoaderMixin</a></code></p>


        <p>Pipeline for generating image prior for Wuerstchen.</p>
<p>This model inherits from [<code>DiffusionPipeline</code>]. Check the superclass documentation for the generic methods the
library implements for all the pipelines (such as downloading or saving, running on a particular device, etc.)</p>


<details class="the-pipeline-also-inherits-the-following-loading-methods" open>
  <summary>The pipeline also inherits the following loading methods</summary>
  <ul>
<li>[<code>~loaders.LoraLoaderMixin.load_lora_weights</code>] for loading LoRA weights</li>
<li>[<code>~loaders.LoraLoaderMixin.save_lora_weights</code>] for saving LoRA weights</li>
</ul>
</details>

<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>prior</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The canonical unCLIP prior to approximate the image embedding from the text embedding.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`Prior`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>text_encoder</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Frozen text-encoder.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`CLIPTextModelWithProjection`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>tokenizer</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Tokenizer of class
<a href="https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer">CLIPTokenizer</a>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`CLIPTokenizer`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scheduler</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A scheduler to be used in combination with <code>prior</code> to generate image embedding.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`DDPMWuerstchenScheduler`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>latent_mean</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Mean value for latent diffusers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>&#39;float&#39;, *optional*, defaults to 42.0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>42.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>latent_std</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Standard value for latent diffusers.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>&#39;float&#39;, *optional*, defaults to 1.0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>resolution_multiple</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Default resolution for multiple images generated.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>&#39;float&#39;, *optional*, defaults to 42.67</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>42.67</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>mindone/diffusers/pipelines/wuerstchen/pipeline_wuerstchen_prior.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">WuerstchenPriorPipeline</span><span class="p">(</span><span class="n">DiffusionPipeline</span><span class="p">,</span> <span class="n">LoraLoaderMixin</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Pipeline for generating image prior for Wuerstchen.</span>

<span class="sd">    This model inherits from [`DiffusionPipeline`]. Check the superclass documentation for the generic methods the</span>
<span class="sd">    library implements for all the pipelines (such as downloading or saving, running on a particular device, etc.)</span>

<span class="sd">    The pipeline also inherits the following loading methods:</span>
<span class="sd">        - [`~loaders.LoraLoaderMixin.load_lora_weights`] for loading LoRA weights</span>
<span class="sd">        - [`~loaders.LoraLoaderMixin.save_lora_weights`] for saving LoRA weights</span>

<span class="sd">    Args:</span>
<span class="sd">        prior ([`Prior`]):</span>
<span class="sd">            The canonical unCLIP prior to approximate the image embedding from the text embedding.</span>
<span class="sd">        text_encoder ([`CLIPTextModelWithProjection`]):</span>
<span class="sd">            Frozen text-encoder.</span>
<span class="sd">        tokenizer (`CLIPTokenizer`):</span>
<span class="sd">            Tokenizer of class</span>
<span class="sd">            [CLIPTokenizer](https://huggingface.co/docs/transformers/v4.21.0/en/model_doc/clip#transformers.CLIPTokenizer).</span>
<span class="sd">        scheduler ([`DDPMWuerstchenScheduler`]):</span>
<span class="sd">            A scheduler to be used in combination with `prior` to generate image embedding.</span>
<span class="sd">        latent_mean (&#39;float&#39;, *optional*, defaults to 42.0):</span>
<span class="sd">            Mean value for latent diffusers.</span>
<span class="sd">        latent_std (&#39;float&#39;, *optional*, defaults to 1.0):</span>
<span class="sd">            Standard value for latent diffusers.</span>
<span class="sd">        resolution_multiple (&#39;float&#39;, *optional*, defaults to 42.67):</span>
<span class="sd">            Default resolution for multiple images generated.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">unet_name</span> <span class="o">=</span> <span class="s2">&quot;prior&quot;</span>
    <span class="n">text_encoder_name</span> <span class="o">=</span> <span class="s2">&quot;text_encoder&quot;</span>
    <span class="n">model_cpu_offload_seq</span> <span class="o">=</span> <span class="s2">&quot;text_encoder-&gt;prior&quot;</span>
    <span class="n">_callback_tensor_inputs</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latents&quot;</span><span class="p">,</span> <span class="s2">&quot;text_encoder_hidden_states&quot;</span><span class="p">,</span> <span class="s2">&quot;negative_prompt_embeds&quot;</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">CLIPTokenizer</span><span class="p">,</span>
        <span class="n">text_encoder</span><span class="p">:</span> <span class="n">CLIPTextModel</span><span class="p">,</span>
        <span class="n">prior</span><span class="p">:</span> <span class="n">WuerstchenPrior</span><span class="p">,</span>
        <span class="n">scheduler</span><span class="p">:</span> <span class="n">DDPMWuerstchenScheduler</span><span class="p">,</span>
        <span class="n">latent_mean</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">42.0</span><span class="p">,</span>
        <span class="n">latent_std</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">resolution_multiple</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">42.67</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_modules</span><span class="p">(</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">text_encoder</span><span class="o">=</span><span class="n">text_encoder</span><span class="p">,</span>
            <span class="n">prior</span><span class="o">=</span><span class="n">prior</span><span class="p">,</span>
            <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_to_config</span><span class="p">(</span><span class="n">latent_mean</span><span class="o">=</span><span class="n">latent_mean</span><span class="p">,</span> <span class="n">latent_std</span><span class="o">=</span><span class="n">latent_std</span><span class="p">,</span> <span class="n">resolution_multiple</span><span class="o">=</span><span class="n">resolution_multiple</span><span class="p">)</span>

    <span class="c1"># Copied from diffusers.pipelines.unclip.pipeline_unclip.UnCLIPPipeline.prepare_latents</span>
    <span class="k">def</span> <span class="nf">prepare_latents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">latents</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">latents</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">latents</span> <span class="o">=</span> <span class="n">randn_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">latents</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">shape</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected latents shape, got </span><span class="si">{</span><span class="n">latents</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, expected </span><span class="si">{</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span> <span class="o">*</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">init_noise_sigma</span>
        <span class="k">return</span> <span class="n">latents</span>

    <span class="k">def</span> <span class="nf">encode_prompt</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_images_per_prompt</span><span class="p">,</span>
        <span class="n">do_classifier_free_guidance</span><span class="p">,</span>
        <span class="n">prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">negative_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">negative_prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">prompt_embeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># get prompt text embeddings</span>
            <span class="n">text_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
                <span class="n">prompt</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">,</span>
                <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">text_input_ids</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">text_inputs</span><span class="o">.</span><span class="n">input_ids</span><span class="p">)</span>
            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">text_inputs</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">)</span>

            <span class="n">untruncated_ids</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;longest&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">untruncated_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">text_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">ops</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">text_input_ids</span><span class="p">,</span> <span class="n">untruncated_ids</span><span class="p">):</span>
                <span class="n">removed_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">untruncated_ids</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
                <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;The following part of your input was truncated because CLIP can only handle sequences up to&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="si">}</span><span class="s2"> tokens: </span><span class="si">{</span><span class="n">removed_text</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
                <span class="n">text_input_ids</span> <span class="o">=</span> <span class="n">text_input_ids</span><span class="p">[:,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">]</span>
                <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">[:,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">]</span>

            <span class="n">text_encoder_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span><span class="n">text_input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
            <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">text_encoder_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">prompt_embeds</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">negative_prompt_embeds</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">do_classifier_free_guidance</span><span class="p">:</span>
            <span class="n">uncond_tokens</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">negative_prompt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span>
            <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;`negative_prompt` should be the same type to `prompt`, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">)</span><span class="si">}</span><span class="s2"> !=&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">negative_prompt</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;`negative_prompt`: </span><span class="si">{</span><span class="n">negative_prompt</span><span class="si">}</span><span class="s2"> has batch size </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">, but `prompt`:&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2"> has batch size </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">. Please make sure that passed `negative_prompt` matches&quot;</span>
                    <span class="s2">&quot; the batch size of `prompt`.&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="n">negative_prompt</span>

            <span class="n">uncond_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
                <span class="n">uncond_tokens</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">,</span>
                <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">negative_prompt_embeds_text_encoder_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span>
                <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">uncond_input</span><span class="o">.</span><span class="n">input_ids</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">uncond_input</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds_text_encoder_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">do_classifier_free_guidance</span><span class="p">:</span>
            <span class="c1"># duplicate unconditional embeddings for each generation per prompt, using mps friendly method</span>
            <span class="n">seq_len</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">tile</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
            <span class="c1"># done duplicates</span>

        <span class="k">return</span> <span class="n">prompt_embeds</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span>

    <span class="k">def</span> <span class="nf">check_inputs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">,</span>
        <span class="n">negative_prompt</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="p">,</span>
        <span class="n">do_classifier_free_guidance</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">negative_prompt_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">prompt_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Cannot forward both `prompt`: </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2"> and `prompt_embeds`: </span><span class="si">{</span><span class="n">prompt_embeds</span><span class="si">}</span><span class="s2">. Please make sure to&quot;</span>
                <span class="s2">&quot; only forward one of the two.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">prompt_embeds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;Provide either `prompt` or `prompt_embeds`. Cannot leave both `prompt` and `prompt_embeds` undefined.&quot;</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`prompt` has to be of type `str` or `list` but is </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">negative_prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">negative_prompt_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Cannot forward both `negative_prompt`: </span><span class="si">{</span><span class="n">negative_prompt</span><span class="si">}</span><span class="s2"> and `negative_prompt_embeds`:&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">negative_prompt_embeds</span><span class="si">}</span><span class="s2">. Please make sure to only forward one of the two.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">prompt_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">negative_prompt_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;`prompt_embeds` and `negative_prompt_embeds` must have the same shape when passed directly, but&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; got: `prompt_embeds` </span><span class="si">{</span><span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2"> != `negative_prompt_embeds`&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">negative_prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_inference_steps</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;num_inference_steps&#39; must be of type &#39;int&#39;, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">num_inference_steps</span><span class="p">)</span><span class="si">}</span><span class="se">\</span>
<span class="s2">                           In Case you want to provide explicit timesteps, please use the &#39;timesteps&#39; argument.&quot;</span>
            <span class="p">)</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">guidance_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_guidance_scale</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">do_classifier_free_guidance</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_guidance_scale</span> <span class="o">&gt;</span> <span class="mi">1</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_timesteps</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_timesteps</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">height</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
        <span class="n">width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">60</span><span class="p">,</span>
        <span class="n">timesteps</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">guidance_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">8.0</span><span class="p">,</span>
        <span class="n">negative_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">negative_prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_images_per_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">generator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">latents</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;ms&quot;</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">callback_on_step_end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latents&quot;</span><span class="p">],</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function invoked when calling the pipeline for generation.</span>

<span class="sd">        Args:</span>
<span class="sd">            prompt (`str` or `List[str]`):</span>
<span class="sd">                The prompt or prompts to guide the image generation.</span>
<span class="sd">            height (`int`, *optional*, defaults to 1024):</span>
<span class="sd">                The height in pixels of the generated image.</span>
<span class="sd">            width (`int`, *optional*, defaults to 1024):</span>
<span class="sd">                The width in pixels of the generated image.</span>
<span class="sd">            num_inference_steps (`int`, *optional*, defaults to 60):</span>
<span class="sd">                The number of denoising steps. More denoising steps usually lead to a higher quality image at the</span>
<span class="sd">                expense of slower inference.</span>
<span class="sd">            timesteps (`List[int]`, *optional*):</span>
<span class="sd">                Custom timesteps to use for the denoising process. If not defined, equal spaced `num_inference_steps`</span>
<span class="sd">                timesteps are used. Must be in descending order.</span>
<span class="sd">            guidance_scale (`float`, *optional*, defaults to 8.0):</span>
<span class="sd">                Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).</span>
<span class="sd">                `decoder_guidance_scale` is defined as `w` of equation 2. of [Imagen</span>
<span class="sd">                Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting</span>
<span class="sd">                `decoder_guidance_scale &gt; 1`. Higher guidance scale encourages to generate images that are closely</span>
<span class="sd">                linked to the text `prompt`, usually at the expense of lower image quality.</span>
<span class="sd">            negative_prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">                The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored</span>
<span class="sd">                if `decoder_guidance_scale` is less than `1`).</span>
<span class="sd">            prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">                Pre-generated text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not</span>
<span class="sd">                provided, text embeddings will be generated from `prompt` input argument.</span>
<span class="sd">            negative_prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">                Pre-generated negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt</span>
<span class="sd">                weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt` input</span>
<span class="sd">                argument.</span>
<span class="sd">            num_images_per_prompt (`int`, *optional*, defaults to 1):</span>
<span class="sd">                The number of images to generate per prompt.</span>
<span class="sd">            generator (`np.random.Generator` or `List[np.random.Generator]`, *optional*):</span>
<span class="sd">                One or a list of [np.random.Generator(s)](https://numpy.org/doc/stable/reference/random/generator.html)</span>
<span class="sd">                to make generation deterministic.</span>
<span class="sd">            latents (`ms.Tensor`, *optional*):</span>
<span class="sd">                Pre-generated noisy latents, sampled from a Gaussian distribution, to be used as inputs for image</span>
<span class="sd">                generation. Can be used to tweak the same generation with different prompts. If not provided, a latents</span>
<span class="sd">                tensor will ge generated by sampling using the supplied random `generator`.</span>
<span class="sd">            output_type (`str`, *optional*, defaults to `&quot;pil&quot;`):</span>
<span class="sd">                The output format of the generate image. Choose between: `&quot;pil&quot;` (`PIL.Image.Image`), `&quot;np&quot;`</span>
<span class="sd">                (`np.array`) or `&quot;ms&quot;` (`ms.Tensor`).</span>
<span class="sd">            return_dict (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                Whether or not to return a [`~pipelines.ImagePipelineOutput`] instead of a plain tuple.</span>
<span class="sd">            callback_on_step_end (`Callable`, *optional*):</span>
<span class="sd">                A function that calls at the end of each denoising steps during the inference. The function is called</span>
<span class="sd">                with the following arguments: `callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int,</span>
<span class="sd">                callback_kwargs: Dict)`. `callback_kwargs` will include a list of all tensors as specified by</span>
<span class="sd">                `callback_on_step_end_tensor_inputs`.</span>
<span class="sd">            callback_on_step_end_tensor_inputs (`List`, *optional*):</span>
<span class="sd">                The list of tensor inputs for the `callback_on_step_end` function. The tensors specified in the list</span>
<span class="sd">                will be passed as `callback_kwargs` argument. You will only be able to include variables listed in the</span>
<span class="sd">                `._callback_tensor_inputs` attribute of your pipeline class.</span>

<span class="sd">        Examples:</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`~pipelines.WuerstchenPriorPipelineOutput`] or `tuple` [`~pipelines.WuerstchenPriorPipelineOutput`] if</span>
<span class="sd">            `return_dict` is True, otherwise a `tuple`. When returning a tuple, the first element is a list with the</span>
<span class="sd">            generated image embeddings.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">callback</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;callback&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">callback_steps</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;callback_steps&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">deprecate</span><span class="p">(</span>
                <span class="s2">&quot;callback&quot;</span><span class="p">,</span>
                <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Passing `callback` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">callback_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">deprecate</span><span class="p">(</span>
                <span class="s2">&quot;callback_steps&quot;</span><span class="p">,</span>
                <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Passing `callback_steps` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">callback_on_step_end_tensor_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span>
            <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">callback_on_step_end_tensor_inputs</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`callback_on_step_end_tensor_inputs` has to be in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but found </span><span class="si">{</span><span class="p">[</span><span class="n">k</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">callback_on_step_end_tensor_inputs</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># 0. Define commonly used variables</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_guidance_scale</span> <span class="o">=</span> <span class="n">guidance_scale</span>
        <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="c1"># 1. Check inputs. Raise error if not correct</span>
        <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="p">[</span><span class="n">prompt</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;prompt&#39; must be of type &#39;list&#39; or &#39;str&#39;, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">negative_prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">negative_prompt</span> <span class="o">=</span> <span class="p">[</span><span class="n">negative_prompt</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;&#39;negative_prompt&#39; must be of type &#39;list&#39; or &#39;str&#39;, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">check_inputs</span><span class="p">(</span>
            <span class="n">prompt</span><span class="p">,</span>
            <span class="n">negative_prompt</span><span class="p">,</span>
            <span class="n">num_inference_steps</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">,</span>
            <span class="n">prompt_embeds</span><span class="o">=</span><span class="n">prompt_embeds</span><span class="p">,</span>
            <span class="n">negative_prompt_embeds</span><span class="o">=</span><span class="n">negative_prompt_embeds</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># 2. Encode caption</span>
        <span class="n">prompt_embeds</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_prompt</span><span class="p">(</span>
            <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
            <span class="n">num_images_per_prompt</span><span class="o">=</span><span class="n">num_images_per_prompt</span><span class="p">,</span>
            <span class="n">do_classifier_free_guidance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">,</span>
            <span class="n">negative_prompt</span><span class="o">=</span><span class="n">negative_prompt</span><span class="p">,</span>
            <span class="n">prompt_embeds</span><span class="o">=</span><span class="n">prompt_embeds</span><span class="p">,</span>
            <span class="n">negative_prompt_embeds</span><span class="o">=</span><span class="n">negative_prompt_embeds</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># For classifier free guidance, we need to do two forward passes.</span>
        <span class="c1"># Here we concatenate the unconditional and text embeddings into a single batch</span>
        <span class="c1"># to avoid doing two forward passes</span>
        <span class="n">text_encoder_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">prompt_embeds</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span><span class="p">])</span> <span class="k">if</span> <span class="n">negative_prompt_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">prompt_embeds</span>
        <span class="p">)</span>

        <span class="c1"># 3. Determine latent shape of image embeddings</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="n">text_encoder_hidden_states</span><span class="o">.</span><span class="n">dtype</span>
        <span class="n">latent_height</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="n">height</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">resolution_multiple</span><span class="p">)</span>
        <span class="n">latent_width</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="n">width</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">resolution_multiple</span><span class="p">)</span>
        <span class="n">num_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">c_in</span>
        <span class="n">effnet_features_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_images_per_prompt</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">latent_height</span><span class="p">,</span> <span class="n">latent_width</span><span class="p">)</span>

        <span class="c1"># 4. Prepare and set timesteps</span>
        <span class="k">if</span> <span class="n">timesteps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">set_timesteps</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">timesteps</span><span class="p">)</span>
            <span class="n">timesteps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">timesteps</span>
            <span class="n">num_inference_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">set_timesteps</span><span class="p">(</span><span class="n">num_inference_steps</span><span class="p">)</span>
            <span class="n">timesteps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">timesteps</span>

        <span class="c1"># 5. Prepare latents</span>
        <span class="n">latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_latents</span><span class="p">(</span><span class="n">effnet_features_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">latents</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">)</span>

        <span class="c1"># 6. Run denoising loop</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_timesteps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">progress_bar</span><span class="p">(</span><span class="n">timesteps</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])):</span>
            <span class="n">ratio</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">((</span><span class="n">latents</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

            <span class="c1"># 7. Denoise image embeddings</span>
            <span class="n">predicted_image_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior</span><span class="p">(</span>
                <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">latents</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span> <span class="k">else</span> <span class="n">latents</span><span class="p">,</span>
                <span class="n">r</span><span class="o">=</span><span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">ratio</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span> <span class="k">else</span> <span class="n">ratio</span><span class="p">,</span>
                <span class="n">c</span><span class="o">=</span><span class="n">text_encoder_hidden_states</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># 8. Check for classifier free guidance and apply it</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">:</span>
                <span class="n">predicted_image_embedding_text</span><span class="p">,</span> <span class="n">predicted_image_embedding_uncond</span> <span class="o">=</span> <span class="n">predicted_image_embedding</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">predicted_image_embedding</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">lerp</span><span class="p">(</span>
                    <span class="n">predicted_image_embedding_uncond</span><span class="p">,</span>
                    <span class="n">predicted_image_embedding_text</span><span class="p">,</span>
                    <span class="n">ms</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">guidance_scale</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">predicted_image_embedding_text</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
                <span class="p">)</span>

            <span class="c1"># 9. Renoise latents to next timestep</span>
            <span class="n">latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span>
                <span class="n">model_output</span><span class="o">=</span><span class="n">predicted_image_embedding</span><span class="p">,</span>
                <span class="n">timestep</span><span class="o">=</span><span class="n">ratio</span><span class="p">,</span>
                <span class="n">sample</span><span class="o">=</span><span class="n">latents</span><span class="p">,</span>
                <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span>
            <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">callback_on_step_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">callback_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span>
                    <span class="n">callback_kwargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">locals</span><span class="p">()[</span><span class="n">k</span><span class="p">]</span>
                <span class="n">callback_outputs</span> <span class="o">=</span> <span class="n">callback_on_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">callback_kwargs</span><span class="p">)</span>

                <span class="n">latents</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;latents&quot;</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span>
                <span class="n">text_encoder_hidden_states</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
                    <span class="s2">&quot;text_encoder_hidden_states&quot;</span><span class="p">,</span> <span class="n">text_encoder_hidden_states</span>
                <span class="p">)</span>
                <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;negative_prompt_embeds&quot;</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="n">callback_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">step_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">,</span> <span class="s2">&quot;order&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">callback</span><span class="p">(</span><span class="n">step_idx</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span>

        <span class="c1"># 10. Denormalize the latents</span>
        <span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">latent_mean</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">latent_std</span>

        <span class="k">if</span> <span class="n">output_type</span> <span class="o">==</span> <span class="s2">&quot;np&quot;</span><span class="p">:</span>
            <span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">latents</span><span class="p">,)</span>

        <span class="k">return</span> <span class="n">WuerstchenPriorPipelineOutput</span><span class="p">(</span><span class="n">latents</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindone.diffusers.WuerstchenPriorPipeline.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindone</span><span class="o">.</span><span class="n">diffusers</span><span class="o">.</span><span class="n">WuerstchenPriorPipeline</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">guidance_scale</span><span class="o">=</span><span class="mf">8.0</span><span class="p">,</span> <span class="n">negative_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">prompt_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">latents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="s1">&#39;ms&#39;</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">callback_on_step_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">callback_on_step_end_tensor_inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;latents&#39;</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindone.diffusers.WuerstchenPriorPipeline.__call__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Function invoked when calling the pipeline for generation.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The prompt or prompts to guide the image generation.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `List[str]`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>height</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The height in pixels of the generated image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 1024</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1024</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>width</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The width in pixels of the generated image.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 1024</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1024</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_inference_steps</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of denoising steps. More denoising steps usually lead to a higher quality image at the
expense of slower inference.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 60</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>60</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>timesteps</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Custom timesteps to use for the denoising process. If not defined, equal spaced <code>num_inference_steps</code>
timesteps are used. Must be in descending order.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[int]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>guidance_scale</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Guidance scale as defined in <a href="https://arxiv.org/abs/2207.12598">Classifier-Free Diffusion Guidance</a>.
<code>decoder_guidance_scale</code> is defined as <code>w</code> of equation 2. of <a href="https://arxiv.org/pdf/2205.11487.pdf">Imagen
Paper</a>. Guidance scale is enabled by setting
<code>decoder_guidance_scale &gt; 1</code>. Higher guidance scale encourages to generate images that are closely
linked to the text <code>prompt</code>, usually at the expense of lower image quality.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 8.0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>8.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>negative_prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored
if <code>decoder_guidance_scale</code> is less than <code>1</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `List[str]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prompt_embeds</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pre-generated text embeddings. Can be used to easily tweak text inputs, <em>e.g.</em> prompt weighting. If not
provided, text embeddings will be generated from <code>prompt</code> input argument.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>negative_prompt_embeds</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pre-generated negative text embeddings. Can be used to easily tweak text inputs, <em>e.g.</em> prompt
weighting. If not provided, negative_prompt_embeds will be generated from <code>negative_prompt</code> input
argument.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_images_per_prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of images to generate per prompt.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 1</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>generator</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>One or a list of <a href="https://numpy.org/doc/stable/reference/random/generator.html">np.random.Generator(s)</a>
to make generation deterministic.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`np.random.Generator` or `List[np.random.Generator]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>latents</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pre-generated noisy latents, sampled from a Gaussian distribution, to be used as inputs for image
generation. Can be used to tweak the same generation with different prompts. If not provided, a latents
tensor will ge generated by sampling using the supplied random <code>generator</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>output_type</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The output format of the generate image. Choose between: <code>"pil"</code> (<code>PIL.Image.Image</code>), <code>"np"</code>
(<code>np.array</code>) or <code>"ms"</code> (<code>ms.Tensor</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;pil&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;ms&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>return_dict</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to return a [<code>~pipelines.ImagePipelineOutput</code>] instead of a plain tuple.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>callback_on_step_end</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A function that calls at the end of each denoising steps during the inference. The function is called
with the following arguments: <code>callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int,
callback_kwargs: Dict)</code>. <code>callback_kwargs</code> will include a list of all tensors as specified by
<code>callback_on_step_end_tensor_inputs</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Callable`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>callback_on_step_end_tensor_inputs</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The list of tensor inputs for the <code>callback_on_step_end</code> function. The tensors specified in the list
will be passed as <code>callback_kwargs</code> argument. You will only be able to include variables listed in the
<code>._callback_tensor_inputs</code> attribute of your pipeline class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>[&#39;latents&#39;]</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>[<code>~pipelines.WuerstchenPriorPipelineOutput</code>] or <code>tuple</code> [<code>~pipelines.WuerstchenPriorPipelineOutput</code>] if</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p><code>return_dict</code> is True, otherwise a <code>tuple</code>. When returning a tuple, the first element is a list with the</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>generated image embeddings.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindone/diffusers/pipelines/wuerstchen/pipeline_wuerstchen_prior.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">height</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
    <span class="n">width</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
    <span class="n">num_inference_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">60</span><span class="p">,</span>
    <span class="n">timesteps</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">guidance_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">8.0</span><span class="p">,</span>
    <span class="n">negative_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">negative_prompt_embeds</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_images_per_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">latents</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;ms&quot;</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">callback_on_step_end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latents&quot;</span><span class="p">],</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function invoked when calling the pipeline for generation.</span>

<span class="sd">    Args:</span>
<span class="sd">        prompt (`str` or `List[str]`):</span>
<span class="sd">            The prompt or prompts to guide the image generation.</span>
<span class="sd">        height (`int`, *optional*, defaults to 1024):</span>
<span class="sd">            The height in pixels of the generated image.</span>
<span class="sd">        width (`int`, *optional*, defaults to 1024):</span>
<span class="sd">            The width in pixels of the generated image.</span>
<span class="sd">        num_inference_steps (`int`, *optional*, defaults to 60):</span>
<span class="sd">            The number of denoising steps. More denoising steps usually lead to a higher quality image at the</span>
<span class="sd">            expense of slower inference.</span>
<span class="sd">        timesteps (`List[int]`, *optional*):</span>
<span class="sd">            Custom timesteps to use for the denoising process. If not defined, equal spaced `num_inference_steps`</span>
<span class="sd">            timesteps are used. Must be in descending order.</span>
<span class="sd">        guidance_scale (`float`, *optional*, defaults to 8.0):</span>
<span class="sd">            Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).</span>
<span class="sd">            `decoder_guidance_scale` is defined as `w` of equation 2. of [Imagen</span>
<span class="sd">            Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting</span>
<span class="sd">            `decoder_guidance_scale &gt; 1`. Higher guidance scale encourages to generate images that are closely</span>
<span class="sd">            linked to the text `prompt`, usually at the expense of lower image quality.</span>
<span class="sd">        negative_prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">            The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored</span>
<span class="sd">            if `decoder_guidance_scale` is less than `1`).</span>
<span class="sd">        prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">            Pre-generated text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt weighting. If not</span>
<span class="sd">            provided, text embeddings will be generated from `prompt` input argument.</span>
<span class="sd">        negative_prompt_embeds (`ms.Tensor`, *optional*):</span>
<span class="sd">            Pre-generated negative text embeddings. Can be used to easily tweak text inputs, *e.g.* prompt</span>
<span class="sd">            weighting. If not provided, negative_prompt_embeds will be generated from `negative_prompt` input</span>
<span class="sd">            argument.</span>
<span class="sd">        num_images_per_prompt (`int`, *optional*, defaults to 1):</span>
<span class="sd">            The number of images to generate per prompt.</span>
<span class="sd">        generator (`np.random.Generator` or `List[np.random.Generator]`, *optional*):</span>
<span class="sd">            One or a list of [np.random.Generator(s)](https://numpy.org/doc/stable/reference/random/generator.html)</span>
<span class="sd">            to make generation deterministic.</span>
<span class="sd">        latents (`ms.Tensor`, *optional*):</span>
<span class="sd">            Pre-generated noisy latents, sampled from a Gaussian distribution, to be used as inputs for image</span>
<span class="sd">            generation. Can be used to tweak the same generation with different prompts. If not provided, a latents</span>
<span class="sd">            tensor will ge generated by sampling using the supplied random `generator`.</span>
<span class="sd">        output_type (`str`, *optional*, defaults to `&quot;pil&quot;`):</span>
<span class="sd">            The output format of the generate image. Choose between: `&quot;pil&quot;` (`PIL.Image.Image`), `&quot;np&quot;`</span>
<span class="sd">            (`np.array`) or `&quot;ms&quot;` (`ms.Tensor`).</span>
<span class="sd">        return_dict (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether or not to return a [`~pipelines.ImagePipelineOutput`] instead of a plain tuple.</span>
<span class="sd">        callback_on_step_end (`Callable`, *optional*):</span>
<span class="sd">            A function that calls at the end of each denoising steps during the inference. The function is called</span>
<span class="sd">            with the following arguments: `callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int,</span>
<span class="sd">            callback_kwargs: Dict)`. `callback_kwargs` will include a list of all tensors as specified by</span>
<span class="sd">            `callback_on_step_end_tensor_inputs`.</span>
<span class="sd">        callback_on_step_end_tensor_inputs (`List`, *optional*):</span>
<span class="sd">            The list of tensor inputs for the `callback_on_step_end` function. The tensors specified in the list</span>
<span class="sd">            will be passed as `callback_kwargs` argument. You will only be able to include variables listed in the</span>
<span class="sd">            `._callback_tensor_inputs` attribute of your pipeline class.</span>

<span class="sd">    Examples:</span>

<span class="sd">    Returns:</span>
<span class="sd">        [`~pipelines.WuerstchenPriorPipelineOutput`] or `tuple` [`~pipelines.WuerstchenPriorPipelineOutput`] if</span>
<span class="sd">        `return_dict` is True, otherwise a `tuple`. When returning a tuple, the first element is a list with the</span>
<span class="sd">        generated image embeddings.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">callback</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;callback&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">callback_steps</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;callback_steps&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">deprecate</span><span class="p">(</span>
            <span class="s2">&quot;callback&quot;</span><span class="p">,</span>
            <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Passing `callback` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`&quot;</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">callback_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">deprecate</span><span class="p">(</span>
            <span class="s2">&quot;callback_steps&quot;</span><span class="p">,</span>
            <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Passing `callback_steps` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">callback_on_step_end_tensor_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span>
        <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">callback_on_step_end_tensor_inputs</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;`callback_on_step_end_tensor_inputs` has to be in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;but found </span><span class="si">{</span><span class="p">[</span><span class="n">k</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">callback_on_step_end_tensor_inputs</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="c1"># 0. Define commonly used variables</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_guidance_scale</span> <span class="o">=</span> <span class="n">guidance_scale</span>
    <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">elif</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">prompt_embeds</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># 1. Check inputs. Raise error if not correct</span>
    <span class="k">if</span> <span class="n">prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="p">[</span><span class="n">prompt</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;prompt&#39; must be of type &#39;list&#39; or &#39;str&#39;, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">negative_prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">negative_prompt</span> <span class="o">=</span> <span class="p">[</span><span class="n">negative_prompt</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;&#39;negative_prompt&#39; must be of type &#39;list&#39; or &#39;str&#39;, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">check_inputs</span><span class="p">(</span>
        <span class="n">prompt</span><span class="p">,</span>
        <span class="n">negative_prompt</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="o">=</span><span class="n">prompt_embeds</span><span class="p">,</span>
        <span class="n">negative_prompt_embeds</span><span class="o">=</span><span class="n">negative_prompt_embeds</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># 2. Encode caption</span>
    <span class="n">prompt_embeds</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_prompt</span><span class="p">(</span>
        <span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span>
        <span class="n">num_images_per_prompt</span><span class="o">=</span><span class="n">num_images_per_prompt</span><span class="p">,</span>
        <span class="n">do_classifier_free_guidance</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">,</span>
        <span class="n">negative_prompt</span><span class="o">=</span><span class="n">negative_prompt</span><span class="p">,</span>
        <span class="n">prompt_embeds</span><span class="o">=</span><span class="n">prompt_embeds</span><span class="p">,</span>
        <span class="n">negative_prompt_embeds</span><span class="o">=</span><span class="n">negative_prompt_embeds</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># For classifier free guidance, we need to do two forward passes.</span>
    <span class="c1"># Here we concatenate the unconditional and text embeddings into a single batch</span>
    <span class="c1"># to avoid doing two forward passes</span>
    <span class="n">text_encoder_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">prompt_embeds</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span><span class="p">])</span> <span class="k">if</span> <span class="n">negative_prompt_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">prompt_embeds</span>
    <span class="p">)</span>

    <span class="c1"># 3. Determine latent shape of image embeddings</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="n">text_encoder_hidden_states</span><span class="o">.</span><span class="n">dtype</span>
    <span class="n">latent_height</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="n">height</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">resolution_multiple</span><span class="p">)</span>
    <span class="n">latent_width</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="n">width</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">resolution_multiple</span><span class="p">)</span>
    <span class="n">num_channels</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">c_in</span>
    <span class="n">effnet_features_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">num_images_per_prompt</span> <span class="o">*</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_channels</span><span class="p">,</span> <span class="n">latent_height</span><span class="p">,</span> <span class="n">latent_width</span><span class="p">)</span>

    <span class="c1"># 4. Prepare and set timesteps</span>
    <span class="k">if</span> <span class="n">timesteps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">set_timesteps</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">timesteps</span><span class="p">)</span>
        <span class="n">timesteps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">timesteps</span>
        <span class="n">num_inference_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">set_timesteps</span><span class="p">(</span><span class="n">num_inference_steps</span><span class="p">)</span>
        <span class="n">timesteps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">timesteps</span>

    <span class="c1"># 5. Prepare latents</span>
    <span class="n">latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_latents</span><span class="p">(</span><span class="n">effnet_features_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">latents</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">)</span>

    <span class="c1"># 6. Run denoising loop</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_num_timesteps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">progress_bar</span><span class="p">(</span><span class="n">timesteps</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])):</span>
        <span class="n">ratio</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">((</span><span class="n">latents</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>

        <span class="c1"># 7. Denoise image embeddings</span>
        <span class="n">predicted_image_embedding</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prior</span><span class="p">(</span>
            <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">latents</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span> <span class="k">else</span> <span class="n">latents</span><span class="p">,</span>
            <span class="n">r</span><span class="o">=</span><span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">ratio</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span> <span class="k">else</span> <span class="n">ratio</span><span class="p">,</span>
            <span class="n">c</span><span class="o">=</span><span class="n">text_encoder_hidden_states</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># 8. Check for classifier free guidance and apply it</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">:</span>
            <span class="n">predicted_image_embedding_text</span><span class="p">,</span> <span class="n">predicted_image_embedding_uncond</span> <span class="o">=</span> <span class="n">predicted_image_embedding</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">predicted_image_embedding</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">lerp</span><span class="p">(</span>
                <span class="n">predicted_image_embedding_uncond</span><span class="p">,</span>
                <span class="n">predicted_image_embedding_text</span><span class="p">,</span>
                <span class="n">ms</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">guidance_scale</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">predicted_image_embedding_text</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
            <span class="p">)</span>

        <span class="c1"># 9. Renoise latents to next timestep</span>
        <span class="n">latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span>
            <span class="n">model_output</span><span class="o">=</span><span class="n">predicted_image_embedding</span><span class="p">,</span>
            <span class="n">timestep</span><span class="o">=</span><span class="n">ratio</span><span class="p">,</span>
            <span class="n">sample</span><span class="o">=</span><span class="n">latents</span><span class="p">,</span>
            <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">callback_on_step_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">callback_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span>
                <span class="n">callback_kwargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">locals</span><span class="p">()[</span><span class="n">k</span><span class="p">]</span>
            <span class="n">callback_outputs</span> <span class="o">=</span> <span class="n">callback_on_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">callback_kwargs</span><span class="p">)</span>

            <span class="n">latents</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;latents&quot;</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span>
            <span class="n">text_encoder_hidden_states</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
                <span class="s2">&quot;text_encoder_hidden_states&quot;</span><span class="p">,</span> <span class="n">text_encoder_hidden_states</span>
            <span class="p">)</span>
            <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;negative_prompt_embeds&quot;</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="n">callback_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">step_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">,</span> <span class="s2">&quot;order&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">callback</span><span class="p">(</span><span class="n">step_idx</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span>

    <span class="c1"># 10. Denormalize the latents</span>
    <span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">latent_mean</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">latent_std</span>

    <span class="k">if</span> <span class="n">output_type</span> <span class="o">==</span> <span class="s2">&quot;np&quot;</span><span class="p">:</span>
        <span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">latents</span><span class="p">,)</span>

    <span class="k">return</span> <span class="n">WuerstchenPriorPipelineOutput</span><span class="p">(</span><span class="n">latents</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindone.diffusers.pipelines.wuerstchen.pipeline_wuerstchen_prior.WuerstchenPriorPipelineOutput" class="doc doc-heading">
            <code>mindone.diffusers.pipelines.wuerstchen.pipeline_wuerstchen_prior.WuerstchenPriorPipelineOutput</code>


  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

<a href="#mindone.diffusers.pipelines.wuerstchen.pipeline_wuerstchen_prior.WuerstchenPriorPipelineOutput" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><span title="mindone.diffusers.utils.BaseOutput">BaseOutput</span></code></p>


        <p>Output class for WuerstchenPriorPipeline.</p>

              <details class="quote">
                <summary>Source code in <code>mindone/diffusers/pipelines/wuerstchen/pipeline_wuerstchen_prior.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">WuerstchenPriorPipelineOutput</span><span class="p">(</span><span class="n">BaseOutput</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Output class for WuerstchenPriorPipeline.</span>

<span class="sd">    Args:</span>
<span class="sd">        image_embeddings (`ms.Tensor` or `np.ndarray`)</span>
<span class="sd">            Prior image embeddings for text prompt</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">image_embeddings</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">











  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="mindone.diffusers.WuerstchenDecoderPipeline" class="doc doc-heading">
            <code>mindone.diffusers.WuerstchenDecoderPipeline</code>


<a href="#mindone.diffusers.WuerstchenDecoderPipeline" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">
            <p class="doc doc-class-bases">
              Bases: <code><a class="autorefs autorefs-internal" title="mindone.diffusers.pipelines.pipeline_utils.DiffusionPipeline" href="../overview/#mindone.diffusers.DiffusionPipeline">DiffusionPipeline</a></code></p>


        <p>Pipeline for generating images from the Wuerstchen model.</p>
<p>This model inherits from [<code>DiffusionPipeline</code>]. Check the superclass documentation for the generic methods the
library implements for all the pipelines (such as downloading or saving, running on a particular device, etc.)</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>tokenizer</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The CLIP tokenizer.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`CLIPTokenizer`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>text_encoder</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The CLIP text encoder.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`CLIPTextModel`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>decoder</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The WuerstchenDiffNeXt unet decoder.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`WuerstchenDiffNeXt`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>vqgan</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The VQGAN model.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`PaellaVQModel`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>scheduler</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A scheduler to be used in combination with <code>prior</code> to generate image embedding.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>[`DDPMWuerstchenScheduler`]</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>latent_dim_scale</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Multiplier to determine the VQ latent space size from the image embeddings. If the image embeddings are
height=24 and width=24, the VQ latent shape needs to be height=int(24*10.67)=256 and
width=int(24*10.67)=256 in order to match the training conditions.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>float, `optional`, defaults to 10.67</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>10.67</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>

              <details class="quote">
                <summary>Source code in <code>mindone/diffusers/pipelines/wuerstchen/pipeline_wuerstchen.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">WuerstchenDecoderPipeline</span><span class="p">(</span><span class="n">DiffusionPipeline</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Pipeline for generating images from the Wuerstchen model.</span>

<span class="sd">    This model inherits from [`DiffusionPipeline`]. Check the superclass documentation for the generic methods the</span>
<span class="sd">    library implements for all the pipelines (such as downloading or saving, running on a particular device, etc.)</span>

<span class="sd">    Args:</span>
<span class="sd">        tokenizer (`CLIPTokenizer`):</span>
<span class="sd">            The CLIP tokenizer.</span>
<span class="sd">        text_encoder (`CLIPTextModel`):</span>
<span class="sd">            The CLIP text encoder.</span>
<span class="sd">        decoder ([`WuerstchenDiffNeXt`]):</span>
<span class="sd">            The WuerstchenDiffNeXt unet decoder.</span>
<span class="sd">        vqgan ([`PaellaVQModel`]):</span>
<span class="sd">            The VQGAN model.</span>
<span class="sd">        scheduler ([`DDPMWuerstchenScheduler`]):</span>
<span class="sd">            A scheduler to be used in combination with `prior` to generate image embedding.</span>
<span class="sd">        latent_dim_scale (float, `optional`, defaults to 10.67):</span>
<span class="sd">            Multiplier to determine the VQ latent space size from the image embeddings. If the image embeddings are</span>
<span class="sd">            height=24 and width=24, the VQ latent shape needs to be height=int(24*10.67)=256 and</span>
<span class="sd">            width=int(24*10.67)=256 in order to match the training conditions.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">model_cpu_offload_seq</span> <span class="o">=</span> <span class="s2">&quot;text_encoder-&gt;decoder-&gt;vqgan&quot;</span>
    <span class="n">_callback_tensor_inputs</span> <span class="o">=</span> <span class="p">[</span>
        <span class="s2">&quot;latents&quot;</span><span class="p">,</span>
        <span class="s2">&quot;text_encoder_hidden_states&quot;</span><span class="p">,</span>
        <span class="s2">&quot;negative_prompt_embeds&quot;</span><span class="p">,</span>
        <span class="s2">&quot;image_embeddings&quot;</span><span class="p">,</span>
    <span class="p">]</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">tokenizer</span><span class="p">:</span> <span class="n">CLIPTokenizer</span><span class="p">,</span>
        <span class="n">text_encoder</span><span class="p">:</span> <span class="n">CLIPTextModel</span><span class="p">,</span>
        <span class="n">decoder</span><span class="p">:</span> <span class="n">WuerstchenDiffNeXt</span><span class="p">,</span>
        <span class="n">scheduler</span><span class="p">:</span> <span class="n">DDPMWuerstchenScheduler</span><span class="p">,</span>
        <span class="n">vqgan</span><span class="p">:</span> <span class="n">PaellaVQModel</span><span class="p">,</span>
        <span class="n">latent_dim_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10.67</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_modules</span><span class="p">(</span>
            <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">,</span>
            <span class="n">text_encoder</span><span class="o">=</span><span class="n">text_encoder</span><span class="p">,</span>
            <span class="n">decoder</span><span class="o">=</span><span class="n">decoder</span><span class="p">,</span>
            <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span>
            <span class="n">vqgan</span><span class="o">=</span><span class="n">vqgan</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_to_config</span><span class="p">(</span><span class="n">latent_dim_scale</span><span class="o">=</span><span class="n">latent_dim_scale</span><span class="p">)</span>

    <span class="c1"># Copied from diffusers.pipelines.unclip.pipeline_unclip.UnCLIPPipeline.prepare_latents</span>
    <span class="k">def</span> <span class="nf">prepare_latents</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">latents</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">latents</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">latents</span> <span class="o">=</span> <span class="n">randn_tensor</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">latents</span><span class="o">.</span><span class="n">shape</span> <span class="o">!=</span> <span class="n">shape</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unexpected latents shape, got </span><span class="si">{</span><span class="n">latents</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">, expected </span><span class="si">{</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span>

        <span class="n">latents</span> <span class="o">=</span> <span class="n">latents</span> <span class="o">*</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">init_noise_sigma</span>
        <span class="k">return</span> <span class="n">latents</span>

    <span class="k">def</span> <span class="nf">encode_prompt</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">prompt</span><span class="p">,</span>
        <span class="n">num_images_per_prompt</span><span class="p">,</span>
        <span class="n">do_classifier_free_guidance</span><span class="p">,</span>
        <span class="n">negative_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">)</span> <span class="k">else</span> <span class="mi">1</span>
        <span class="c1"># get prompt text embeddings</span>
        <span class="n">text_inputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
            <span class="n">prompt</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
            <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">,</span>
            <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">text_input_ids</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">text_inputs</span><span class="o">.</span><span class="n">input_ids</span><span class="p">)</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">text_inputs</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">)</span>

        <span class="n">untruncated_ids</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;longest&quot;</span><span class="p">,</span> <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">input_ids</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">untruncated_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">text_input_ids</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">ops</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">text_input_ids</span><span class="p">,</span> <span class="n">untruncated_ids</span><span class="p">):</span>
            <span class="n">removed_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">batch_decode</span><span class="p">(</span><span class="n">untruncated_ids</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span> <span class="o">-</span> <span class="mi">1</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                <span class="s2">&quot;The following part of your input was truncated because CLIP can only handle sequences up to&quot;</span>
                <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="si">}</span><span class="s2"> tokens: </span><span class="si">{</span><span class="n">removed_text</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="n">text_input_ids</span> <span class="o">=</span> <span class="n">text_input_ids</span><span class="p">[:,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">]</span>
            <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="p">[:,</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">]</span>

        <span class="n">text_encoder_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span><span class="n">text_input_ids</span><span class="p">,</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">attention_mask</span><span class="p">)</span>
        <span class="n">text_encoder_hidden_states</span> <span class="o">=</span> <span class="n">text_encoder_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">text_encoder_hidden_states</span> <span class="o">=</span> <span class="n">text_encoder_hidden_states</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="n">uncond_text_encoder_hidden_states</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="n">do_classifier_free_guidance</span><span class="p">:</span>
            <span class="n">uncond_tokens</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">negative_prompt</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;&quot;</span><span class="p">]</span> <span class="o">*</span> <span class="n">batch_size</span>
            <span class="k">elif</span> <span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span> <span class="ow">is</span> <span class="ow">not</span> <span class="nb">type</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;`negative_prompt` should be the same type to `prompt`, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">)</span><span class="si">}</span><span class="s2"> !=&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">negative_prompt</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">batch_size</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;`negative_prompt`: </span><span class="si">{</span><span class="n">negative_prompt</span><span class="si">}</span><span class="s2"> has batch size </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">, but `prompt`:&quot;</span>
                    <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">prompt</span><span class="si">}</span><span class="s2"> has batch size </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">. Please make sure that passed `negative_prompt` matches&quot;</span>
                    <span class="s2">&quot; the batch size of `prompt`.&quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">uncond_tokens</span> <span class="o">=</span> <span class="n">negative_prompt</span>

            <span class="n">uncond_input</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="p">(</span>
                <span class="n">uncond_tokens</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;max_length&quot;</span><span class="p">,</span>
                <span class="n">max_length</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">model_max_length</span><span class="p">,</span>
                <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">return_tensors</span><span class="o">=</span><span class="s2">&quot;np&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">negative_prompt_embeds_text_encoder_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">text_encoder</span><span class="p">(</span>
                <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">uncond_input</span><span class="o">.</span><span class="n">input_ids</span><span class="p">),</span> <span class="n">attention_mask</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">uncond_input</span><span class="o">.</span><span class="n">attention_mask</span><span class="p">)</span>
            <span class="p">)</span>

            <span class="n">uncond_text_encoder_hidden_states</span> <span class="o">=</span> <span class="n">negative_prompt_embeds_text_encoder_output</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="c1"># duplicate unconditional embeddings for each generation per prompt, using mps friendly method</span>
            <span class="n">seq_len</span> <span class="o">=</span> <span class="n">uncond_text_encoder_hidden_states</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">uncond_text_encoder_hidden_states</span> <span class="o">=</span> <span class="n">uncond_text_encoder_hidden_states</span><span class="o">.</span><span class="n">tile</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">uncond_text_encoder_hidden_states</span> <span class="o">=</span> <span class="n">uncond_text_encoder_hidden_states</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
                <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="n">seq_len</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span>
            <span class="p">)</span>
            <span class="c1"># done duplicates</span>

            <span class="c1"># For classifier free guidance, we need to do two forward passes.</span>
            <span class="c1"># Here we concatenate the unconditional and text embeddings into a single batch</span>
            <span class="c1"># to avoid doing two forward passes</span>
        <span class="k">return</span> <span class="n">text_encoder_hidden_states</span><span class="p">,</span> <span class="n">uncond_text_encoder_hidden_states</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">guidance_scale</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_guidance_scale</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">do_classifier_free_guidance</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_guidance_scale</span> <span class="o">&gt;</span> <span class="mi">1</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_timesteps</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_num_timesteps</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">image_embeddings</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
        <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_inference_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span>
        <span class="n">timesteps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">guidance_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
        <span class="n">negative_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_images_per_prompt</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">generator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">latents</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">output_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;pil&quot;</span><span class="p">,</span>
        <span class="n">return_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">callback_on_step_end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latents&quot;</span><span class="p">],</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function invoked when calling the pipeline for generation.</span>

<span class="sd">        Args:</span>
<span class="sd">            image_embedding (`ms.Tensor` or `List[ms.Tensor]`):</span>
<span class="sd">                Image Embeddings either extracted from an image or generated by a Prior Model.</span>
<span class="sd">            prompt (`str` or `List[str]`):</span>
<span class="sd">                The prompt or prompts to guide the image generation.</span>
<span class="sd">            num_inference_steps (`int`, *optional*, defaults to 12):</span>
<span class="sd">                The number of denoising steps. More denoising steps usually lead to a higher quality image at the</span>
<span class="sd">                expense of slower inference.</span>
<span class="sd">            timesteps (`List[int]`, *optional*):</span>
<span class="sd">                Custom timesteps to use for the denoising process. If not defined, equal spaced `num_inference_steps`</span>
<span class="sd">                timesteps are used. Must be in descending order.</span>
<span class="sd">            guidance_scale (`float`, *optional*, defaults to 0.0):</span>
<span class="sd">                Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).</span>
<span class="sd">                `decoder_guidance_scale` is defined as `w` of equation 2. of [Imagen</span>
<span class="sd">                Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting</span>
<span class="sd">                `decoder_guidance_scale &gt; 1`. Higher guidance scale encourages to generate images that are closely</span>
<span class="sd">                linked to the text `prompt`, usually at the expense of lower image quality.</span>
<span class="sd">            negative_prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">                The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored</span>
<span class="sd">                if `decoder_guidance_scale` is less than `1`).</span>
<span class="sd">            num_images_per_prompt (`int`, *optional*, defaults to 1):</span>
<span class="sd">                The number of images to generate per prompt.</span>
<span class="sd">            generator (`np.random.Generator` or `List[np.random.Generator]`, *optional*):</span>
<span class="sd">                One or a list of [np.random.Generator(s)](https://numpy.org/doc/stable/reference/random/generator.html)</span>
<span class="sd">                to make generation deterministic.</span>
<span class="sd">            latents (`ms.Tensor`, *optional*):</span>
<span class="sd">                Pre-generated noisy latents, sampled from a Gaussian distribution, to be used as inputs for image</span>
<span class="sd">                generation. Can be used to tweak the same generation with different prompts. If not provided, a latents</span>
<span class="sd">                tensor will ge generated by sampling using the supplied random `generator`.</span>
<span class="sd">            output_type (`str`, *optional*, defaults to `&quot;pil&quot;`):</span>
<span class="sd">                The output format of the generate image. Choose between: `&quot;pil&quot;` (`PIL.Image.Image`), `&quot;np&quot;`</span>
<span class="sd">                (`np.array`) or `&quot;ms&quot;` (`ms.Tensor`).</span>
<span class="sd">            return_dict (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                Whether or not to return a [`~pipelines.ImagePipelineOutput`] instead of a plain tuple.</span>
<span class="sd">            callback_on_step_end (`Callable`, *optional*):</span>
<span class="sd">                A function that calls at the end of each denoising steps during the inference. The function is called</span>
<span class="sd">                with the following arguments: `callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int,</span>
<span class="sd">                callback_kwargs: Dict)`. `callback_kwargs` will include a list of all tensors as specified by</span>
<span class="sd">                `callback_on_step_end_tensor_inputs`.</span>
<span class="sd">            callback_on_step_end_tensor_inputs (`List`, *optional*):</span>
<span class="sd">                The list of tensor inputs for the `callback_on_step_end` function. The tensors specified in the list</span>
<span class="sd">                will be passed as `callback_kwargs` argument. You will only be able to include variables listed in the</span>
<span class="sd">                `._callback_tensor_inputs` attribute of your pipeline class.</span>

<span class="sd">        Examples:</span>

<span class="sd">        Returns:</span>
<span class="sd">            [`~pipelines.ImagePipelineOutput`] or `tuple` [`~pipelines.ImagePipelineOutput`] if `return_dict` is True,</span>
<span class="sd">            otherwise a `tuple`. When returning a tuple, the first element is a list with the generated image</span>
<span class="sd">            embeddings.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">callback</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;callback&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">callback_steps</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;callback_steps&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">deprecate</span><span class="p">(</span>
                <span class="s2">&quot;callback&quot;</span><span class="p">,</span>
                <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Passing `callback` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`&quot;</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">callback_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">deprecate</span><span class="p">(</span>
                <span class="s2">&quot;callback_steps&quot;</span><span class="p">,</span>
                <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
                <span class="s2">&quot;Passing `callback_steps` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`&quot;</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">callback_on_step_end_tensor_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span>
            <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">callback_on_step_end_tensor_inputs</span>
        <span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`callback_on_step_end_tensor_inputs` has to be in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span><span class="si">}</span><span class="s2">, &quot;</span>
                <span class="sa">f</span><span class="s2">&quot;but found </span><span class="si">{</span><span class="p">[</span><span class="n">k</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">callback_on_step_end_tensor_inputs</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="c1"># 0. Define commonly used variables</span>
        <span class="n">dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_guidance_scale</span> <span class="o">=</span> <span class="n">guidance_scale</span>

        <span class="c1"># 1. Check inputs. Raise error if not correct</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">prompt</span> <span class="o">=</span> <span class="p">[</span><span class="n">prompt</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;prompt&#39; must be of type &#39;list&#39; or &#39;str&#39;, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">negative_prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                    <span class="n">negative_prompt</span> <span class="o">=</span> <span class="p">[</span><span class="n">negative_prompt</span><span class="p">]</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;&#39;negative_prompt&#39; must be of type &#39;list&#39; or &#39;str&#39;, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                    <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;image_embeddings&#39; must be of type &#39;ms.Tensor&#39; or &#39;np.array&#39;, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_inference_steps</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&#39;num_inference_steps&#39; must be of type &#39;int&#39;, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">num_inference_steps</span><span class="p">)</span><span class="si">}</span><span class="se">\</span>
<span class="s2">                           In Case you want to provide explicit timesteps, please use the &#39;timesteps&#39; argument.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># 2. Encode caption</span>
        <span class="n">prompt_embeds</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_prompt</span><span class="p">(</span>
            <span class="n">prompt</span><span class="p">,</span>
            <span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span><span class="p">,</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">,</span>
            <span class="n">negative_prompt</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">text_encoder_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">prompt_embeds</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span><span class="p">])</span> <span class="k">if</span> <span class="n">negative_prompt_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">prompt_embeds</span>
        <span class="p">)</span>
        <span class="n">effnet</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">image_embeddings</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">)])</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span>
            <span class="k">else</span> <span class="n">image_embeddings</span>
        <span class="p">)</span>

        <span class="c1"># 3. Determine latent shape of latents</span>
        <span class="n">latent_height</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">latent_dim_scale</span><span class="p">)</span>
        <span class="n">latent_width</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">latent_dim_scale</span><span class="p">)</span>
        <span class="n">latent_features_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">latent_height</span><span class="p">,</span> <span class="n">latent_width</span><span class="p">)</span>

        <span class="c1"># 4. Prepare and set timesteps</span>
        <span class="k">if</span> <span class="n">timesteps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">set_timesteps</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">timesteps</span><span class="p">)</span>
            <span class="n">timesteps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">timesteps</span>
            <span class="n">num_inference_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">set_timesteps</span><span class="p">(</span><span class="n">num_inference_steps</span><span class="p">)</span>
            <span class="n">timesteps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">timesteps</span>

        <span class="c1"># 5. Prepare latents</span>
        <span class="n">latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_latents</span><span class="p">(</span><span class="n">latent_features_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">latents</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">)</span>

        <span class="c1"># 6. Run denoising loop</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_timesteps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">progress_bar</span><span class="p">(</span><span class="n">timesteps</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])):</span>
            <span class="n">ratio</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">((</span><span class="n">latents</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
            <span class="c1"># 7. Denoise latents</span>
            <span class="n">predicted_latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span>
                <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">latents</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span> <span class="k">else</span> <span class="n">latents</span><span class="p">,</span>
                <span class="n">r</span><span class="o">=</span><span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">ratio</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span> <span class="k">else</span> <span class="n">ratio</span><span class="p">,</span>
                <span class="n">effnet</span><span class="o">=</span><span class="n">effnet</span><span class="p">,</span>
                <span class="n">clip</span><span class="o">=</span><span class="n">text_encoder_hidden_states</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="c1"># 8. Check for classifier free guidance and apply it</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">:</span>
                <span class="n">predicted_latents_text</span><span class="p">,</span> <span class="n">predicted_latents_uncond</span> <span class="o">=</span> <span class="n">predicted_latents</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">predicted_latents</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">lerp</span><span class="p">(</span>
                    <span class="n">predicted_latents_uncond</span><span class="p">,</span>
                    <span class="n">predicted_latents_text</span><span class="p">,</span>
                    <span class="n">ms</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">guidance_scale</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">predicted_latents_text</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
                <span class="p">)</span>

            <span class="c1"># 9. Renoise latents to next timestep</span>
            <span class="n">latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span>
                <span class="n">model_output</span><span class="o">=</span><span class="n">predicted_latents</span><span class="p">,</span>
                <span class="n">timestep</span><span class="o">=</span><span class="n">ratio</span><span class="p">,</span>
                <span class="n">sample</span><span class="o">=</span><span class="n">latents</span><span class="p">,</span>
                <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span>
            <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">callback_on_step_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">callback_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span>
                    <span class="n">callback_kwargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">locals</span><span class="p">()[</span><span class="n">k</span><span class="p">]</span>
                <span class="n">callback_outputs</span> <span class="o">=</span> <span class="n">callback_on_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">callback_kwargs</span><span class="p">)</span>

                <span class="n">latents</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;latents&quot;</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span>
                <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;image_embeddings&quot;</span><span class="p">,</span> <span class="n">image_embeddings</span><span class="p">)</span>
                <span class="n">text_encoder_hidden_states</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
                    <span class="s2">&quot;text_encoder_hidden_states&quot;</span><span class="p">,</span> <span class="n">text_encoder_hidden_states</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="n">callback_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">step_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">,</span> <span class="s2">&quot;order&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">callback</span><span class="p">(</span><span class="n">step_idx</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">output_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;ms&quot;</span><span class="p">,</span> <span class="s2">&quot;np&quot;</span><span class="p">,</span> <span class="s2">&quot;pil&quot;</span><span class="p">,</span> <span class="s2">&quot;latent&quot;</span><span class="p">]:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Only the output types `ms`, `np`, `pil` and `latent` are supported not output_type=</span><span class="si">{</span><span class="n">output_type</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">output_type</span> <span class="o">==</span> <span class="s2">&quot;latent&quot;</span><span class="p">:</span>
            <span class="c1"># 10. Scale and decode the image latents with vq-vae</span>
            <span class="n">latents</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vqgan</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">scale_factor</span> <span class="o">*</span> <span class="n">latents</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">latents</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
            <span class="n">images</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vqgan</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">latents</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">output_type</span> <span class="o">==</span> <span class="s2">&quot;np&quot;</span><span class="p">:</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">permute</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="k">elif</span> <span class="n">output_type</span> <span class="o">==</span> <span class="s2">&quot;pil&quot;</span><span class="p">:</span>
                <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">permute</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">images</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">numpy_to_pil</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">latents</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">images</span>
        <span class="k">return</span> <span class="n">ImagePipelineOutput</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindone.diffusers.WuerstchenDecoderPipeline.__call__" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindone</span><span class="o">.</span><span class="n">diffusers</span><span class="o">.</span><span class="n">WuerstchenDecoderPipeline</span><span class="o">.</span><span class="fm">__call__</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">,</span> <span class="n">prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_inference_steps</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span> <span class="n">timesteps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">guidance_scale</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">negative_prompt</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">num_images_per_prompt</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">latents</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">output_type</span><span class="o">=</span><span class="s1">&#39;pil&#39;</span><span class="p">,</span> <span class="n">return_dict</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">callback_on_step_end</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">callback_on_step_end_tensor_inputs</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;latents&#39;</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindone.diffusers.WuerstchenDecoderPipeline.__call__" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Function invoked when calling the pipeline for generation.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>image_embedding</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Image Embeddings either extracted from an image or generated by a Prior Model.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor` or `List[ms.Tensor]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The prompt or prompts to guide the image generation.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `List[str]`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_inference_steps</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of denoising steps. More denoising steps usually lead to a higher quality image at the
expense of slower inference.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 12</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>12</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>timesteps</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Custom timesteps to use for the denoising process. If not defined, equal spaced <code>num_inference_steps</code>
timesteps are used. Must be in descending order.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[int]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>guidance_scale</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Guidance scale as defined in <a href="https://arxiv.org/abs/2207.12598">Classifier-Free Diffusion Guidance</a>.
<code>decoder_guidance_scale</code> is defined as <code>w</code> of equation 2. of <a href="https://arxiv.org/pdf/2205.11487.pdf">Imagen
Paper</a>. Guidance scale is enabled by setting
<code>decoder_guidance_scale &gt; 1</code>. Higher guidance scale encourages to generate images that are closely
linked to the text <code>prompt</code>, usually at the expense of lower image quality.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`float`, *optional*, defaults to 0.0</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>0.0</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>negative_prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored
if <code>decoder_guidance_scale</code> is less than <code>1</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `List[str]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>num_images_per_prompt</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The number of images to generate per prompt.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`int`, *optional*, defaults to 1</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>1</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>generator</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>One or a list of <a href="https://numpy.org/doc/stable/reference/random/generator.html">np.random.Generator(s)</a>
to make generation deterministic.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`np.random.Generator` or `List[np.random.Generator]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>latents</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Pre-generated noisy latents, sampled from a Gaussian distribution, to be used as inputs for image
generation. Can be used to tweak the same generation with different prompts. If not provided, a latents
tensor will ge generated by sampling using the supplied random <code>generator</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`ms.Tensor`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>output_type</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The output format of the generate image. Choose between: <code>"pil"</code> (<code>PIL.Image.Image</code>), <code>"np"</code>
(<code>np.array</code>) or <code>"ms"</code> (<code>ms.Tensor</code>).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;pil&#34;`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>&#39;pil&#39;</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>return_dict</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to return a [<code>~pipelines.ImagePipelineOutput</code>] instead of a plain tuple.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>False</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>callback_on_step_end</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A function that calls at the end of each denoising steps during the inference. The function is called
with the following arguments: <code>callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int,
callback_kwargs: Dict)</code>. <code>callback_kwargs</code> will include a list of all tensors as specified by
<code>callback_on_step_end_tensor_inputs</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Callable`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>callback_on_step_end_tensor_inputs</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The list of tensor inputs for the <code>callback_on_step_end</code> function. The tensors specified in the list
will be passed as <code>callback_kwargs</code> argument. You will only be able to include variables listed in the
<code>._callback_tensor_inputs</code> attribute of your pipeline class.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>[&#39;latents&#39;]</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">RETURNS</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>[<code>~pipelines.ImagePipelineOutput</code>] or <code>tuple</code> [<code>~pipelines.ImagePipelineOutput</code>] if <code>return_dict</code> is True,</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>otherwise a <code>tuple</code>. When returning a tuple, the first element is a list with the generated image</p>
              </div>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
            </td>
            <td class="doc-returns-details">
              <div class="doc-md-description">
                <p>embeddings.</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>

            <details class="quote">
              <summary>Source code in <code>mindone/diffusers/pipelines/wuerstchen/pipeline_wuerstchen.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">image_embeddings</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span>
    <span class="n">prompt</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_inference_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span>
    <span class="n">timesteps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">guidance_scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">negative_prompt</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_images_per_prompt</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">Generator</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">latents</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">output_type</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;pil&quot;</span><span class="p">,</span>
    <span class="n">return_dict</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">callback_on_step_end</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">[[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">,</span> <span class="n">Dict</span><span class="p">],</span> <span class="kc">None</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;latents&quot;</span><span class="p">],</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function invoked when calling the pipeline for generation.</span>

<span class="sd">    Args:</span>
<span class="sd">        image_embedding (`ms.Tensor` or `List[ms.Tensor]`):</span>
<span class="sd">            Image Embeddings either extracted from an image or generated by a Prior Model.</span>
<span class="sd">        prompt (`str` or `List[str]`):</span>
<span class="sd">            The prompt or prompts to guide the image generation.</span>
<span class="sd">        num_inference_steps (`int`, *optional*, defaults to 12):</span>
<span class="sd">            The number of denoising steps. More denoising steps usually lead to a higher quality image at the</span>
<span class="sd">            expense of slower inference.</span>
<span class="sd">        timesteps (`List[int]`, *optional*):</span>
<span class="sd">            Custom timesteps to use for the denoising process. If not defined, equal spaced `num_inference_steps`</span>
<span class="sd">            timesteps are used. Must be in descending order.</span>
<span class="sd">        guidance_scale (`float`, *optional*, defaults to 0.0):</span>
<span class="sd">            Guidance scale as defined in [Classifier-Free Diffusion Guidance](https://arxiv.org/abs/2207.12598).</span>
<span class="sd">            `decoder_guidance_scale` is defined as `w` of equation 2. of [Imagen</span>
<span class="sd">            Paper](https://arxiv.org/pdf/2205.11487.pdf). Guidance scale is enabled by setting</span>
<span class="sd">            `decoder_guidance_scale &gt; 1`. Higher guidance scale encourages to generate images that are closely</span>
<span class="sd">            linked to the text `prompt`, usually at the expense of lower image quality.</span>
<span class="sd">        negative_prompt (`str` or `List[str]`, *optional*):</span>
<span class="sd">            The prompt or prompts not to guide the image generation. Ignored when not using guidance (i.e., ignored</span>
<span class="sd">            if `decoder_guidance_scale` is less than `1`).</span>
<span class="sd">        num_images_per_prompt (`int`, *optional*, defaults to 1):</span>
<span class="sd">            The number of images to generate per prompt.</span>
<span class="sd">        generator (`np.random.Generator` or `List[np.random.Generator]`, *optional*):</span>
<span class="sd">            One or a list of [np.random.Generator(s)](https://numpy.org/doc/stable/reference/random/generator.html)</span>
<span class="sd">            to make generation deterministic.</span>
<span class="sd">        latents (`ms.Tensor`, *optional*):</span>
<span class="sd">            Pre-generated noisy latents, sampled from a Gaussian distribution, to be used as inputs for image</span>
<span class="sd">            generation. Can be used to tweak the same generation with different prompts. If not provided, a latents</span>
<span class="sd">            tensor will ge generated by sampling using the supplied random `generator`.</span>
<span class="sd">        output_type (`str`, *optional*, defaults to `&quot;pil&quot;`):</span>
<span class="sd">            The output format of the generate image. Choose between: `&quot;pil&quot;` (`PIL.Image.Image`), `&quot;np&quot;`</span>
<span class="sd">            (`np.array`) or `&quot;ms&quot;` (`ms.Tensor`).</span>
<span class="sd">        return_dict (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether or not to return a [`~pipelines.ImagePipelineOutput`] instead of a plain tuple.</span>
<span class="sd">        callback_on_step_end (`Callable`, *optional*):</span>
<span class="sd">            A function that calls at the end of each denoising steps during the inference. The function is called</span>
<span class="sd">            with the following arguments: `callback_on_step_end(self: DiffusionPipeline, step: int, timestep: int,</span>
<span class="sd">            callback_kwargs: Dict)`. `callback_kwargs` will include a list of all tensors as specified by</span>
<span class="sd">            `callback_on_step_end_tensor_inputs`.</span>
<span class="sd">        callback_on_step_end_tensor_inputs (`List`, *optional*):</span>
<span class="sd">            The list of tensor inputs for the `callback_on_step_end` function. The tensors specified in the list</span>
<span class="sd">            will be passed as `callback_kwargs` argument. You will only be able to include variables listed in the</span>
<span class="sd">            `._callback_tensor_inputs` attribute of your pipeline class.</span>

<span class="sd">    Examples:</span>

<span class="sd">    Returns:</span>
<span class="sd">        [`~pipelines.ImagePipelineOutput`] or `tuple` [`~pipelines.ImagePipelineOutput`] if `return_dict` is True,</span>
<span class="sd">        otherwise a `tuple`. When returning a tuple, the first element is a list with the generated image</span>
<span class="sd">        embeddings.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">callback</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;callback&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">callback_steps</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;callback_steps&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">deprecate</span><span class="p">(</span>
            <span class="s2">&quot;callback&quot;</span><span class="p">,</span>
            <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Passing `callback` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`&quot;</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">callback_steps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">deprecate</span><span class="p">(</span>
            <span class="s2">&quot;callback_steps&quot;</span><span class="p">,</span>
            <span class="s2">&quot;1.0.0&quot;</span><span class="p">,</span>
            <span class="s2">&quot;Passing `callback_steps` as an input argument to `__call__` is deprecated, consider use `callback_on_step_end`&quot;</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">callback_on_step_end_tensor_inputs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span>
        <span class="n">k</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">callback_on_step_end_tensor_inputs</span>
    <span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;`callback_on_step_end_tensor_inputs` has to be in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span><span class="si">}</span><span class="s2">, &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;but found </span><span class="si">{</span><span class="p">[</span><span class="n">k</span><span class="w"> </span><span class="k">for</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="n">callback_on_step_end_tensor_inputs</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">k</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="ow">in</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">_callback_tensor_inputs</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="c1"># 0. Define commonly used variables</span>
    <span class="n">dtype</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">get_parameters</span><span class="p">())</span><span class="o">.</span><span class="n">dtype</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_guidance_scale</span> <span class="o">=</span> <span class="n">guidance_scale</span>

    <span class="c1"># 1. Check inputs. Raise error if not correct</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">prompt</span> <span class="o">=</span> <span class="p">[</span><span class="n">prompt</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;&#39;prompt&#39; must be of type &#39;list&#39; or &#39;str&#39;, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">negative_prompt</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
                <span class="n">negative_prompt</span> <span class="o">=</span> <span class="p">[</span><span class="n">negative_prompt</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;&#39;negative_prompt&#39; must be of type &#39;list&#39; or &#39;str&#39;, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">negative_prompt</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
                <span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;&#39;image_embeddings&#39; must be of type &#39;ms.Tensor&#39; or &#39;np.array&#39;, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_inference_steps</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;&#39;num_inference_steps&#39; must be of type &#39;int&#39;, but got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">num_inference_steps</span><span class="p">)</span><span class="si">}</span><span class="se">\</span>
<span class="s2">                       In Case you want to provide explicit timesteps, please use the &#39;timesteps&#39; argument.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># 2. Encode caption</span>
    <span class="n">prompt_embeds</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encode_prompt</span><span class="p">(</span>
        <span class="n">prompt</span><span class="p">,</span>
        <span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span><span class="p">,</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">,</span>
        <span class="n">negative_prompt</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">text_encoder_hidden_states</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">prompt_embeds</span><span class="p">,</span> <span class="n">negative_prompt_embeds</span><span class="p">])</span> <span class="k">if</span> <span class="n">negative_prompt_embeds</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">prompt_embeds</span>
    <span class="p">)</span>
    <span class="n">effnet</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">image_embeddings</span><span class="p">,</span> <span class="n">ops</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">image_embeddings</span><span class="p">)])</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span>
        <span class="k">else</span> <span class="n">image_embeddings</span>
    <span class="p">)</span>

    <span class="c1"># 3. Determine latent shape of latents</span>
    <span class="n">latent_height</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">latent_dim_scale</span><span class="p">)</span>
    <span class="n">latent_width</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">latent_dim_scale</span><span class="p">)</span>
    <span class="n">latent_features_shape</span> <span class="o">=</span> <span class="p">(</span><span class="n">image_embeddings</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_images_per_prompt</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">latent_height</span><span class="p">,</span> <span class="n">latent_width</span><span class="p">)</span>

    <span class="c1"># 4. Prepare and set timesteps</span>
    <span class="k">if</span> <span class="n">timesteps</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">set_timesteps</span><span class="p">(</span><span class="n">timesteps</span><span class="o">=</span><span class="n">timesteps</span><span class="p">)</span>
        <span class="n">timesteps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">timesteps</span>
        <span class="n">num_inference_steps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">set_timesteps</span><span class="p">(</span><span class="n">num_inference_steps</span><span class="p">)</span>
        <span class="n">timesteps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">timesteps</span>

    <span class="c1"># 5. Prepare latents</span>
    <span class="n">latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prepare_latents</span><span class="p">(</span><span class="n">latent_features_shape</span><span class="p">,</span> <span class="n">dtype</span><span class="p">,</span> <span class="n">generator</span><span class="p">,</span> <span class="n">latents</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">)</span>

    <span class="c1"># 6. Run denoising loop</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">_num_timesteps</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">timesteps</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">progress_bar</span><span class="p">(</span><span class="n">timesteps</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">])):</span>
        <span class="n">ratio</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">broadcast_to</span><span class="p">((</span><span class="n">latents</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="p">)</span>
        <span class="c1"># 7. Denoise latents</span>
        <span class="n">predicted_latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span>
            <span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">latents</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span> <span class="k">else</span> <span class="n">latents</span><span class="p">,</span>
            <span class="n">r</span><span class="o">=</span><span class="n">ops</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">ratio</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">)</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span> <span class="k">else</span> <span class="n">ratio</span><span class="p">,</span>
            <span class="n">effnet</span><span class="o">=</span><span class="n">effnet</span><span class="p">,</span>
            <span class="n">clip</span><span class="o">=</span><span class="n">text_encoder_hidden_states</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># 8. Check for classifier free guidance and apply it</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_classifier_free_guidance</span><span class="p">:</span>
            <span class="n">predicted_latents_text</span><span class="p">,</span> <span class="n">predicted_latents_uncond</span> <span class="o">=</span> <span class="n">predicted_latents</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">predicted_latents</span> <span class="o">=</span> <span class="n">ops</span><span class="o">.</span><span class="n">lerp</span><span class="p">(</span>
                <span class="n">predicted_latents_uncond</span><span class="p">,</span>
                <span class="n">predicted_latents_text</span><span class="p">,</span>
                <span class="n">ms</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">guidance_scale</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">predicted_latents_text</span><span class="o">.</span><span class="n">dtype</span><span class="p">),</span>
            <span class="p">)</span>

        <span class="c1"># 9. Renoise latents to next timestep</span>
        <span class="n">latents</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">(</span>
            <span class="n">model_output</span><span class="o">=</span><span class="n">predicted_latents</span><span class="p">,</span>
            <span class="n">timestep</span><span class="o">=</span><span class="n">ratio</span><span class="p">,</span>
            <span class="n">sample</span><span class="o">=</span><span class="n">latents</span><span class="p">,</span>
            <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">,</span>
        <span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">callback_on_step_end</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">callback_kwargs</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">callback_on_step_end_tensor_inputs</span><span class="p">:</span>
                <span class="n">callback_kwargs</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="nb">locals</span><span class="p">()[</span><span class="n">k</span><span class="p">]</span>
            <span class="n">callback_outputs</span> <span class="o">=</span> <span class="n">callback_on_step_end</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">callback_kwargs</span><span class="p">)</span>

            <span class="n">latents</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;latents&quot;</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span>
            <span class="n">image_embeddings</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;image_embeddings&quot;</span><span class="p">,</span> <span class="n">image_embeddings</span><span class="p">)</span>
            <span class="n">text_encoder_hidden_states</span> <span class="o">=</span> <span class="n">callback_outputs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span>
                <span class="s2">&quot;text_encoder_hidden_states&quot;</span><span class="p">,</span> <span class="n">text_encoder_hidden_states</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="n">callback_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">step_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">scheduler</span><span class="p">,</span> <span class="s2">&quot;order&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">callback</span><span class="p">(</span><span class="n">step_idx</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">latents</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">output_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;ms&quot;</span><span class="p">,</span> <span class="s2">&quot;np&quot;</span><span class="p">,</span> <span class="s2">&quot;pil&quot;</span><span class="p">,</span> <span class="s2">&quot;latent&quot;</span><span class="p">]:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Only the output types `ms`, `np`, `pil` and `latent` are supported not output_type=</span><span class="si">{</span><span class="n">output_type</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">output_type</span> <span class="o">==</span> <span class="s2">&quot;latent&quot;</span><span class="p">:</span>
        <span class="c1"># 10. Scale and decode the image latents with vq-vae</span>
        <span class="n">latents</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vqgan</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">scale_factor</span> <span class="o">*</span> <span class="n">latents</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">latents</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
        <span class="n">images</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vqgan</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">latents</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">output_type</span> <span class="o">==</span> <span class="s2">&quot;np&quot;</span><span class="p">:</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">permute</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">output_type</span> <span class="o">==</span> <span class="s2">&quot;pil&quot;</span><span class="p">:</span>
            <span class="n">images</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">permute</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">images</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">numpy_to_pil</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">images</span> <span class="o">=</span> <span class="n">latents</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">return_dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">images</span>
    <span class="k">return</span> <span class="n">ImagePipelineOutput</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><h2 id="citation">Citation<a class="headerlink" href="#citation" title="Permanent link">&para;</a></h2>
<div class="highlight"><pre><span></span><code><span class="nc">@misc</span><span class="p">{</span><span class="nl">pernias2023wuerstchen</span><span class="p">,</span>
<span class="w">    </span><span class="na">title</span><span class="p">=</span><span class="s">{Wuerstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models}</span><span class="p">,</span>
<span class="w">    </span><span class="na">author</span><span class="p">=</span><span class="s">{Pablo Pernias and Dominic Rampas and Mats L. Richter and Christopher J. Pal and Marc Aubreville}</span><span class="p">,</span>
<span class="w">    </span><span class="na">year</span><span class="p">=</span><span class="s">{2023}</span><span class="p">,</span>
<span class="w">    </span><span class="na">eprint</span><span class="p">=</span><span class="s">{2306.00637}</span><span class="p">,</span>
<span class="w">    </span><span class="na">archivePrefix</span><span class="p">=</span><span class="s">{arXiv}</span><span class="p">,</span>
<span class="w">    </span><span class="na">primaryClass</span><span class="p">=</span><span class="s">{cs.CV}</span>
<span class="p">}</span>
</code></pre></div>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 1, 2024</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 1, 2024</span>
  </span>

    
    
      
  
  <span class="md-source-file__fact">
    <span class="md-icon" title="Contributors">
      
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 4a4 4 0 0 1 4 4 4 4 0 0 1-4 4 4 4 0 0 1-4-4 4 4 0 0 1 4-4m0 10c4.42 0 8 1.79 8 4v2H4v-2c0-2.21 3.58-4 8-4"/></svg>
      
    </span>
    <nav>
      
        <a href="mailto:77485245+wcrzlh@users.noreply.github.com">Chaoran Wei</a>
    </nav>
  </span>

    
    
  </aside>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../unclip/" class="md-footer__link md-footer__link--prev" aria-label="Previous: unCLIP">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                unCLIP
              </div>
            </div>
          </a>
        
        
          
          <a href="../../internal_classes_overview/" class="md-footer__link md-footer__link--next" aria-label="Next: Overview">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Overview
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 - 2024 MindSpore Lab
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="mailto:mindspore-lab@huawei.com" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/mindspore-lab/mindone" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.zhihu.com/people/mindsporelab" target="_blank" rel="noopener" title="www.zhihu.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M170.54 148.13v217.54l23.43.01 7.71 26.37 42.01-26.37h49.53V148.13zm97.75 193.93h-27.94l-27.9 17.51-5.08-17.47-11.9-.04V171.75h72.82zm-118.46-94.39H97.5c1.74-27.1 2.2-51.59 2.2-73.46h51.16s1.97-22.56-8.58-22.31h-88.5c3.49-13.12 7.87-26.66 13.12-40.67 0 0-24.07 0-32.27 21.57-3.39 8.9-13.21 43.14-30.7 78.12 5.89-.64 25.37-1.18 36.84-22.21 2.11-5.89 2.51-6.66 5.14-14.53h28.87c0 10.5-1.2 66.88-1.68 73.44H20.83c-11.74 0-15.56 23.62-15.56 23.62h65.58C66.45 321.1 42.83 363.12 0 396.34c20.49 5.85 40.91-.93 51-9.9 0 0 22.98-20.9 35.59-69.25l53.96 64.94s7.91-26.89-1.24-39.99c-7.58-8.92-28.06-33.06-36.79-41.81L87.9 311.95c4.36-13.98 6.99-27.55 7.87-40.67h61.65s-.09-23.62-7.59-23.62zm412.02-1.6c20.83-25.64 44.98-58.57 44.98-58.57s-18.65-14.8-27.38-4.06c-6 8.15-36.83 48.2-36.83 48.2zm-150.09-59.09c-9.01-8.25-25.91 2.13-25.91 2.13s39.52 55.04 41.12 57.45l19.46-13.73s-25.67-37.61-34.66-45.86h-.01zM640 258.35c-19.78 0-130.91.93-131.06.93v-101c4.81 0 12.42-.4 22.85-1.2 40.88-2.41 70.13-4 87.77-4.81 0 0 12.22-27.19-.59-33.44-3.07-1.18-23.17 4.58-23.17 4.58s-165.22 16.49-232.36 18.05c1.6 8.82 7.62 17.08 15.78 19.55 13.31 3.48 22.69 1.7 49.15.89 24.83-1.6 43.68-2.43 56.51-2.43v99.81H351.41s2.82 22.31 25.51 22.85h107.94v70.92c0 13.97-11.19 21.99-24.48 21.12-14.08.11-26.08-1.15-41.69-1.81 1.99 3.97 6.33 14.39 19.31 21.84 9.88 4.81 16.17 6.57 26.02 6.57 29.56 0 45.67-17.28 44.89-45.31v-73.32h122.36c9.68 0 8.7-23.78 8.7-23.78z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.top", "navigation.footer", "toc.follow", "search.highlight", "search.share", "search.suggest", "content.action.view", "content.action.edit", "content.tabs.link", "content.code.copy", "content.code.select", "content.code.annotations"], "search": "../../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>