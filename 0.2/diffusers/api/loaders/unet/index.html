
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://mindspore-lab.github.io/mindone/0.2/diffusers/api/loaders/unet/">
      
      
        <link rel="prev" href="../textual_inversion/">
      
      
        <link rel="next" href="../../models/overview/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.5.43">
    
    
      
        <title>UNet - MindOne - One for All</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.0253249f.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,300i,400,400i,700,700i%7CIBM+Plex+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Source Sans Pro";--md-code-font:"IBM Plex Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#unet" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="MindOne - One for All" class="md-header__button md-logo" aria-label="MindOne - One for All" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            MindOne - One for All
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              UNet
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
          <a href="javascript:void(0)" class="md-search__icon md-icon" title="Share" aria-label="Share" data-clipboard data-clipboard-text="" data-md-component="search-share" tabindex="-1">
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg>
          </a>
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/mindspore-lab/mindone" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindone
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
    
  
  
    
    
      
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../" class="md-tabs__link">
          
  
  Diffusers

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../transformers/" class="md-tabs__link">
          
  
  Transformers

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../peft/" class="md-tabs__link">
          
  
  PEFT

        </a>
      </li>
    
  

    
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="MindOne - One for All" class="md-nav__button md-logo" aria-label="MindOne - One for All" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    MindOne - One for All
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/mindspore-lab/mindone" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    mindspore-lab/mindone
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
      
        
        
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Diffusers
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Diffusers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Get started
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            Get started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ðŸ§¨ Diffusers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../quicktour/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Quicktour
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../stable_diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Effective and efficient diffusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Installation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../limitations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Limitations
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_2" >
        
          
          <label class="md-nav__link" for="__nav_2_2" id="__nav_2_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    Tutorials
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_2">
            <span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/tutorial_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../using-diffusers/write_own_pipeline/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Understanding pipelines, models and schedulers
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/basic_training/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Train a diffusion model
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../tutorials/using_peft_for_inference/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Load LoRAs for inference
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
      
      
        
          
          
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" checked>
        
          
          <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="">
            
  
  <span class="md-ellipsis">
    API
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_3">
            <span class="md-nav__icon md-icon"></span>
            API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3_1" checked>
        
          
          <label class="md-nav__link" for="__nav_2_3_1" id="__nav_2_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Loaders
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_3_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_3_1">
            <span class="md-nav__icon md-icon"></span>
            Loaders
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ip_adapter/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    IP-Adapter
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../lora/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    LoRA
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PEFT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../single_file/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Single file
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../textual_inversion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Textual Inversion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    UNet
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    UNet
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin" class="md-nav__link">
    <span class="md-ellipsis">
      UNet2DConditionLoadersMixin
    </span>
  </a>
  
    <nav class="md-nav" aria-label="UNet2DConditionLoadersMixin">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.delete_adapters" class="md-nav__link">
    <span class="md-ellipsis">
      delete_adapters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.disable_lora" class="md-nav__link">
    <span class="md-ellipsis">
      disable_lora
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.enable_lora" class="md-nav__link">
    <span class="md-ellipsis">
      enable_lora
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.load_attn_procs" class="md-nav__link">
    <span class="md-ellipsis">
      load_attn_procs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.save_attn_procs" class="md-nav__link">
    <span class="md-ellipsis">
      save_attn_procs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.set_adapters" class="md-nav__link">
    <span class="md-ellipsis">
      set_adapters
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3_2" >
        
          
          <label class="md-nav__link" for="__nav_2_3_2" id="__nav_2_3_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Models
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_3_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3_2">
            <span class="md-nav__icon md-icon"></span>
            Models
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/unet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UNet1DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/unet2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UNet2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/unet2d-cond/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UNet2DConditionModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/unet3d-cond/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UNet3DConditionModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/unet-motion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UNetMotionModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/uvit2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UViT2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/vq/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    UVQModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/autoencoderkl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AutoEncoderKL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/asymmetricautoencoderkl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AsymmetricAutoEncoderKL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/autoencoder_tiny/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Tiny AutoEncoder
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/consistency_decoder_vae/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ConsistencyDecoderVae
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/transformer2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Transformer2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/pixart_transformer2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PixArtTransformer2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/dit_transformer2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DiTTransformer2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/hunyuan_transformer2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    HunyuanDiT2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/transformer_temporal/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    TransformerTemporalModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/sd3_transformer2d/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SD3Transformer2DModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/prior_transformer/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PriorTransformer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/controlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNetModel
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../models/controlnet_sd3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    SD3ControlNetModel
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3_3" >
        
          
          <label class="md-nav__link" for="__nav_2_3_3" id="__nav_2_3_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Pipelines
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_3_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3_3">
            <span class="md-nav__icon md-icon"></span>
            Pipelines
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/animatediff/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    AnimateDiff
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/blip_diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    BLIP-Diffusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/consistency_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Consistency Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/controlnet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNet
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/controlnet_sd3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNet with Stable Diffusion 3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/controlnetxs/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNet-XS
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/controlnetxs_sdxl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ControlNet-XS with Stable Diffusion XL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/dance_diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dance Diffusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/ddim/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DDIM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/ddpm/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DDPM
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/deepfloyd_if/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DeepFloyd IF
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/diffedit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DiffEdit
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/dit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    DiT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/hunyuandit/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Hunyuan-DiT
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/i2vgenxl/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    I2VGen-XL
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/pix2pix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    InstructPix2Pix
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/kandinsky/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kandinsky 2.1
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/kandinsky_v22/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kandinsky 2.2
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/kandinsky3/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Kandinsky 3
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/latent_consistency_models/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Latent Consistency Models
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/latent_diffusion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Latent Diffusion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/marigold/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Marigold
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/pixart/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PixArt-Î±
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/pixart_sigma/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PixArt-Î£
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/shap_e/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Shap-E
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/stable_cascade/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stable Cascade
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/unclip/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    unCLIP
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../pipelines/wuerstchen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Wuerstchen
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3_4" >
        
          
          <label class="md-nav__link" for="__nav_2_3_4" id="__nav_2_3_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Internal Class
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_3_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_3_4">
            <span class="md-nav__icon md-icon"></span>
            Internal Class
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../internal_classes_overview/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Overview
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../attnprocessor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Attention Processor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../activations/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom activation functions
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../normalization/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Custom Normalization Layer
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../utilities/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Utilities
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../image_processor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    VAE Image Processor
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../video_processor/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Video Processor
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Transformers
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Transformers
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_1" >
        
          
          <label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Get started
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_1">
            <span class="md-nav__icon md-icon"></span>
            Get started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../transformers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ðŸ¤— Transformers
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    PEFT
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            PEFT
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
      
      
        
      
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_1" >
        
          
          <label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Get started
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_1">
            <span class="md-nav__icon md-icon"></span>
            Get started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../peft/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    ðŸ¤— PEFT
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin" class="md-nav__link">
    <span class="md-ellipsis">
      UNet2DConditionLoadersMixin
    </span>
  </a>
  
    <nav class="md-nav" aria-label="UNet2DConditionLoadersMixin">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.delete_adapters" class="md-nav__link">
    <span class="md-ellipsis">
      delete_adapters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.disable_lora" class="md-nav__link">
    <span class="md-ellipsis">
      disable_lora
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.enable_lora" class="md-nav__link">
    <span class="md-ellipsis">
      enable_lora
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.load_attn_procs" class="md-nav__link">
    <span class="md-ellipsis">
      load_attn_procs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.save_attn_procs" class="md-nav__link">
    <span class="md-ellipsis">
      save_attn_procs
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.set_adapters" class="md-nav__link">
    <span class="md-ellipsis">
      set_adapters
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/mindspore-lab/mindone/edit/master/docs/diffusers/api/loaders/unet.md" title="Edit this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/mindspore-lab/mindone/raw/master/docs/diffusers/api/loaders/unet.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<!--Copyright 2024 The HuggingFace Team. All rights reserved.

Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file except in compliance with
the License. You may obtain a copy of the License at

http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on
an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the
specific language governing permissions and limitations under the License.
-->

<h1 id="unet">UNet<a class="headerlink" href="#unet" title="Permanent link">&para;</a></h1>
<p>Some training methods - like LoRA and Custom Diffusion - typically target the UNet's attention layers, but these training methods can also target other non-attention layers. Instead of training all of a model's parameters, only a subset of the parameters are trained, which is faster and more efficient. This class is useful if you're <em>only</em> loading weights into a UNet. If you need to load weights into the text encoder or a text encoder and UNet, try using the <a href="../lora/#mindone.diffusers.loaders.lora.LoraLoaderMixin.load_lora_weights"><code>load_lora_weights</code></a> function instead.</p>
<p>The <a href="./#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin"><code>UNet2DConditionLoadersMixin</code></a> class provides functions for loading and saving weights, fusing and unfusing LoRAs, disabling and enabling LoRAs, and setting and deleting adapters.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>To learn more about how to load LoRA weights, see the <a href="../../using-diffusers/loading_adapters.md#lora">LoRA</a> loading guide.</p>
</div>


<div class="doc doc-object doc-class">



<h2 id="mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin" class="doc doc-heading">
            <code>mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin</code>


<a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents first">


        <p>Load LoRA layers into a [<code>UNet2DConditionModel</code>].</p>

              <details class="quote">
                <summary>Source code in <code>mindone/diffusers/loaders/unet.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span>
<span class="normal">548</span>
<span class="normal">549</span>
<span class="normal">550</span>
<span class="normal">551</span>
<span class="normal">552</span>
<span class="normal">553</span>
<span class="normal">554</span>
<span class="normal">555</span>
<span class="normal">556</span>
<span class="normal">557</span>
<span class="normal">558</span>
<span class="normal">559</span>
<span class="normal">560</span>
<span class="normal">561</span>
<span class="normal">562</span>
<span class="normal">563</span>
<span class="normal">564</span>
<span class="normal">565</span>
<span class="normal">566</span>
<span class="normal">567</span>
<span class="normal">568</span>
<span class="normal">569</span>
<span class="normal">570</span>
<span class="normal">571</span>
<span class="normal">572</span>
<span class="normal">573</span>
<span class="normal">574</span>
<span class="normal">575</span>
<span class="normal">576</span>
<span class="normal">577</span>
<span class="normal">578</span>
<span class="normal">579</span>
<span class="normal">580</span>
<span class="normal">581</span>
<span class="normal">582</span>
<span class="normal">583</span>
<span class="normal">584</span>
<span class="normal">585</span>
<span class="normal">586</span>
<span class="normal">587</span>
<span class="normal">588</span>
<span class="normal">589</span>
<span class="normal">590</span>
<span class="normal">591</span>
<span class="normal">592</span>
<span class="normal">593</span>
<span class="normal">594</span>
<span class="normal">595</span>
<span class="normal">596</span>
<span class="normal">597</span>
<span class="normal">598</span>
<span class="normal">599</span>
<span class="normal">600</span>
<span class="normal">601</span>
<span class="normal">602</span>
<span class="normal">603</span>
<span class="normal">604</span>
<span class="normal">605</span>
<span class="normal">606</span>
<span class="normal">607</span>
<span class="normal">608</span>
<span class="normal">609</span>
<span class="normal">610</span>
<span class="normal">611</span>
<span class="normal">612</span>
<span class="normal">613</span>
<span class="normal">614</span>
<span class="normal">615</span>
<span class="normal">616</span>
<span class="normal">617</span>
<span class="normal">618</span>
<span class="normal">619</span>
<span class="normal">620</span>
<span class="normal">621</span>
<span class="normal">622</span>
<span class="normal">623</span>
<span class="normal">624</span>
<span class="normal">625</span>
<span class="normal">626</span>
<span class="normal">627</span>
<span class="normal">628</span>
<span class="normal">629</span>
<span class="normal">630</span>
<span class="normal">631</span>
<span class="normal">632</span>
<span class="normal">633</span>
<span class="normal">634</span>
<span class="normal">635</span>
<span class="normal">636</span>
<span class="normal">637</span>
<span class="normal">638</span>
<span class="normal">639</span>
<span class="normal">640</span>
<span class="normal">641</span>
<span class="normal">642</span>
<span class="normal">643</span>
<span class="normal">644</span>
<span class="normal">645</span>
<span class="normal">646</span>
<span class="normal">647</span>
<span class="normal">648</span>
<span class="normal">649</span>
<span class="normal">650</span>
<span class="normal">651</span>
<span class="normal">652</span>
<span class="normal">653</span>
<span class="normal">654</span>
<span class="normal">655</span>
<span class="normal">656</span>
<span class="normal">657</span>
<span class="normal">658</span>
<span class="normal">659</span>
<span class="normal">660</span>
<span class="normal">661</span>
<span class="normal">662</span>
<span class="normal">663</span>
<span class="normal">664</span>
<span class="normal">665</span>
<span class="normal">666</span>
<span class="normal">667</span>
<span class="normal">668</span>
<span class="normal">669</span>
<span class="normal">670</span>
<span class="normal">671</span>
<span class="normal">672</span>
<span class="normal">673</span>
<span class="normal">674</span>
<span class="normal">675</span>
<span class="normal">676</span>
<span class="normal">677</span>
<span class="normal">678</span>
<span class="normal">679</span>
<span class="normal">680</span>
<span class="normal">681</span>
<span class="normal">682</span>
<span class="normal">683</span>
<span class="normal">684</span>
<span class="normal">685</span>
<span class="normal">686</span>
<span class="normal">687</span>
<span class="normal">688</span>
<span class="normal">689</span>
<span class="normal">690</span>
<span class="normal">691</span>
<span class="normal">692</span>
<span class="normal">693</span>
<span class="normal">694</span>
<span class="normal">695</span>
<span class="normal">696</span>
<span class="normal">697</span>
<span class="normal">698</span>
<span class="normal">699</span>
<span class="normal">700</span>
<span class="normal">701</span>
<span class="normal">702</span>
<span class="normal">703</span>
<span class="normal">704</span>
<span class="normal">705</span>
<span class="normal">706</span>
<span class="normal">707</span>
<span class="normal">708</span>
<span class="normal">709</span>
<span class="normal">710</span>
<span class="normal">711</span>
<span class="normal">712</span>
<span class="normal">713</span>
<span class="normal">714</span>
<span class="normal">715</span>
<span class="normal">716</span>
<span class="normal">717</span>
<span class="normal">718</span>
<span class="normal">719</span>
<span class="normal">720</span>
<span class="normal">721</span>
<span class="normal">722</span>
<span class="normal">723</span>
<span class="normal">724</span>
<span class="normal">725</span>
<span class="normal">726</span>
<span class="normal">727</span>
<span class="normal">728</span>
<span class="normal">729</span>
<span class="normal">730</span>
<span class="normal">731</span>
<span class="normal">732</span>
<span class="normal">733</span>
<span class="normal">734</span>
<span class="normal">735</span>
<span class="normal">736</span>
<span class="normal">737</span>
<span class="normal">738</span>
<span class="normal">739</span>
<span class="normal">740</span>
<span class="normal">741</span>
<span class="normal">742</span>
<span class="normal">743</span>
<span class="normal">744</span>
<span class="normal">745</span>
<span class="normal">746</span>
<span class="normal">747</span>
<span class="normal">748</span>
<span class="normal">749</span>
<span class="normal">750</span>
<span class="normal">751</span>
<span class="normal">752</span>
<span class="normal">753</span>
<span class="normal">754</span>
<span class="normal">755</span>
<span class="normal">756</span>
<span class="normal">757</span>
<span class="normal">758</span>
<span class="normal">759</span>
<span class="normal">760</span>
<span class="normal">761</span>
<span class="normal">762</span>
<span class="normal">763</span>
<span class="normal">764</span>
<span class="normal">765</span>
<span class="normal">766</span>
<span class="normal">767</span>
<span class="normal">768</span>
<span class="normal">769</span>
<span class="normal">770</span>
<span class="normal">771</span>
<span class="normal">772</span>
<span class="normal">773</span>
<span class="normal">774</span>
<span class="normal">775</span>
<span class="normal">776</span>
<span class="normal">777</span>
<span class="normal">778</span>
<span class="normal">779</span>
<span class="normal">780</span>
<span class="normal">781</span>
<span class="normal">782</span>
<span class="normal">783</span>
<span class="normal">784</span>
<span class="normal">785</span>
<span class="normal">786</span>
<span class="normal">787</span>
<span class="normal">788</span>
<span class="normal">789</span>
<span class="normal">790</span>
<span class="normal">791</span>
<span class="normal">792</span>
<span class="normal">793</span>
<span class="normal">794</span>
<span class="normal">795</span>
<span class="normal">796</span>
<span class="normal">797</span>
<span class="normal">798</span>
<span class="normal">799</span>
<span class="normal">800</span>
<span class="normal">801</span>
<span class="normal">802</span>
<span class="normal">803</span>
<span class="normal">804</span>
<span class="normal">805</span>
<span class="normal">806</span>
<span class="normal">807</span>
<span class="normal">808</span>
<span class="normal">809</span>
<span class="normal">810</span>
<span class="normal">811</span>
<span class="normal">812</span>
<span class="normal">813</span>
<span class="normal">814</span>
<span class="normal">815</span>
<span class="normal">816</span>
<span class="normal">817</span>
<span class="normal">818</span>
<span class="normal">819</span>
<span class="normal">820</span>
<span class="normal">821</span>
<span class="normal">822</span>
<span class="normal">823</span>
<span class="normal">824</span>
<span class="normal">825</span>
<span class="normal">826</span>
<span class="normal">827</span>
<span class="normal">828</span>
<span class="normal">829</span>
<span class="normal">830</span>
<span class="normal">831</span>
<span class="normal">832</span>
<span class="normal">833</span>
<span class="normal">834</span>
<span class="normal">835</span>
<span class="normal">836</span>
<span class="normal">837</span>
<span class="normal">838</span>
<span class="normal">839</span>
<span class="normal">840</span>
<span class="normal">841</span>
<span class="normal">842</span>
<span class="normal">843</span>
<span class="normal">844</span>
<span class="normal">845</span>
<span class="normal">846</span>
<span class="normal">847</span>
<span class="normal">848</span>
<span class="normal">849</span>
<span class="normal">850</span>
<span class="normal">851</span>
<span class="normal">852</span>
<span class="normal">853</span>
<span class="normal">854</span>
<span class="normal">855</span>
<span class="normal">856</span>
<span class="normal">857</span>
<span class="normal">858</span>
<span class="normal">859</span>
<span class="normal">860</span>
<span class="normal">861</span>
<span class="normal">862</span>
<span class="normal">863</span>
<span class="normal">864</span>
<span class="normal">865</span>
<span class="normal">866</span>
<span class="normal">867</span>
<span class="normal">868</span>
<span class="normal">869</span>
<span class="normal">870</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span> <span class="nc">UNet2DConditionLoadersMixin</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load LoRA layers into a [`UNet2DConditionModel`].</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">text_encoder_name</span> <span class="o">=</span> <span class="n">TEXT_ENCODER_NAME</span>
    <span class="n">unet_name</span> <span class="o">=</span> <span class="n">UNET_NAME</span>

    <span class="nd">@validate_hf_hub_args</span>
    <span class="k">def</span> <span class="nf">load_attn_procs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pretrained_model_name_or_path_or_dict</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Load pretrained attention processor layers into [`UNet2DConditionModel`]. Attention processor layers have to be</span>
<span class="sd">        defined in</span>
<span class="sd">        [`attention_processor.py`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)</span>
<span class="sd">        and be a `mindspore.nn.Cell` class. Currently supported: LoRA, Custom Diffusion. For LoRA, one must install</span>
<span class="sd">        `peft`: `pip install -U peft`.</span>

<span class="sd">        Parameters:</span>
<span class="sd">            pretrained_model_name_or_path_or_dict (`str` or `os.PathLike` or `dict`):</span>
<span class="sd">                Can be either:</span>

<span class="sd">                    - A string, the model id (for example `google/ddpm-celebahq-256`) of a pretrained model hosted on</span>
<span class="sd">                      the Hub.</span>
<span class="sd">                    - A path to a directory (for example `./my_model_directory`) containing the model weights saved</span>
<span class="sd">                      with [`ModelMixin.save_pretrained`].</span>
<span class="sd">                    - A mindspore state dict.</span>

<span class="sd">            cache_dir (`Union[str, os.PathLike]`, *optional*):</span>
<span class="sd">                Path to a directory where a downloaded pretrained model configuration is cached if the standard cache</span>
<span class="sd">                is not used.</span>
<span class="sd">            force_download (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                Whether or not to force the (re-)download of the model weights and configuration files, overriding the</span>
<span class="sd">                cached versions if they exist.</span>
<span class="sd">            resume_download:</span>
<span class="sd">                Deprecated and ignored. All downloads are now resumed by default when possible. Will be removed in v1</span>
<span class="sd">                of Diffusers.</span>
<span class="sd">            proxies (`Dict[str, str]`, *optional*):</span>
<span class="sd">                A dictionary of proxy servers to use by protocol or endpoint, for example, `{&#39;http&#39;: &#39;foo.bar:3128&#39;,</span>
<span class="sd">                &#39;http://hostname&#39;: &#39;foo.bar:4012&#39;}`. The proxies are used on each request.</span>
<span class="sd">            local_files_only (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">                Whether to only load local model weights and configuration files or not. If set to `True`, the model</span>
<span class="sd">                won&#39;t be downloaded from the Hub.</span>
<span class="sd">            token (`str` or *bool*, *optional*):</span>
<span class="sd">                The token to use as HTTP bearer authorization for remote files. If `True`, the token generated from</span>
<span class="sd">                `diffusers-cli login` (stored in `~/.huggingface`) is used.</span>
<span class="sd">            revision (`str`, *optional*, defaults to `&quot;main&quot;`):</span>
<span class="sd">                The specific model version to use. It can be a branch name, a tag name, a commit id, or any identifier</span>
<span class="sd">                allowed by Git.</span>
<span class="sd">            subfolder (`str`, *optional*, defaults to `&quot;&quot;`):</span>
<span class="sd">                The subfolder location of a model file within a larger model repository on the Hub or locally.</span>
<span class="sd">            network_alphas (`Dict[str, float]`):</span>
<span class="sd">                The value of the network alpha used for stable learning and preventing underflow. This value has the</span>
<span class="sd">                same meaning as the `--network_alpha` option in the kohya-ss trainer script. Refer to [this</span>
<span class="sd">                link](https://github.com/darkstorm2150/sd-scripts/blob/main/docs/train_network_README-en.md#execute-learning).</span>
<span class="sd">            adapter_name (`str`, *optional*, defaults to None):</span>
<span class="sd">                Adapter name to be used for referencing the loaded adapter model. If not specified, it will use</span>
<span class="sd">                `default_{i}` where i is the total number of adapters being loaded.</span>
<span class="sd">            weight_name (`str`, *optional*, defaults to None):</span>
<span class="sd">                Name of the serialized state dict file.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        from mindone.diffusers import AutoPipelineForText2Image</span>
<span class="sd">        import mindspore as ms</span>

<span class="sd">        pipeline = AutoPipelineForText2Image.from_pretrained(</span>
<span class="sd">            &quot;stabilityai/stable-diffusion-xl-base-1.0&quot;, mindspore_dtype=ms.float16</span>
<span class="sd">        )</span>
<span class="sd">        pipeline.unet.load_attn_procs(</span>
<span class="sd">            &quot;jbilcke-hf/sdxl-cinematic-1&quot;, weight_name=&quot;pytorch_lora_weights.safetensors&quot;, adapter_name=&quot;cinematic&quot;</span>
<span class="sd">        )</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">cache_dir</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;cache_dir&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">force_download</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;force_download&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
        <span class="n">resume_download</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;resume_download&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">proxies</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;proxies&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">local_files_only</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;local_files_only&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">token</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">revision</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;revision&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">subfolder</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;subfolder&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">weight_name</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;weight_name&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">use_safetensors</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;use_safetensors&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">adapter_name</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;adapter_name&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">_pipeline</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_pipeline&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">network_alphas</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;network_alphas&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">allow_pickle</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="n">_pipeline</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_pipeline&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>  <span class="c1"># noqa: F841</span>

        <span class="n">is_network_alphas_none</span> <span class="o">=</span> <span class="n">network_alphas</span> <span class="ow">is</span> <span class="kc">None</span>  <span class="c1"># noqa: F841</span>

        <span class="n">allow_pickle</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">use_safetensors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">use_safetensors</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="n">allow_pickle</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="n">user_agent</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;file_type&quot;</span><span class="p">:</span> <span class="s2">&quot;attn_procs_weights&quot;</span><span class="p">,</span>
            <span class="s2">&quot;framework&quot;</span><span class="p">:</span> <span class="s2">&quot;pytorch&quot;</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="n">model_file</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pretrained_model_name_or_path_or_dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
            <span class="c1"># Let&#39;s first try to load .safetensors weights</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">use_safetensors</span> <span class="ow">and</span> <span class="n">weight_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
                <span class="n">weight_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">weight_name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.safetensors&quot;</span><span class="p">)</span>
            <span class="p">):</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">model_file</span> <span class="o">=</span> <span class="n">_get_model_file</span><span class="p">(</span>
                        <span class="n">pretrained_model_name_or_path_or_dict</span><span class="p">,</span>
                        <span class="n">weights_name</span><span class="o">=</span><span class="n">weight_name</span> <span class="ow">or</span> <span class="n">LORA_WEIGHT_NAME_SAFE</span><span class="p">,</span>
                        <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span>
                        <span class="n">force_download</span><span class="o">=</span><span class="n">force_download</span><span class="p">,</span>
                        <span class="n">resume_download</span><span class="o">=</span><span class="n">resume_download</span><span class="p">,</span>
                        <span class="n">proxies</span><span class="o">=</span><span class="n">proxies</span><span class="p">,</span>
                        <span class="n">local_files_only</span><span class="o">=</span><span class="n">local_files_only</span><span class="p">,</span>
                        <span class="n">token</span><span class="o">=</span><span class="n">token</span><span class="p">,</span>
                        <span class="n">revision</span><span class="o">=</span><span class="n">revision</span><span class="p">,</span>
                        <span class="n">subfolder</span><span class="o">=</span><span class="n">subfolder</span><span class="p">,</span>
                        <span class="n">user_agent</span><span class="o">=</span><span class="n">user_agent</span><span class="p">,</span>
                    <span class="p">)</span>
                    <span class="n">state_dict</span> <span class="o">=</span> <span class="n">load_file</span><span class="p">(</span><span class="n">model_file</span><span class="p">)</span>
                <span class="k">except</span> <span class="ne">IOError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                    <span class="k">if</span> <span class="ow">not</span> <span class="n">allow_pickle</span><span class="p">:</span>
                        <span class="k">raise</span> <span class="n">e</span>
                    <span class="c1"># try loading non-safetensors weights</span>
                    <span class="k">pass</span>
            <span class="k">if</span> <span class="n">model_file</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">model_file</span> <span class="o">=</span> <span class="n">_get_model_file</span><span class="p">(</span>
                    <span class="n">pretrained_model_name_or_path_or_dict</span><span class="p">,</span>
                    <span class="n">weights_name</span><span class="o">=</span><span class="n">weight_name</span> <span class="ow">or</span> <span class="n">LORA_WEIGHT_NAME</span><span class="p">,</span>
                    <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span>
                    <span class="n">force_download</span><span class="o">=</span><span class="n">force_download</span><span class="p">,</span>
                    <span class="n">resume_download</span><span class="o">=</span><span class="n">resume_download</span><span class="p">,</span>
                    <span class="n">proxies</span><span class="o">=</span><span class="n">proxies</span><span class="p">,</span>
                    <span class="n">local_files_only</span><span class="o">=</span><span class="n">local_files_only</span><span class="p">,</span>
                    <span class="n">token</span><span class="o">=</span><span class="n">token</span><span class="p">,</span>
                    <span class="n">revision</span><span class="o">=</span><span class="n">revision</span><span class="p">,</span>
                    <span class="n">subfolder</span><span class="o">=</span><span class="n">subfolder</span><span class="p">,</span>
                    <span class="n">user_agent</span><span class="o">=</span><span class="n">user_agent</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Only supports deserialization of weights file in safetensors format, but got </span><span class="si">{</span><span class="n">model_file</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">pretrained_model_name_or_path_or_dict</span>

        <span class="n">is_custom_diffusion</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="s2">&quot;custom_diffusion&quot;</span> <span class="ow">in</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">is_lora</span> <span class="o">=</span> <span class="nb">all</span><span class="p">((</span><span class="s2">&quot;lora&quot;</span> <span class="ow">in</span> <span class="n">k</span> <span class="ow">or</span> <span class="n">k</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.alpha&quot;</span><span class="p">))</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

        <span class="k">if</span> <span class="n">is_custom_diffusion</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;CustomDiffusionAttnProcessor is not yet supported.&quot;</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">is_lora</span><span class="p">:</span>
            <span class="n">is_model_cpu_offload</span><span class="p">,</span> <span class="n">is_sequential_cpu_offload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_lora</span><span class="p">(</span>
                <span class="n">state_dict</span><span class="o">=</span><span class="n">state_dict</span><span class="p">,</span>
                <span class="n">unet_identifier_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unet_name</span><span class="p">,</span>
                <span class="n">network_alphas</span><span class="o">=</span><span class="n">network_alphas</span><span class="p">,</span>
                <span class="n">adapter_name</span><span class="o">=</span><span class="n">adapter_name</span><span class="p">,</span>
                <span class="n">_pipeline</span><span class="o">=</span><span class="n">_pipeline</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_file</span><span class="si">}</span><span class="s2"> does not seem to be in the correct format expected by Custom Diffusion training.&quot;</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">_process_lora</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">,</span> <span class="n">unet_identifier_key</span><span class="p">,</span> <span class="n">network_alphas</span><span class="p">,</span> <span class="n">adapter_name</span><span class="p">,</span> <span class="n">_pipeline</span><span class="p">):</span>
        <span class="c1"># This method does the following things:</span>
        <span class="c1"># 1. Filters the `state_dict` with keys matching  `unet_identifier_key` when using the non-legacy</span>
        <span class="c1">#    format. For legacy format no filtering is applied.</span>
        <span class="c1"># 2. Converts the `state_dict` to the `peft` compatible format.</span>
        <span class="c1"># 3. Creates a `LoraConfig` and then injects the converted `state_dict` into the UNet per the</span>
        <span class="c1">#    `LoraConfig` specs.</span>
        <span class="c1"># 4. It also reports if the underlying `_pipeline` has any kind of offloading inside of it.</span>
        <span class="kn">from</span> <span class="nn">mindone.diffusers._peft</span> <span class="kn">import</span> <span class="n">LoraConfig</span><span class="p">,</span> <span class="n">inject_adapter_in_model</span><span class="p">,</span> <span class="n">set_peft_model_state_dict</span>

        <span class="n">keys</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">state_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

        <span class="n">unet_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">keys</span> <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">unet_identifier_key</span><span class="p">)]</span>
        <span class="n">unet_state_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">unet_identifier_key</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">):</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">unet_keys</span><span class="p">}</span>

        <span class="k">if</span> <span class="n">network_alphas</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">alpha_keys</span> <span class="o">=</span> <span class="p">[</span><span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">network_alphas</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">unet_identifier_key</span><span class="p">)]</span>
            <span class="n">network_alphas</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">k</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">unet_identifier_key</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">):</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">network_alphas</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">alpha_keys</span>
            <span class="p">}</span>

        <span class="n">is_model_cpu_offload</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">is_sequential_cpu_offload</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">state_dict_to_be_used</span> <span class="o">=</span> <span class="n">unet_state_dict</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">unet_state_dict</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">state_dict</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">state_dict_to_be_used</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">adapter_name</span> <span class="ow">in</span> <span class="nb">getattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;peft_config&quot;</span><span class="p">,</span> <span class="p">{}):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Adapter name </span><span class="si">{</span><span class="n">adapter_name</span><span class="si">}</span><span class="s2"> already in use in the Unet - please select a new adapter name.&quot;</span>
                <span class="p">)</span>

            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">convert_unet_state_dict_to_peft</span><span class="p">(</span><span class="n">state_dict_to_be_used</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">network_alphas</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># The alphas state dict have the same structure as Unet, thus we convert it to peft format using</span>
                <span class="c1"># `convert_unet_state_dict_to_peft` method.</span>
                <span class="n">network_alphas</span> <span class="o">=</span> <span class="n">convert_unet_state_dict_to_peft</span><span class="p">(</span><span class="n">network_alphas</span><span class="p">)</span>

            <span class="n">rank</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="k">if</span> <span class="s2">&quot;lora_B&quot;</span> <span class="ow">in</span> <span class="n">key</span><span class="p">:</span>
                    <span class="n">rank</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

            <span class="n">lora_config_kwargs</span> <span class="o">=</span> <span class="n">get_peft_kwargs</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">network_alphas</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">,</span> <span class="n">is_unet</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="k">if</span> <span class="s2">&quot;use_dora&quot;</span> <span class="ow">in</span> <span class="n">lora_config_kwargs</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">lora_config_kwargs</span><span class="p">[</span><span class="s2">&quot;use_dora&quot;</span><span class="p">]:</span>
                    <span class="k">if</span> <span class="n">is_peft_version</span><span class="p">(</span><span class="s2">&quot;&lt;&quot;</span><span class="p">,</span> <span class="s2">&quot;0.9.0&quot;</span><span class="p">):</span>
                        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                            <span class="s2">&quot;You need `peft` 0.9.0 at least to use DoRA-enabled LoRAs. Please upgrade your installation of `peft`.&quot;</span>
                        <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="n">is_peft_version</span><span class="p">(</span><span class="s2">&quot;&lt;&quot;</span><span class="p">,</span> <span class="s2">&quot;0.9.0&quot;</span><span class="p">):</span>
                        <span class="n">lora_config_kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;use_dora&quot;</span><span class="p">)</span>
            <span class="n">lora_config</span> <span class="o">=</span> <span class="n">LoraConfig</span><span class="p">(</span><span class="o">**</span><span class="n">lora_config_kwargs</span><span class="p">)</span>

            <span class="c1"># adapter_name</span>
            <span class="k">if</span> <span class="n">adapter_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">adapter_name</span> <span class="o">=</span> <span class="n">get_adapter_name</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

            <span class="n">inject_adapter_in_model</span><span class="p">(</span><span class="n">lora_config</span><span class="p">,</span> <span class="bp">self</span><span class="p">,</span> <span class="n">adapter_name</span><span class="o">=</span><span class="n">adapter_name</span><span class="p">)</span>
            <span class="n">incompatible_keys</span> <span class="o">=</span> <span class="n">set_peft_model_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">,</span> <span class="n">adapter_name</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">incompatible_keys</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># check only for unexpected keys</span>
                <span class="n">unexpected_keys</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">incompatible_keys</span><span class="p">,</span> <span class="s2">&quot;unexpected_keys&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">unexpected_keys</span><span class="p">:</span>
                    <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Loading adapter weights from state_dict led to unexpected keys not found in the model: &quot;</span>
                        <span class="sa">f</span><span class="s2">&quot; </span><span class="si">{</span><span class="n">unexpected_keys</span><span class="si">}</span><span class="s2">. &quot;</span>
                    <span class="p">)</span>

        <span class="k">return</span> <span class="n">is_model_cpu_offload</span><span class="p">,</span> <span class="n">is_sequential_cpu_offload</span>

    <span class="k">def</span> <span class="nf">save_attn_procs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">save_directory</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">],</span>
        <span class="n">is_main_process</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">weight_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">save_function</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">safe_serialization</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Save attention processor layers to a directory so that it can be reloaded with the</span>
<span class="sd">        [`~loaders.UNet2DConditionLoadersMixin.load_attn_procs`] method.</span>

<span class="sd">        Arguments:</span>
<span class="sd">            save_directory (`str` or `os.PathLike`):</span>
<span class="sd">                Directory to save an attention processor to (will be created if it doesn&#39;t exist).</span>
<span class="sd">            is_main_process (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">                Whether the process calling this is the main process or not. Useful during distributed training and you</span>
<span class="sd">                need to call this function on all processes. In this case, set `is_main_process=True` only on the main</span>
<span class="sd">                process to avoid race conditions.</span>
<span class="sd">            save_function (`Callable`):</span>
<span class="sd">                The function to use to save the state dictionary. Useful during distributed training when you need to</span>
<span class="sd">                replace `MindSpore.save_checkpoint` with another method. Can be configured with the environment variable</span>
<span class="sd">                `DIFFUSERS_SAVE_MODE`.</span>
<span class="sd">            safe_serialization (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">                Whether to save the model using `safetensors` or with `pickle`.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        import mindspore</span>
<span class="sd">        from mindone.diffusers import DiffusionPipeline</span>

<span class="sd">        pipeline = DiffusionPipeline.from_pretrained(</span>
<span class="sd">            &quot;CompVis/stable-diffusion-v1-4&quot;,</span>
<span class="sd">            mindspore_dtype=mindspore.float16,</span>
<span class="sd">        )</span>
<span class="sd">        pipeline.unet.load_attn_procs(&quot;path-to-save-model&quot;, weight_name=&quot;lora_diffusion_weights.safetensors&quot;)</span>
<span class="sd">        pipeline.unet.save_attn_procs(&quot;path-to-save-model&quot;, weight_name=&quot;lora_diffusion_weights.safetensors&quot;)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="kn">from</span> <span class="nn">..models.attention_processor</span> <span class="kn">import</span> <span class="n">CustomDiffusionAttnProcessor</span>

        <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">save_directory</span><span class="p">):</span>
            <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Provided path (</span><span class="si">{</span><span class="n">save_directory</span><span class="si">}</span><span class="s2">) should be a directory, not a file&quot;</span><span class="p">)</span>
            <span class="k">return</span>

        <span class="n">is_custom_diffusion</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">CustomDiffusionAttnProcessor</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_processors</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">is_custom_diffusion</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;is_custom_diffusion is not yet supported in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.save_attn_procs .&quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="kn">from</span> <span class="nn">mindone.diffusers._peft.utils</span> <span class="kn">import</span> <span class="n">get_peft_model_state_dict</span>

            <span class="n">state_dict</span> <span class="o">=</span> <span class="n">get_peft_model_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">save_function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">safe_serialization</span><span class="p">:</span>
                <span class="n">save_function</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">save_file</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;np&quot;</span><span class="p">})</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">save_function</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">save_checkpoint</span>

        <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">weight_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">safe_serialization</span><span class="p">:</span>
                <span class="n">weight_name</span> <span class="o">=</span> <span class="n">CUSTOM_DIFFUSION_WEIGHT_NAME_SAFE</span> <span class="k">if</span> <span class="n">is_custom_diffusion</span> <span class="k">else</span> <span class="n">LORA_WEIGHT_NAME_SAFE</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">weight_name</span> <span class="o">=</span> <span class="n">CUSTOM_DIFFUSION_WEIGHT_NAME</span> <span class="k">if</span> <span class="n">is_custom_diffusion</span> <span class="k">else</span> <span class="n">LORA_WEIGHT_NAME</span>

        <span class="c1"># Save the model</span>
        <span class="n">save_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="n">weight_name</span><span class="p">)</span><span class="o">.</span><span class="n">as_posix</span><span class="p">()</span>
        <span class="n">save_function</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model weights saved in </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">fuse_lora</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lora_scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">safe_fusing</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">adapter_names</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lora_scale</span> <span class="o">=</span> <span class="n">lora_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_safe_fusing</span> <span class="o">=</span> <span class="n">safe_fusing</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_fuse_lora_apply</span><span class="p">,</span> <span class="n">adapter_names</span><span class="o">=</span><span class="n">adapter_names</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">_fuse_lora_apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">adapter_names</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">mindone.diffusers._peft.tuners.tuners_utils</span> <span class="kn">import</span> <span class="n">BaseTunerLayer</span>

        <span class="n">merge_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;safe_merge&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_safe_fusing</span><span class="p">}</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">BaseTunerLayer</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">lora_scale</span> <span class="o">!=</span> <span class="mf">1.0</span><span class="p">:</span>
                <span class="n">module</span><span class="o">.</span><span class="n">scale_layer</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lora_scale</span><span class="p">)</span>

            <span class="c1"># For BC with previous PEFT versions, we need to check the signature</span>
            <span class="c1"># of the `merge` method to see if it supports the `adapter_names` argument.</span>
            <span class="n">supported_merge_kwargs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">module</span><span class="o">.</span><span class="n">merge</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span><span class="p">)</span>
            <span class="k">if</span> <span class="s2">&quot;adapter_names&quot;</span> <span class="ow">in</span> <span class="n">supported_merge_kwargs</span><span class="p">:</span>
                <span class="n">merge_kwargs</span><span class="p">[</span><span class="s2">&quot;adapter_names&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">adapter_names</span>
            <span class="k">elif</span> <span class="s2">&quot;adapter_names&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">supported_merge_kwargs</span> <span class="ow">and</span> <span class="n">adapter_names</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;The `adapter_names` argument is not supported with `BaseTunerLayer.merge`&quot;</span><span class="p">)</span>

            <span class="n">module</span><span class="o">.</span><span class="n">merge</span><span class="p">(</span><span class="o">**</span><span class="n">merge_kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">unfuse_lora</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_unfuse_lora_apply</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_unfuse_lora_apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">mindone.diffusers._peft.tuners.tuners_utils</span> <span class="kn">import</span> <span class="n">BaseTunerLayer</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">BaseTunerLayer</span><span class="p">):</span>
            <span class="n">module</span><span class="o">.</span><span class="n">unmerge</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">unload_lora</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">..utils</span> <span class="kn">import</span> <span class="n">recurse_remove_peft_layers</span>

        <span class="n">recurse_remove_peft_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;peft_config&quot;</span><span class="p">):</span>
            <span class="k">del</span> <span class="bp">self</span><span class="o">.</span><span class="n">peft_config</span>

    <span class="k">def</span> <span class="nf">set_adapters</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">adapter_names</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">],</span>
        <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="kc">None</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the currently active adapters for use in the UNet.</span>

<span class="sd">        Args:</span>
<span class="sd">            adapter_names (`List[str]` or `str`):</span>
<span class="sd">                The names of the adapters to use.</span>
<span class="sd">            weights (`Union[List[float], float]`, *optional*):</span>
<span class="sd">                The adapter(s) weights to use with the UNet. If `None`, the weights are set to `1.0` for all the</span>
<span class="sd">                adapters.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        from mindone.diffusers import AutoPipelineForText2Image</span>
<span class="sd">        import mindspore as ms</span>

<span class="sd">        pipeline = AutoPipelineForText2Image.from_pretrained(</span>
<span class="sd">            &quot;stabilityai/stable-diffusion-xl-base-1.0&quot;, mindspore_dtype=ms.float16</span>
<span class="sd">        )</span>
<span class="sd">        pipeline.load_lora_weights(</span>
<span class="sd">            &quot;jbilcke-hf/sdxl-cinematic-1&quot;, weight_name=&quot;pytorch_lora_weights.safetensors&quot;, adapter_name=&quot;cinematic&quot;</span>
<span class="sd">        )</span>
<span class="sd">        pipeline.load_lora_weights(&quot;nerijs/pixel-art-xl&quot;, weight_name=&quot;pixel-art-xl.safetensors&quot;, adapter_name=&quot;pixel&quot;)</span>
<span class="sd">        pipeline.set_adapters([&quot;cinematic&quot;, &quot;pixel&quot;], adapter_weights=[0.5, 0.5])</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">adapter_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">adapter_names</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">adapter_names</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">adapter_names</span>

        <span class="c1"># Expand weights into a list, one entry per adapter</span>
        <span class="c1"># examples for e.g. 2 adapters:  [{...}, 7] -&gt; [7,7] ; None -&gt; [None, None]</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">weights</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">adapter_names</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">adapter_names</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Length of adapter names </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">adapter_names</span><span class="p">)</span><span class="si">}</span><span class="s2"> is not equal to the length of their weights </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Set None values to default of 1.0</span>
        <span class="c1"># e.g. [{...}, 7] -&gt; [{...}, 7] ; [None, None] -&gt; [1.0, 1.0]</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mf">1.0</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">weights</span><span class="p">]</span>

        <span class="c1"># e.g. [{...}, 7] -&gt; [{expanded dict...}, 7]</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">_maybe_expand_lora_scales</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>

        <span class="n">set_weights_and_activate_adapters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">adapter_names</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">disable_lora</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Disable the UNet&#39;s active LoRA layers.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        from mindone.diffusers import AutoPipelineForText2Image</span>
<span class="sd">        import mindspore as ms</span>

<span class="sd">        pipeline = AutoPipelineForText2Image.from_pretrained(</span>
<span class="sd">            &quot;stabilityai/stable-diffusion-xl-base-1.0&quot;, mindspore_dtype=ms.float16</span>
<span class="sd">        )</span>
<span class="sd">        pipeline.load_lora_weights(</span>
<span class="sd">            &quot;jbilcke-hf/sdxl-cinematic-1&quot;, weight_name=&quot;pytorch_lora_weights.safetensors&quot;, adapter_name=&quot;cinematic&quot;</span>
<span class="sd">        )</span>
<span class="sd">        pipeline.disable_lora()</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">set_adapter_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enabled</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">enable_lora</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Enable the UNet&#39;s active LoRA layers.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        from mindone.diffusers import AutoPipelineForText2Image</span>
<span class="sd">        import mindspore as ms</span>

<span class="sd">        pipeline = AutoPipelineForText2Image.from_pretrained(</span>
<span class="sd">            &quot;stabilityai/stable-diffusion-xl-base-1.0&quot;, mindspore_dtype=ms.float16</span>
<span class="sd">        )</span>
<span class="sd">        pipeline.load_lora_weights(</span>
<span class="sd">            &quot;jbilcke-hf/sdxl-cinematic-1&quot;, weight_name=&quot;pytorch_lora_weights.safetensors&quot;, adapter_name=&quot;cinematic&quot;</span>
<span class="sd">        )</span>
<span class="sd">        pipeline.enable_lora()</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">set_adapter_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enabled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">delete_adapters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">adapter_names</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">]):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Delete an adapter&#39;s LoRA layers from the UNet.</span>

<span class="sd">        Args:</span>
<span class="sd">            adapter_names (`Union[List[str], str]`):</span>
<span class="sd">                The names (single string or list of strings) of the adapter to delete.</span>

<span class="sd">        Example:</span>

<span class="sd">        ```py</span>
<span class="sd">        from mindone.diffusers import AutoPipelineForText2Image</span>
<span class="sd">        import mindspore as ms</span>

<span class="sd">        pipeline = AutoPipelineForText2Image.from_pretrained(</span>
<span class="sd">            &quot;stabilityai/stable-diffusion-xl-base-1.0&quot;, mindspore_dtype=ms.float16</span>
<span class="sd">        )</span>
<span class="sd">        pipeline.load_lora_weights(</span>
<span class="sd">            &quot;jbilcke-hf/sdxl-cinematic-1&quot;, weight_name=&quot;pytorch_lora_weights.safetensors&quot;, adapter_names=&quot;cinematic&quot;</span>
<span class="sd">        )</span>
<span class="sd">        pipeline.delete_adapters(&quot;cinematic&quot;)</span>
<span class="sd">        ```</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">adapter_names</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">adapter_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">adapter_names</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">adapter_name</span> <span class="ow">in</span> <span class="n">adapter_names</span><span class="p">:</span>
            <span class="n">delete_adapter_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">adapter_name</span><span class="p">)</span>

            <span class="c1"># Pop also the corresponding adapter from the config</span>
            <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;peft_config&quot;</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">peft_config</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">adapter_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_convert_ip_adapter_image_proj_to_diffusers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dict</span><span class="p">):</span>
        <span class="n">updated_state_dict</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">image_projection</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="s2">&quot;proj.weight&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">:</span>
            <span class="c1"># IP-Adapter</span>
            <span class="n">num_image_text_embeds</span> <span class="o">=</span> <span class="mi">4</span>
            <span class="n">clip_embeddings_dim</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;proj.weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">cross_attention_dim</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;proj.weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">4</span>

            <span class="n">image_projection</span> <span class="o">=</span> <span class="n">ImageProjection</span><span class="p">(</span>
                <span class="n">cross_attention_dim</span><span class="o">=</span><span class="n">cross_attention_dim</span><span class="p">,</span>
                <span class="n">image_embed_dim</span><span class="o">=</span><span class="n">clip_embeddings_dim</span><span class="p">,</span>
                <span class="n">num_image_text_embeds</span><span class="o">=</span><span class="n">num_image_text_embeds</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;proj&quot;</span><span class="p">,</span> <span class="s2">&quot;image_embeds&quot;</span><span class="p">)</span>
                <span class="n">updated_state_dict</span><span class="p">[</span><span class="n">diffusers_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

        <span class="k">elif</span> <span class="s2">&quot;proj.3.weight&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">:</span>
            <span class="c1"># IP-Adapter Full</span>
            <span class="n">clip_embeddings_dim</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;proj.0.weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">cross_attention_dim</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;proj.3.weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

            <span class="n">image_projection</span> <span class="o">=</span> <span class="n">IPAdapterFullImageProjection</span><span class="p">(</span>
                <span class="n">cross_attention_dim</span><span class="o">=</span><span class="n">cross_attention_dim</span><span class="p">,</span> <span class="n">image_embed_dim</span><span class="o">=</span><span class="n">clip_embeddings_dim</span>
            <span class="p">)</span>

            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;proj.0&quot;</span><span class="p">,</span> <span class="s2">&quot;ff.net.0.proj&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;proj.2&quot;</span><span class="p">,</span> <span class="s2">&quot;ff.net.2&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;proj.3&quot;</span><span class="p">,</span> <span class="s2">&quot;norm&quot;</span><span class="p">)</span>
                <span class="n">updated_state_dict</span><span class="p">[</span><span class="n">diffusers_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="k">elif</span> <span class="s2">&quot;perceiver_resampler.proj_in.weight&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">:</span>
            <span class="c1"># IP-Adapter Face ID Plus</span>
            <span class="n">id_embeddings_dim</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;proj.0.weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">embed_dims</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;perceiver_resampler.proj_in.weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">hidden_dims</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;perceiver_resampler.proj_in.weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">output_dims</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;perceiver_resampler.proj_out.weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">heads</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;perceiver_resampler.layers.0.0.to_q.weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">64</span>

            <span class="n">image_projection</span> <span class="o">=</span> <span class="n">IPAdapterFaceIDPlusImageProjection</span><span class="p">(</span>
                <span class="n">embed_dims</span><span class="o">=</span><span class="n">embed_dims</span><span class="p">,</span>
                <span class="n">output_dims</span><span class="o">=</span><span class="n">output_dims</span><span class="p">,</span>
                <span class="n">hidden_dims</span><span class="o">=</span><span class="n">hidden_dims</span><span class="p">,</span>
                <span class="n">heads</span><span class="o">=</span><span class="n">heads</span><span class="p">,</span>
                <span class="n">id_embeddings_dim</span><span class="o">=</span><span class="n">id_embeddings_dim</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;perceiver_resampler.&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;0.to&quot;</span><span class="p">,</span> <span class="s2">&quot;attn.to&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;0.1.0.&quot;</span><span class="p">,</span> <span class="s2">&quot;0.ff.0.&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;0.1.1.weight&quot;</span><span class="p">,</span> <span class="s2">&quot;0.ff.1.net.0.proj.weight&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;0.1.3.weight&quot;</span><span class="p">,</span> <span class="s2">&quot;0.ff.1.net.2.weight&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;1.1.0.&quot;</span><span class="p">,</span> <span class="s2">&quot;1.ff.0.&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;1.1.1.weight&quot;</span><span class="p">,</span> <span class="s2">&quot;1.ff.1.net.0.proj.weight&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;1.1.3.weight&quot;</span><span class="p">,</span> <span class="s2">&quot;1.ff.1.net.2.weight&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;2.1.0.&quot;</span><span class="p">,</span> <span class="s2">&quot;2.ff.0.&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;2.1.1.weight&quot;</span><span class="p">,</span> <span class="s2">&quot;2.ff.1.net.0.proj.weight&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;2.1.3.weight&quot;</span><span class="p">,</span> <span class="s2">&quot;2.ff.1.net.2.weight&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;3.1.0.&quot;</span><span class="p">,</span> <span class="s2">&quot;3.ff.0.&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;3.1.1.weight&quot;</span><span class="p">,</span> <span class="s2">&quot;3.ff.1.net.0.proj.weight&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;3.1.3.weight&quot;</span><span class="p">,</span> <span class="s2">&quot;3.ff.1.net.2.weight&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;layers.0.0&quot;</span><span class="p">,</span> <span class="s2">&quot;layers.0.ln0&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;layers.0.1&quot;</span><span class="p">,</span> <span class="s2">&quot;layers.0.ln1&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;layers.1.0&quot;</span><span class="p">,</span> <span class="s2">&quot;layers.1.ln0&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;layers.1.1&quot;</span><span class="p">,</span> <span class="s2">&quot;layers.1.ln1&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;layers.2.0&quot;</span><span class="p">,</span> <span class="s2">&quot;layers.2.ln0&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;layers.2.1&quot;</span><span class="p">,</span> <span class="s2">&quot;layers.2.ln1&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;layers.3.0&quot;</span><span class="p">,</span> <span class="s2">&quot;layers.3.ln0&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;layers.3.1&quot;</span><span class="p">,</span> <span class="s2">&quot;layers.3.ln1&quot;</span><span class="p">)</span>

                <span class="k">if</span> <span class="s2">&quot;norm1&quot;</span> <span class="ow">in</span> <span class="n">diffusers_name</span><span class="p">:</span>
                    <span class="n">updated_state_dict</span><span class="p">[</span><span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;0.norm1&quot;</span><span class="p">,</span> <span class="s2">&quot;0&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">elif</span> <span class="s2">&quot;norm2&quot;</span> <span class="ow">in</span> <span class="n">diffusers_name</span><span class="p">:</span>
                    <span class="n">updated_state_dict</span><span class="p">[</span><span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;0.norm2&quot;</span><span class="p">,</span> <span class="s2">&quot;1&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">elif</span> <span class="s2">&quot;to_kv&quot;</span> <span class="ow">in</span> <span class="n">diffusers_name</span><span class="p">:</span>
                    <span class="n">v_chunk</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">updated_state_dict</span><span class="p">[</span><span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;to_kv&quot;</span><span class="p">,</span> <span class="s2">&quot;to_k&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                        <span class="n">v_chunk</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;to_kv&quot;</span><span class="p">,</span> <span class="s2">&quot;to_k&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="n">updated_state_dict</span><span class="p">[</span><span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;to_kv&quot;</span><span class="p">,</span> <span class="s2">&quot;to_v&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                        <span class="n">v_chunk</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;to_kv&quot;</span><span class="p">,</span> <span class="s2">&quot;to_v&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="s2">&quot;to_out&quot;</span> <span class="ow">in</span> <span class="n">diffusers_name</span><span class="p">:</span>
                    <span class="n">updated_state_dict</span><span class="p">[</span><span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;to_out&quot;</span><span class="p">,</span> <span class="s2">&quot;to_out.0&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">elif</span> <span class="s2">&quot;proj.0.weight&quot;</span> <span class="o">==</span> <span class="n">diffusers_name</span><span class="p">:</span>
                    <span class="n">updated_state_dict</span><span class="p">[</span><span class="s2">&quot;proj.net.0.proj.weight&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">elif</span> <span class="s2">&quot;proj.0.bias&quot;</span> <span class="o">==</span> <span class="n">diffusers_name</span><span class="p">:</span>
                    <span class="n">updated_state_dict</span><span class="p">[</span><span class="s2">&quot;proj.net.0.proj.bias&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">elif</span> <span class="s2">&quot;proj.2.weight&quot;</span> <span class="o">==</span> <span class="n">diffusers_name</span><span class="p">:</span>
                    <span class="n">updated_state_dict</span><span class="p">[</span><span class="s2">&quot;proj.net.2.weight&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">elif</span> <span class="s2">&quot;proj.2.bias&quot;</span> <span class="o">==</span> <span class="n">diffusers_name</span><span class="p">:</span>
                    <span class="n">updated_state_dict</span><span class="p">[</span><span class="s2">&quot;proj.net.2.bias&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">updated_state_dict</span><span class="p">[</span><span class="n">diffusers_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

        <span class="k">elif</span> <span class="s2">&quot;norm.weight&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">:</span>
            <span class="c1"># IP-Adapter Face ID</span>
            <span class="n">id_embeddings_dim_in</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;proj.0.weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">id_embeddings_dim_out</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;proj.0.weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">multiplier</span> <span class="o">=</span> <span class="n">id_embeddings_dim_out</span> <span class="o">//</span> <span class="n">id_embeddings_dim_in</span>
            <span class="n">norm_layer</span> <span class="o">=</span> <span class="s2">&quot;norm.weight&quot;</span>
            <span class="n">cross_attention_dim</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="n">norm_layer</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">num_tokens</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;proj.2.weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="n">cross_attention_dim</span>

            <span class="n">image_projection</span> <span class="o">=</span> <span class="n">IPAdapterFaceIDImageProjection</span><span class="p">(</span>
                <span class="n">cross_attention_dim</span><span class="o">=</span><span class="n">cross_attention_dim</span><span class="p">,</span>
                <span class="n">image_embed_dim</span><span class="o">=</span><span class="n">id_embeddings_dim_in</span><span class="p">,</span>
                <span class="n">mult</span><span class="o">=</span><span class="n">multiplier</span><span class="p">,</span>
                <span class="n">num_tokens</span><span class="o">=</span><span class="n">num_tokens</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;proj.0&quot;</span><span class="p">,</span> <span class="s2">&quot;ff.net.0.proj&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;proj.2&quot;</span><span class="p">,</span> <span class="s2">&quot;ff.net.2&quot;</span><span class="p">)</span>
                <span class="n">updated_state_dict</span><span class="p">[</span><span class="n">diffusers_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="c1"># IP-Adapter Plus</span>
            <span class="n">num_image_text_embeds</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;latents&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">embed_dims</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;proj_in.weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">output_dims</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;proj_out.weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">hidden_dims</span> <span class="o">=</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;latents&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>
            <span class="n">attn_key_present</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="s2">&quot;attn&quot;</span> <span class="ow">in</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">)</span>
            <span class="n">heads</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;layers.0.attn.to_q.weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">64</span>
                <span class="k">if</span> <span class="n">attn_key_present</span>
                <span class="k">else</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;layers.0.0.to_q.weight&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">//</span> <span class="mi">64</span>
            <span class="p">)</span>

            <span class="n">image_projection</span> <span class="o">=</span> <span class="n">IPAdapterPlusImageProjection</span><span class="p">(</span>
                <span class="n">embed_dims</span><span class="o">=</span><span class="n">embed_dims</span><span class="p">,</span>
                <span class="n">output_dims</span><span class="o">=</span><span class="n">output_dims</span><span class="p">,</span>
                <span class="n">hidden_dims</span><span class="o">=</span><span class="n">hidden_dims</span><span class="p">,</span>
                <span class="n">heads</span><span class="o">=</span><span class="n">heads</span><span class="p">,</span>
                <span class="n">num_queries</span><span class="o">=</span><span class="n">num_image_text_embeds</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">key</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;0.to&quot;</span><span class="p">,</span> <span class="s2">&quot;2.to&quot;</span><span class="p">)</span>

                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;0.0.norm1&quot;</span><span class="p">,</span> <span class="s2">&quot;0.ln0&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;0.0.norm2&quot;</span><span class="p">,</span> <span class="s2">&quot;0.ln1&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;1.0.norm1&quot;</span><span class="p">,</span> <span class="s2">&quot;1.ln0&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;1.0.norm2&quot;</span><span class="p">,</span> <span class="s2">&quot;1.ln1&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;2.0.norm1&quot;</span><span class="p">,</span> <span class="s2">&quot;2.ln0&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;2.0.norm2&quot;</span><span class="p">,</span> <span class="s2">&quot;2.ln1&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;3.0.norm1&quot;</span><span class="p">,</span> <span class="s2">&quot;3.ln0&quot;</span><span class="p">)</span>
                <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;3.0.norm2&quot;</span><span class="p">,</span> <span class="s2">&quot;3.ln1&quot;</span><span class="p">)</span>

                <span class="k">if</span> <span class="s2">&quot;to_kv&quot;</span> <span class="ow">in</span> <span class="n">diffusers_name</span><span class="p">:</span>
                    <span class="n">parts</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
                    <span class="n">parts</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;attn&quot;</span>
                    <span class="n">diffusers_name</span> <span class="o">=</span> <span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span>
                    <span class="n">v_chunk</span> <span class="o">=</span> <span class="n">value</span><span class="o">.</span><span class="n">chunk</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
                    <span class="n">updated_state_dict</span><span class="p">[</span><span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;to_kv&quot;</span><span class="p">,</span> <span class="s2">&quot;to_k&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                        <span class="n">v_chunk</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;to_kv&quot;</span><span class="p">,</span> <span class="s2">&quot;to_k&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
                    <span class="n">updated_state_dict</span><span class="p">[</span><span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;to_kv&quot;</span><span class="p">,</span> <span class="s2">&quot;to_v&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                        <span class="n">v_chunk</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">name</span><span class="o">=</span><span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;to_kv&quot;</span><span class="p">,</span> <span class="s2">&quot;to_v&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
                <span class="k">elif</span> <span class="s2">&quot;to_q&quot;</span> <span class="ow">in</span> <span class="n">diffusers_name</span><span class="p">:</span>
                    <span class="n">parts</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
                    <span class="n">parts</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;attn&quot;</span>
                    <span class="n">diffusers_name</span> <span class="o">=</span> <span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span>
                    <span class="n">updated_state_dict</span><span class="p">[</span><span class="n">diffusers_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">elif</span> <span class="s2">&quot;to_out&quot;</span> <span class="ow">in</span> <span class="n">diffusers_name</span><span class="p">:</span>
                    <span class="n">parts</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)</span>
                    <span class="n">parts</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;attn&quot;</span>
                    <span class="n">diffusers_name</span> <span class="o">=</span> <span class="s2">&quot;.&quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">parts</span><span class="p">)</span>
                    <span class="n">updated_state_dict</span><span class="p">[</span><span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;to_out&quot;</span><span class="p">,</span> <span class="s2">&quot;to_out.0&quot;</span><span class="p">)]</span> <span class="o">=</span> <span class="n">value</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;0.1.0&quot;</span><span class="p">,</span> <span class="s2">&quot;0.ff.0&quot;</span><span class="p">)</span>
                    <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;0.1.1&quot;</span><span class="p">,</span> <span class="s2">&quot;0.ff.1.net.0.proj&quot;</span><span class="p">)</span>
                    <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;0.1.3&quot;</span><span class="p">,</span> <span class="s2">&quot;0.ff.1.net.2&quot;</span><span class="p">)</span>

                    <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;1.1.0&quot;</span><span class="p">,</span> <span class="s2">&quot;1.ff.0&quot;</span><span class="p">)</span>
                    <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;1.1.1&quot;</span><span class="p">,</span> <span class="s2">&quot;1.ff.1.net.0.proj&quot;</span><span class="p">)</span>
                    <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;1.1.3&quot;</span><span class="p">,</span> <span class="s2">&quot;1.ff.1.net.2&quot;</span><span class="p">)</span>

                    <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;2.1.0&quot;</span><span class="p">,</span> <span class="s2">&quot;2.ff.0&quot;</span><span class="p">)</span>
                    <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;2.1.1&quot;</span><span class="p">,</span> <span class="s2">&quot;2.ff.1.net.0.proj&quot;</span><span class="p">)</span>
                    <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;2.1.3&quot;</span><span class="p">,</span> <span class="s2">&quot;2.ff.1.net.2&quot;</span><span class="p">)</span>

                    <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;3.1.0&quot;</span><span class="p">,</span> <span class="s2">&quot;3.ff.0&quot;</span><span class="p">)</span>
                    <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;3.1.1&quot;</span><span class="p">,</span> <span class="s2">&quot;3.ff.1.net.0.proj&quot;</span><span class="p">)</span>
                    <span class="n">diffusers_name</span> <span class="o">=</span> <span class="n">diffusers_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;3.1.3&quot;</span><span class="p">,</span> <span class="s2">&quot;3.ff.1.net.2&quot;</span><span class="p">)</span>
                    <span class="n">updated_state_dict</span><span class="p">[</span><span class="n">diffusers_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
                    <span class="n">updated_state_dict</span><span class="p">[</span><span class="n">diffusers_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
        <span class="n">_load_param_into_net</span><span class="p">(</span><span class="n">image_projection</span><span class="p">,</span> <span class="n">updated_state_dict</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">image_projection</span>

    <span class="k">def</span> <span class="nf">_convert_ip_adapter_attn_to_diffusers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dicts</span><span class="p">):</span>
        <span class="kn">from</span> <span class="nn">..models.attention_processor</span> <span class="kn">import</span> <span class="n">AttnProcessor</span><span class="p">,</span> <span class="n">IPAdapterAttnProcessor</span>

        <span class="c1"># set ip-adapter cross-attention processors &amp; load state_dict</span>
        <span class="n">attn_procs</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">key_id</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_processors</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">cross_attention_dim</span> <span class="o">=</span> <span class="kc">None</span> <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;attn1.processor&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">cross_attention_dim</span>
            <span class="k">if</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;mid_block&quot;</span><span class="p">):</span>
                <span class="n">hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">block_out_channels</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;up_blocks&quot;</span><span class="p">):</span>
                <span class="n">block_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">name</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;up_blocks.&quot;</span><span class="p">)])</span>
                <span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">block_out_channels</span><span class="p">))[</span><span class="n">block_id</span><span class="p">]</span>
            <span class="k">elif</span> <span class="n">name</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s2">&quot;down_blocks&quot;</span><span class="p">):</span>
                <span class="n">block_id</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">name</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="s2">&quot;down_blocks.&quot;</span><span class="p">)])</span>
                <span class="n">hidden_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">block_out_channels</span><span class="p">[</span><span class="n">block_id</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">cross_attention_dim</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="s2">&quot;motion_modules&quot;</span> <span class="ow">in</span> <span class="n">name</span><span class="p">:</span>
                <span class="n">attn_processor_class</span> <span class="o">=</span> <span class="n">AttnProcessor</span>
                <span class="n">attn_procs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">attn_processor_class</span><span class="p">()</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">attn_processor_class</span> <span class="o">=</span> <span class="n">IPAdapterAttnProcessor</span>
                <span class="n">num_image_text_embeds</span> <span class="o">=</span> <span class="p">[]</span>
                <span class="k">for</span> <span class="n">state_dict</span> <span class="ow">in</span> <span class="n">state_dicts</span><span class="p">:</span>
                    <span class="k">if</span> <span class="s2">&quot;proj.weight&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;image_proj&quot;</span><span class="p">]:</span>
                        <span class="c1"># IP-Adapter</span>
                        <span class="n">num_image_text_embeds</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">4</span><span class="p">]</span>
                    <span class="k">elif</span> <span class="s2">&quot;proj.3.weight&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;image_proj&quot;</span><span class="p">]:</span>
                        <span class="c1"># IP-Adapter Full Face</span>
                        <span class="n">num_image_text_embeds</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">257</span><span class="p">]</span>  <span class="c1"># 256 CLIP tokens + 1 CLS token</span>
                    <span class="k">elif</span> <span class="s2">&quot;perceiver_resampler.proj_in.weight&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;image_proj&quot;</span><span class="p">]:</span>
                        <span class="c1"># IP-Adapter Face ID Plus</span>
                        <span class="n">num_image_text_embeds</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">4</span><span class="p">]</span>
                    <span class="k">elif</span> <span class="s2">&quot;norm.weight&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;image_proj&quot;</span><span class="p">]:</span>
                        <span class="c1"># IP-Adapter Face ID</span>
                        <span class="n">num_image_text_embeds</span> <span class="o">+=</span> <span class="p">[</span><span class="mi">4</span><span class="p">]</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="c1"># IP-Adapter Plus</span>
                        <span class="n">num_image_text_embeds</span> <span class="o">+=</span> <span class="p">[</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;image_proj&quot;</span><span class="p">][</span><span class="s2">&quot;latents&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>

                <span class="n">attn_procs</span><span class="p">[</span><span class="n">name</span><span class="p">]</span> <span class="o">=</span> <span class="n">attn_processor_class</span><span class="p">(</span>
                    <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
                    <span class="n">cross_attention_dim</span><span class="o">=</span><span class="n">cross_attention_dim</span><span class="p">,</span>
                    <span class="n">scale</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
                    <span class="n">num_tokens</span><span class="o">=</span><span class="n">num_image_text_embeds</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">value_dict</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">state_dict</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">state_dicts</span><span class="p">):</span>
                    <span class="n">value_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="sa">f</span><span class="s2">&quot;to_k_ip.</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">.weight&quot;</span><span class="p">:</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;ip_adapter&quot;</span><span class="p">][</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key_id</span><span class="si">}</span><span class="s2">.to_k_ip.weight&quot;</span><span class="p">]})</span>
                    <span class="n">value_dict</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="sa">f</span><span class="s2">&quot;to_v_ip.</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">.weight&quot;</span><span class="p">:</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;ip_adapter&quot;</span><span class="p">][</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key_id</span><span class="si">}</span><span class="s2">.to_v_ip.weight&quot;</span><span class="p">]})</span>

                <span class="n">_load_param_into_net</span><span class="p">(</span><span class="n">attn_procs</span><span class="p">[</span><span class="n">name</span><span class="p">],</span> <span class="n">value_dict</span><span class="p">)</span>

                <span class="n">key_id</span> <span class="o">+=</span> <span class="mi">2</span>

        <span class="k">return</span> <span class="n">attn_procs</span>

    <span class="k">def</span> <span class="nf">_load_ip_adapter_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dicts</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state_dicts</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">state_dicts</span> <span class="o">=</span> <span class="p">[</span><span class="n">state_dicts</span><span class="p">]</span>
        <span class="c1"># Set encoder_hid_proj after loading ip_adapter weights,</span>
        <span class="c1"># because `IPAdapterPlusImageProjection` also has `attn_processors`.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_hid_proj</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">attn_procs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_ip_adapter_attn_to_diffusers</span><span class="p">(</span><span class="n">state_dicts</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_attn_processor</span><span class="p">(</span><span class="n">attn_procs</span><span class="p">)</span>

        <span class="c1"># convert IP-Adapter Image Projection layers to diffusers</span>
        <span class="n">image_projection_layers</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">state_dict</span> <span class="ow">in</span> <span class="n">state_dicts</span><span class="p">:</span>
            <span class="n">image_projection_layer</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_convert_ip_adapter_image_proj_to_diffusers</span><span class="p">(</span><span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;image_proj&quot;</span><span class="p">])</span>
            <span class="n">image_projection_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">image_projection_layer</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_hid_proj</span> <span class="o">=</span> <span class="n">MultiIPAdapterImageProjection</span><span class="p">(</span><span class="n">image_projection_layers</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">encoder_hid_dim_type</span> <span class="o">=</span> <span class="s2">&quot;ip_image_proj&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;encoder_hid_dim_type&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;ip_image_proj&quot;</span>  <span class="c1"># not same with `self.config.encoder_hid_dim_type`</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder_hid_dim_type</span> <span class="o">=</span> <span class="s2">&quot;ip_image_proj&quot;</span>  <span class="c1"># used in UNet2DConditionModel.construct()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_load_ip_adapter_loras</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state_dicts</span><span class="p">):</span>
        <span class="n">lora_dicts</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">key_id</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attn_processors</span><span class="o">.</span><span class="n">keys</span><span class="p">()):</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">state_dict</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">state_dicts</span><span class="p">):</span>
                <span class="k">if</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key_id</span><span class="si">}</span><span class="s2">.to_k_lora.down.weight&quot;</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;ip_adapter&quot;</span><span class="p">]:</span>
                    <span class="k">if</span> <span class="n">i</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">lora_dicts</span><span class="p">:</span>
                        <span class="n">lora_dicts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
                    <span class="n">lora_dicts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="p">{</span>
                            <span class="sa">f</span><span class="s2">&quot;unet.</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.to_k_lora.down.weight&quot;</span><span class="p">:</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;ip_adapter&quot;</span><span class="p">][</span>
                                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key_id</span><span class="si">}</span><span class="s2">.to_k_lora.down.weight&quot;</span>
                            <span class="p">]</span>
                        <span class="p">}</span>
                    <span class="p">)</span>
                    <span class="n">lora_dicts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="p">{</span>
                            <span class="sa">f</span><span class="s2">&quot;unet.</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.to_q_lora.down.weight&quot;</span><span class="p">:</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;ip_adapter&quot;</span><span class="p">][</span>
                                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key_id</span><span class="si">}</span><span class="s2">.to_q_lora.down.weight&quot;</span>
                            <span class="p">]</span>
                        <span class="p">}</span>
                    <span class="p">)</span>
                    <span class="n">lora_dicts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="p">{</span>
                            <span class="sa">f</span><span class="s2">&quot;unet.</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.to_v_lora.down.weight&quot;</span><span class="p">:</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;ip_adapter&quot;</span><span class="p">][</span>
                                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key_id</span><span class="si">}</span><span class="s2">.to_v_lora.down.weight&quot;</span>
                            <span class="p">]</span>
                        <span class="p">}</span>
                    <span class="p">)</span>
                    <span class="n">lora_dicts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="p">{</span>
                            <span class="sa">f</span><span class="s2">&quot;unet.</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.to_out_lora.down.weight&quot;</span><span class="p">:</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;ip_adapter&quot;</span><span class="p">][</span>
                                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key_id</span><span class="si">}</span><span class="s2">.to_out_lora.down.weight&quot;</span>
                            <span class="p">]</span>
                        <span class="p">}</span>
                    <span class="p">)</span>
                    <span class="n">lora_dicts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;unet.</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.to_k_lora.up.weight&quot;</span><span class="p">:</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;ip_adapter&quot;</span><span class="p">][</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key_id</span><span class="si">}</span><span class="s2">.to_k_lora.up.weight&quot;</span><span class="p">]}</span>
                    <span class="p">)</span>
                    <span class="n">lora_dicts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;unet.</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.to_q_lora.up.weight&quot;</span><span class="p">:</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;ip_adapter&quot;</span><span class="p">][</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key_id</span><span class="si">}</span><span class="s2">.to_q_lora.up.weight&quot;</span><span class="p">]}</span>
                    <span class="p">)</span>
                    <span class="n">lora_dicts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;unet.</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.to_v_lora.up.weight&quot;</span><span class="p">:</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;ip_adapter&quot;</span><span class="p">][</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key_id</span><span class="si">}</span><span class="s2">.to_v_lora.up.weight&quot;</span><span class="p">]}</span>
                    <span class="p">)</span>
                    <span class="n">lora_dicts</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                        <span class="p">{</span>
                            <span class="sa">f</span><span class="s2">&quot;unet.</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">.to_out_lora.up.weight&quot;</span><span class="p">:</span> <span class="n">state_dict</span><span class="p">[</span><span class="s2">&quot;ip_adapter&quot;</span><span class="p">][</span>
                                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key_id</span><span class="si">}</span><span class="s2">.to_out_lora.up.weight&quot;</span>
                            <span class="p">]</span>
                        <span class="p">}</span>
                    <span class="p">)</span>
        <span class="k">return</span> <span class="n">lora_dicts</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.delete_adapters" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindone</span><span class="o">.</span><span class="n">diffusers</span><span class="o">.</span><span class="n">loaders</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">UNet2DConditionLoadersMixin</span><span class="o">.</span><span class="n">delete_adapters</span><span class="p">(</span><span class="n">adapter_names</span><span class="p">)</span></code>

<a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.delete_adapters" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Delete an adapter's LoRA layers from the UNet.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>adapter_names</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The names (single string or list of strings) of the adapter to delete.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Union[List[str], str]`</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">mindone.diffusers</span> <span class="kn">import</span> <span class="n">AutoPipelineForText2Image</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">AutoPipelineForText2Image</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span><span class="p">,</span> <span class="n">mindspore_dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">load_lora_weights</span><span class="p">(</span>
    <span class="s2">&quot;jbilcke-hf/sdxl-cinematic-1&quot;</span><span class="p">,</span> <span class="n">weight_name</span><span class="o">=</span><span class="s2">&quot;pytorch_lora_weights.safetensors&quot;</span><span class="p">,</span> <span class="n">adapter_names</span><span class="o">=</span><span class="s2">&quot;cinematic&quot;</span>
<span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">delete_adapters</span><span class="p">(</span><span class="s2">&quot;cinematic&quot;</span><span class="p">)</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindone/diffusers/loaders/unet.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">delete_adapters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">adapter_names</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">]):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Delete an adapter&#39;s LoRA layers from the UNet.</span>

<span class="sd">    Args:</span>
<span class="sd">        adapter_names (`Union[List[str], str]`):</span>
<span class="sd">            The names (single string or list of strings) of the adapter to delete.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```py</span>
<span class="sd">    from mindone.diffusers import AutoPipelineForText2Image</span>
<span class="sd">    import mindspore as ms</span>

<span class="sd">    pipeline = AutoPipelineForText2Image.from_pretrained(</span>
<span class="sd">        &quot;stabilityai/stable-diffusion-xl-base-1.0&quot;, mindspore_dtype=ms.float16</span>
<span class="sd">    )</span>
<span class="sd">    pipeline.load_lora_weights(</span>
<span class="sd">        &quot;jbilcke-hf/sdxl-cinematic-1&quot;, weight_name=&quot;pytorch_lora_weights.safetensors&quot;, adapter_names=&quot;cinematic&quot;</span>
<span class="sd">    )</span>
<span class="sd">    pipeline.delete_adapters(&quot;cinematic&quot;)</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">adapter_names</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
        <span class="n">adapter_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">adapter_names</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">adapter_name</span> <span class="ow">in</span> <span class="n">adapter_names</span><span class="p">:</span>
        <span class="n">delete_adapter_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">adapter_name</span><span class="p">)</span>

        <span class="c1"># Pop also the corresponding adapter from the config</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="s2">&quot;peft_config&quot;</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">peft_config</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">adapter_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.disable_lora" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindone</span><span class="o">.</span><span class="n">diffusers</span><span class="o">.</span><span class="n">loaders</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">UNet2DConditionLoadersMixin</span><span class="o">.</span><span class="n">disable_lora</span><span class="p">()</span></code>

<a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.disable_lora" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Disable the UNet's active LoRA layers.</p>
<p>Example:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">mindone.diffusers</span> <span class="kn">import</span> <span class="n">AutoPipelineForText2Image</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">AutoPipelineForText2Image</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span><span class="p">,</span> <span class="n">mindspore_dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">load_lora_weights</span><span class="p">(</span>
    <span class="s2">&quot;jbilcke-hf/sdxl-cinematic-1&quot;</span><span class="p">,</span> <span class="n">weight_name</span><span class="o">=</span><span class="s2">&quot;pytorch_lora_weights.safetensors&quot;</span><span class="p">,</span> <span class="n">adapter_name</span><span class="o">=</span><span class="s2">&quot;cinematic&quot;</span>
<span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">disable_lora</span><span class="p">()</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindone/diffusers/loaders/unet.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">disable_lora</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Disable the UNet&#39;s active LoRA layers.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```py</span>
<span class="sd">    from mindone.diffusers import AutoPipelineForText2Image</span>
<span class="sd">    import mindspore as ms</span>

<span class="sd">    pipeline = AutoPipelineForText2Image.from_pretrained(</span>
<span class="sd">        &quot;stabilityai/stable-diffusion-xl-base-1.0&quot;, mindspore_dtype=ms.float16</span>
<span class="sd">    )</span>
<span class="sd">    pipeline.load_lora_weights(</span>
<span class="sd">        &quot;jbilcke-hf/sdxl-cinematic-1&quot;, weight_name=&quot;pytorch_lora_weights.safetensors&quot;, adapter_name=&quot;cinematic&quot;</span>
<span class="sd">    )</span>
<span class="sd">    pipeline.disable_lora()</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">set_adapter_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enabled</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.enable_lora" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindone</span><span class="o">.</span><span class="n">diffusers</span><span class="o">.</span><span class="n">loaders</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">UNet2DConditionLoadersMixin</span><span class="o">.</span><span class="n">enable_lora</span><span class="p">()</span></code>

<a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.enable_lora" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Enable the UNet's active LoRA layers.</p>
<p>Example:</p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">mindone.diffusers</span> <span class="kn">import</span> <span class="n">AutoPipelineForText2Image</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">AutoPipelineForText2Image</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span><span class="p">,</span> <span class="n">mindspore_dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">load_lora_weights</span><span class="p">(</span>
    <span class="s2">&quot;jbilcke-hf/sdxl-cinematic-1&quot;</span><span class="p">,</span> <span class="n">weight_name</span><span class="o">=</span><span class="s2">&quot;pytorch_lora_weights.safetensors&quot;</span><span class="p">,</span> <span class="n">adapter_name</span><span class="o">=</span><span class="s2">&quot;cinematic&quot;</span>
<span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">enable_lora</span><span class="p">()</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindone/diffusers/loaders/unet.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">enable_lora</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Enable the UNet&#39;s active LoRA layers.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```py</span>
<span class="sd">    from mindone.diffusers import AutoPipelineForText2Image</span>
<span class="sd">    import mindspore as ms</span>

<span class="sd">    pipeline = AutoPipelineForText2Image.from_pretrained(</span>
<span class="sd">        &quot;stabilityai/stable-diffusion-xl-base-1.0&quot;, mindspore_dtype=ms.float16</span>
<span class="sd">    )</span>
<span class="sd">    pipeline.load_lora_weights(</span>
<span class="sd">        &quot;jbilcke-hf/sdxl-cinematic-1&quot;, weight_name=&quot;pytorch_lora_weights.safetensors&quot;, adapter_name=&quot;cinematic&quot;</span>
<span class="sd">    )</span>
<span class="sd">    pipeline.enable_lora()</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">set_adapter_layers</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enabled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.load_attn_procs" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindone</span><span class="o">.</span><span class="n">diffusers</span><span class="o">.</span><span class="n">loaders</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">UNet2DConditionLoadersMixin</span><span class="o">.</span><span class="n">load_attn_procs</span><span class="p">(</span><span class="n">pretrained_model_name_or_path_or_dict</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.load_attn_procs" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Load pretrained attention processor layers into [<code>UNet2DConditionModel</code>]. Attention processor layers have to be
defined in
<a href="https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py"><code>attention_processor.py</code></a>
and be a <code>mindspore.nn.Cell</code> class. Currently supported: LoRA, Custom Diffusion. For LoRA, one must install
<code>peft</code>: <code>pip install -U peft</code>.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>pretrained_model_name_or_path_or_dict</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Can be either:</p>
<div class="highlight"><pre><span></span><code>- A string, the model id (for example `google/ddpm-celebahq-256`) of a pretrained model hosted on
  the Hub.
- A path to a directory (for example `./my_model_directory`) containing the model weights saved
  with [`ModelMixin.save_pretrained`].
- A mindspore state dict.
</code></pre></div>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `os.PathLike` or `dict`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>cache_dir</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Path to a directory where a downloaded pretrained model configuration is cached if the standard cache
is not used.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Union[str, os.PathLike]`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>force_download</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether or not to force the (re-)download of the model weights and configuration files, overriding the
cached versions if they exist.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>resume_download</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Deprecated and ignored. All downloads are now resumed by default when possible. Will be removed in v1
of Diffusers.</p>
              </div>
              <p>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>proxies</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>A dictionary of proxy servers to use by protocol or endpoint, for example, <code>{'http': 'foo.bar:3128',
'http://hostname': 'foo.bar:4012'}</code>. The proxies are used on each request.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Dict[str, str]`, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>local_files_only</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to only load local model weights and configuration files or not. If set to <code>True</code>, the model
won't be downloaded from the Hub.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `False`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>token</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The token to use as HTTP bearer authorization for remote files. If <code>True</code>, the token generated from
<code>diffusers-cli login</code> (stored in <code>~/.huggingface</code>) is used.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or *bool*, *optional*</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>revision</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The specific model version to use. It can be a branch name, a tag name, a commit id, or any identifier
allowed by Git.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;main&#34;`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>subfolder</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The subfolder location of a model file within a larger model repository on the Hub or locally.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to `&#34;&#34;`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>network_alphas</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The value of the network alpha used for stable learning and preventing underflow. This value has the
same meaning as the <code>--network_alpha</code> option in the kohya-ss trainer script. Refer to <a href="https://github.com/darkstorm2150/sd-scripts/blob/main/docs/train_network_README-en.md#execute-learning">this
link</a>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Dict[str, float]`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>adapter_name</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Adapter name to be used for referencing the loaded adapter model. If not specified, it will use
<code>default_{i}</code> where i is the total number of adapters being loaded.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weight_name</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Name of the serialized state dict file.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str`, *optional*, defaults to None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">mindone.diffusers</span> <span class="kn">import</span> <span class="n">AutoPipelineForText2Image</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">AutoPipelineForText2Image</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span><span class="p">,</span> <span class="n">mindspore_dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">load_attn_procs</span><span class="p">(</span>
    <span class="s2">&quot;jbilcke-hf/sdxl-cinematic-1&quot;</span><span class="p">,</span> <span class="n">weight_name</span><span class="o">=</span><span class="s2">&quot;pytorch_lora_weights.safetensors&quot;</span><span class="p">,</span> <span class="n">adapter_name</span><span class="o">=</span><span class="s2">&quot;cinematic&quot;</span>
<span class="p">)</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindone/diffusers/loaders/unet.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="nd">@validate_hf_hub_args</span>
<span class="k">def</span> <span class="nf">load_attn_procs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pretrained_model_name_or_path_or_dict</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ms</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Load pretrained attention processor layers into [`UNet2DConditionModel`]. Attention processor layers have to be</span>
<span class="sd">    defined in</span>
<span class="sd">    [`attention_processor.py`](https://github.com/huggingface/diffusers/blob/main/src/diffusers/models/attention_processor.py)</span>
<span class="sd">    and be a `mindspore.nn.Cell` class. Currently supported: LoRA, Custom Diffusion. For LoRA, one must install</span>
<span class="sd">    `peft`: `pip install -U peft`.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        pretrained_model_name_or_path_or_dict (`str` or `os.PathLike` or `dict`):</span>
<span class="sd">            Can be either:</span>

<span class="sd">                - A string, the model id (for example `google/ddpm-celebahq-256`) of a pretrained model hosted on</span>
<span class="sd">                  the Hub.</span>
<span class="sd">                - A path to a directory (for example `./my_model_directory`) containing the model weights saved</span>
<span class="sd">                  with [`ModelMixin.save_pretrained`].</span>
<span class="sd">                - A mindspore state dict.</span>

<span class="sd">        cache_dir (`Union[str, os.PathLike]`, *optional*):</span>
<span class="sd">            Path to a directory where a downloaded pretrained model configuration is cached if the standard cache</span>
<span class="sd">            is not used.</span>
<span class="sd">        force_download (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether or not to force the (re-)download of the model weights and configuration files, overriding the</span>
<span class="sd">            cached versions if they exist.</span>
<span class="sd">        resume_download:</span>
<span class="sd">            Deprecated and ignored. All downloads are now resumed by default when possible. Will be removed in v1</span>
<span class="sd">            of Diffusers.</span>
<span class="sd">        proxies (`Dict[str, str]`, *optional*):</span>
<span class="sd">            A dictionary of proxy servers to use by protocol or endpoint, for example, `{&#39;http&#39;: &#39;foo.bar:3128&#39;,</span>
<span class="sd">            &#39;http://hostname&#39;: &#39;foo.bar:4012&#39;}`. The proxies are used on each request.</span>
<span class="sd">        local_files_only (`bool`, *optional*, defaults to `False`):</span>
<span class="sd">            Whether to only load local model weights and configuration files or not. If set to `True`, the model</span>
<span class="sd">            won&#39;t be downloaded from the Hub.</span>
<span class="sd">        token (`str` or *bool*, *optional*):</span>
<span class="sd">            The token to use as HTTP bearer authorization for remote files. If `True`, the token generated from</span>
<span class="sd">            `diffusers-cli login` (stored in `~/.huggingface`) is used.</span>
<span class="sd">        revision (`str`, *optional*, defaults to `&quot;main&quot;`):</span>
<span class="sd">            The specific model version to use. It can be a branch name, a tag name, a commit id, or any identifier</span>
<span class="sd">            allowed by Git.</span>
<span class="sd">        subfolder (`str`, *optional*, defaults to `&quot;&quot;`):</span>
<span class="sd">            The subfolder location of a model file within a larger model repository on the Hub or locally.</span>
<span class="sd">        network_alphas (`Dict[str, float]`):</span>
<span class="sd">            The value of the network alpha used for stable learning and preventing underflow. This value has the</span>
<span class="sd">            same meaning as the `--network_alpha` option in the kohya-ss trainer script. Refer to [this</span>
<span class="sd">            link](https://github.com/darkstorm2150/sd-scripts/blob/main/docs/train_network_README-en.md#execute-learning).</span>
<span class="sd">        adapter_name (`str`, *optional*, defaults to None):</span>
<span class="sd">            Adapter name to be used for referencing the loaded adapter model. If not specified, it will use</span>
<span class="sd">            `default_{i}` where i is the total number of adapters being loaded.</span>
<span class="sd">        weight_name (`str`, *optional*, defaults to None):</span>
<span class="sd">            Name of the serialized state dict file.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```py</span>
<span class="sd">    from mindone.diffusers import AutoPipelineForText2Image</span>
<span class="sd">    import mindspore as ms</span>

<span class="sd">    pipeline = AutoPipelineForText2Image.from_pretrained(</span>
<span class="sd">        &quot;stabilityai/stable-diffusion-xl-base-1.0&quot;, mindspore_dtype=ms.float16</span>
<span class="sd">    )</span>
<span class="sd">    pipeline.unet.load_attn_procs(</span>
<span class="sd">        &quot;jbilcke-hf/sdxl-cinematic-1&quot;, weight_name=&quot;pytorch_lora_weights.safetensors&quot;, adapter_name=&quot;cinematic&quot;</span>
<span class="sd">    )</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">cache_dir</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;cache_dir&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">force_download</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;force_download&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">)</span>
    <span class="n">resume_download</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;resume_download&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">proxies</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;proxies&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">local_files_only</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;local_files_only&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">token</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;token&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">revision</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;revision&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">subfolder</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;subfolder&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">weight_name</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;weight_name&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">use_safetensors</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;use_safetensors&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">adapter_name</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;adapter_name&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">_pipeline</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_pipeline&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">network_alphas</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;network_alphas&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
    <span class="n">allow_pickle</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="n">_pipeline</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;_pipeline&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>  <span class="c1"># noqa: F841</span>

    <span class="n">is_network_alphas_none</span> <span class="o">=</span> <span class="n">network_alphas</span> <span class="ow">is</span> <span class="kc">None</span>  <span class="c1"># noqa: F841</span>

    <span class="n">allow_pickle</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">if</span> <span class="n">use_safetensors</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">use_safetensors</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">allow_pickle</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="n">user_agent</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;file_type&quot;</span><span class="p">:</span> <span class="s2">&quot;attn_procs_weights&quot;</span><span class="p">,</span>
        <span class="s2">&quot;framework&quot;</span><span class="p">:</span> <span class="s2">&quot;pytorch&quot;</span><span class="p">,</span>
    <span class="p">}</span>

    <span class="n">model_file</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pretrained_model_name_or_path_or_dict</span><span class="p">,</span> <span class="nb">dict</span><span class="p">):</span>
        <span class="c1"># Let&#39;s first try to load .safetensors weights</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">use_safetensors</span> <span class="ow">and</span> <span class="n">weight_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span>
            <span class="n">weight_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">weight_name</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.safetensors&quot;</span><span class="p">)</span>
        <span class="p">):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">model_file</span> <span class="o">=</span> <span class="n">_get_model_file</span><span class="p">(</span>
                    <span class="n">pretrained_model_name_or_path_or_dict</span><span class="p">,</span>
                    <span class="n">weights_name</span><span class="o">=</span><span class="n">weight_name</span> <span class="ow">or</span> <span class="n">LORA_WEIGHT_NAME_SAFE</span><span class="p">,</span>
                    <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span>
                    <span class="n">force_download</span><span class="o">=</span><span class="n">force_download</span><span class="p">,</span>
                    <span class="n">resume_download</span><span class="o">=</span><span class="n">resume_download</span><span class="p">,</span>
                    <span class="n">proxies</span><span class="o">=</span><span class="n">proxies</span><span class="p">,</span>
                    <span class="n">local_files_only</span><span class="o">=</span><span class="n">local_files_only</span><span class="p">,</span>
                    <span class="n">token</span><span class="o">=</span><span class="n">token</span><span class="p">,</span>
                    <span class="n">revision</span><span class="o">=</span><span class="n">revision</span><span class="p">,</span>
                    <span class="n">subfolder</span><span class="o">=</span><span class="n">subfolder</span><span class="p">,</span>
                    <span class="n">user_agent</span><span class="o">=</span><span class="n">user_agent</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">state_dict</span> <span class="o">=</span> <span class="n">load_file</span><span class="p">(</span><span class="n">model_file</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">IOError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="n">allow_pickle</span><span class="p">:</span>
                    <span class="k">raise</span> <span class="n">e</span>
                <span class="c1"># try loading non-safetensors weights</span>
                <span class="k">pass</span>
        <span class="k">if</span> <span class="n">model_file</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_file</span> <span class="o">=</span> <span class="n">_get_model_file</span><span class="p">(</span>
                <span class="n">pretrained_model_name_or_path_or_dict</span><span class="p">,</span>
                <span class="n">weights_name</span><span class="o">=</span><span class="n">weight_name</span> <span class="ow">or</span> <span class="n">LORA_WEIGHT_NAME</span><span class="p">,</span>
                <span class="n">cache_dir</span><span class="o">=</span><span class="n">cache_dir</span><span class="p">,</span>
                <span class="n">force_download</span><span class="o">=</span><span class="n">force_download</span><span class="p">,</span>
                <span class="n">resume_download</span><span class="o">=</span><span class="n">resume_download</span><span class="p">,</span>
                <span class="n">proxies</span><span class="o">=</span><span class="n">proxies</span><span class="p">,</span>
                <span class="n">local_files_only</span><span class="o">=</span><span class="n">local_files_only</span><span class="p">,</span>
                <span class="n">token</span><span class="o">=</span><span class="n">token</span><span class="p">,</span>
                <span class="n">revision</span><span class="o">=</span><span class="n">revision</span><span class="p">,</span>
                <span class="n">subfolder</span><span class="o">=</span><span class="n">subfolder</span><span class="p">,</span>
                <span class="n">user_agent</span><span class="o">=</span><span class="n">user_agent</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Only supports deserialization of weights file in safetensors format, but got </span><span class="si">{</span><span class="n">model_file</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">pretrained_model_name_or_path_or_dict</span>

    <span class="n">is_custom_diffusion</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span><span class="s2">&quot;custom_diffusion&quot;</span> <span class="ow">in</span> <span class="n">k</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
    <span class="n">is_lora</span> <span class="o">=</span> <span class="nb">all</span><span class="p">((</span><span class="s2">&quot;lora&quot;</span> <span class="ow">in</span> <span class="n">k</span> <span class="ow">or</span> <span class="n">k</span><span class="o">.</span><span class="n">endswith</span><span class="p">(</span><span class="s2">&quot;.alpha&quot;</span><span class="p">))</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">state_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>

    <span class="k">if</span> <span class="n">is_custom_diffusion</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;CustomDiffusionAttnProcessor is not yet supported.&quot;</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">is_lora</span><span class="p">:</span>
        <span class="n">is_model_cpu_offload</span><span class="p">,</span> <span class="n">is_sequential_cpu_offload</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_process_lora</span><span class="p">(</span>
            <span class="n">state_dict</span><span class="o">=</span><span class="n">state_dict</span><span class="p">,</span>
            <span class="n">unet_identifier_key</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">unet_name</span><span class="p">,</span>
            <span class="n">network_alphas</span><span class="o">=</span><span class="n">network_alphas</span><span class="p">,</span>
            <span class="n">adapter_name</span><span class="o">=</span><span class="n">adapter_name</span><span class="p">,</span>
            <span class="n">_pipeline</span><span class="o">=</span><span class="n">_pipeline</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_file</span><span class="si">}</span><span class="s2"> does not seem to be in the correct format expected by Custom Diffusion training.&quot;</span>
        <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.save_attn_procs" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindone</span><span class="o">.</span><span class="n">diffusers</span><span class="o">.</span><span class="n">loaders</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">UNet2DConditionLoadersMixin</span><span class="o">.</span><span class="n">save_attn_procs</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="n">is_main_process</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">weight_name</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">save_function</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">safe_serialization</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>

<a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.save_attn_procs" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Save attention processor layers to a directory so that it can be reloaded with the
[<code>~loaders.UNet2DConditionLoadersMixin.load_attn_procs</code>] method.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>save_directory</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Directory to save an attention processor to (will be created if it doesn't exist).</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`str` or `os.PathLike`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>is_main_process</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether the process calling this is the main process or not. Useful during distributed training and you
need to call this function on all processes. In this case, set <code>is_main_process=True</code> only on the main
process to avoid race conditions.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>save_function</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The function to use to save the state dictionary. Useful during distributed training when you need to
replace <code>MindSpore.save_checkpoint</code> with another method. Can be configured with the environment variable
<code>DIFFUSERS_SAVE_MODE</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Callable`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>safe_serialization</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>Whether to save the model using <code>safetensors</code> or with <code>pickle</code>.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`bool`, *optional*, defaults to `True`</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>True</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">mindspore</span>
<span class="kn">from</span> <span class="nn">mindone.diffusers</span> <span class="kn">import</span> <span class="n">DiffusionPipeline</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">DiffusionPipeline</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;CompVis/stable-diffusion-v1-4&quot;</span><span class="p">,</span>
    <span class="n">mindspore_dtype</span><span class="o">=</span><span class="n">mindspore</span><span class="o">.</span><span class="n">float16</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">load_attn_procs</span><span class="p">(</span><span class="s2">&quot;path-to-save-model&quot;</span><span class="p">,</span> <span class="n">weight_name</span><span class="o">=</span><span class="s2">&quot;lora_diffusion_weights.safetensors&quot;</span><span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">save_attn_procs</span><span class="p">(</span><span class="s2">&quot;path-to-save-model&quot;</span><span class="p">,</span> <span class="n">weight_name</span><span class="o">=</span><span class="s2">&quot;lora_diffusion_weights.safetensors&quot;</span><span class="p">)</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindone/diffusers/loaders/unet.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">save_attn_procs</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">save_directory</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">os</span><span class="o">.</span><span class="n">PathLike</span><span class="p">],</span>
    <span class="n">is_main_process</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">weight_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">save_function</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">safe_serialization</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Save attention processor layers to a directory so that it can be reloaded with the</span>
<span class="sd">    [`~loaders.UNet2DConditionLoadersMixin.load_attn_procs`] method.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        save_directory (`str` or `os.PathLike`):</span>
<span class="sd">            Directory to save an attention processor to (will be created if it doesn&#39;t exist).</span>
<span class="sd">        is_main_process (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether the process calling this is the main process or not. Useful during distributed training and you</span>
<span class="sd">            need to call this function on all processes. In this case, set `is_main_process=True` only on the main</span>
<span class="sd">            process to avoid race conditions.</span>
<span class="sd">        save_function (`Callable`):</span>
<span class="sd">            The function to use to save the state dictionary. Useful during distributed training when you need to</span>
<span class="sd">            replace `MindSpore.save_checkpoint` with another method. Can be configured with the environment variable</span>
<span class="sd">            `DIFFUSERS_SAVE_MODE`.</span>
<span class="sd">        safe_serialization (`bool`, *optional*, defaults to `True`):</span>
<span class="sd">            Whether to save the model using `safetensors` or with `pickle`.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```py</span>
<span class="sd">    import mindspore</span>
<span class="sd">    from mindone.diffusers import DiffusionPipeline</span>

<span class="sd">    pipeline = DiffusionPipeline.from_pretrained(</span>
<span class="sd">        &quot;CompVis/stable-diffusion-v1-4&quot;,</span>
<span class="sd">        mindspore_dtype=mindspore.float16,</span>
<span class="sd">    )</span>
<span class="sd">    pipeline.unet.load_attn_procs(&quot;path-to-save-model&quot;, weight_name=&quot;lora_diffusion_weights.safetensors&quot;)</span>
<span class="sd">    pipeline.unet.save_attn_procs(&quot;path-to-save-model&quot;, weight_name=&quot;lora_diffusion_weights.safetensors&quot;)</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="kn">from</span> <span class="nn">..models.attention_processor</span> <span class="kn">import</span> <span class="n">CustomDiffusionAttnProcessor</span>

    <span class="k">if</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">save_directory</span><span class="p">):</span>
        <span class="n">logger</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Provided path (</span><span class="si">{</span><span class="n">save_directory</span><span class="si">}</span><span class="s2">) should be a directory, not a file&quot;</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="n">is_custom_diffusion</span> <span class="o">=</span> <span class="nb">any</span><span class="p">(</span>
        <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">CustomDiffusionAttnProcessor</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">attn_processors</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">is_custom_diffusion</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;is_custom_diffusion is not yet supported in </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">.save_attn_procs .&quot;</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">mindone.diffusers._peft.utils</span> <span class="kn">import</span> <span class="n">get_peft_model_state_dict</span>

        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">get_peft_model_state_dict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">save_function</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">safe_serialization</span><span class="p">:</span>
            <span class="n">save_function</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">save_file</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;format&quot;</span><span class="p">:</span> <span class="s2">&quot;np&quot;</span><span class="p">})</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">save_function</span> <span class="o">=</span> <span class="n">ms</span><span class="o">.</span><span class="n">save_checkpoint</span>

    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">weight_name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">safe_serialization</span><span class="p">:</span>
            <span class="n">weight_name</span> <span class="o">=</span> <span class="n">CUSTOM_DIFFUSION_WEIGHT_NAME_SAFE</span> <span class="k">if</span> <span class="n">is_custom_diffusion</span> <span class="k">else</span> <span class="n">LORA_WEIGHT_NAME_SAFE</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">weight_name</span> <span class="o">=</span> <span class="n">CUSTOM_DIFFUSION_WEIGHT_NAME</span> <span class="k">if</span> <span class="n">is_custom_diffusion</span> <span class="k">else</span> <span class="n">LORA_WEIGHT_NAME</span>

    <span class="c1"># Save the model</span>
    <span class="n">save_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">save_directory</span><span class="p">,</span> <span class="n">weight_name</span><span class="p">)</span><span class="o">.</span><span class="n">as_posix</span><span class="p">()</span>
    <span class="n">save_function</span><span class="p">(</span><span class="n">state_dict</span><span class="p">,</span> <span class="n">save_path</span><span class="p">)</span>
    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model weights saved in </span><span class="si">{</span><span class="n">save_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.set_adapters" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">mindone</span><span class="o">.</span><span class="n">diffusers</span><span class="o">.</span><span class="n">loaders</span><span class="o">.</span><span class="n">unet</span><span class="o">.</span><span class="n">UNet2DConditionLoadersMixin</span><span class="o">.</span><span class="n">set_adapters</span><span class="p">(</span><span class="n">adapter_names</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#mindone.diffusers.loaders.unet.UNet2DConditionLoadersMixin.set_adapters" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Set the currently active adapters for use in the UNet.</p>


<table>
      <thead>
        <tr>
          <th><span class="doc-section-title">PARAMETER</span></th>
          <th><span>DESCRIPTION</span></th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td><code>adapter_names</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The names of the adapters to use.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`List[str]` or `str`</code>
                  </span>
              </p>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td><code>weights</code></td>
            <td class="doc-param-details">
              <div class="doc-md-description">
                <p>The adapter(s) weights to use with the UNet. If <code>None</code>, the weights are set to <code>1.0</code> for all the
adapters.</p>
              </div>
              <p>
                  <span class="doc-param-annotation">
                    <b>TYPE:</b>
                      <code>`Union[List[float], float]`, *optional*</code>
                  </span>
                  <span class="doc-param-default">
                    <b>DEFAULT:</b>
                      <code>None</code>
                  </span>
              </p>
            </td>
          </tr>
      </tbody>
    </table>
        <div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">mindone.diffusers</span> <span class="kn">import</span> <span class="n">AutoPipelineForText2Image</span>
<span class="kn">import</span> <span class="nn">mindspore</span> <span class="k">as</span> <span class="nn">ms</span>

<span class="n">pipeline</span> <span class="o">=</span> <span class="n">AutoPipelineForText2Image</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
    <span class="s2">&quot;stabilityai/stable-diffusion-xl-base-1.0&quot;</span><span class="p">,</span> <span class="n">mindspore_dtype</span><span class="o">=</span><span class="n">ms</span><span class="o">.</span><span class="n">float16</span>
<span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">load_lora_weights</span><span class="p">(</span>
    <span class="s2">&quot;jbilcke-hf/sdxl-cinematic-1&quot;</span><span class="p">,</span> <span class="n">weight_name</span><span class="o">=</span><span class="s2">&quot;pytorch_lora_weights.safetensors&quot;</span><span class="p">,</span> <span class="n">adapter_name</span><span class="o">=</span><span class="s2">&quot;cinematic&quot;</span>
<span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">load_lora_weights</span><span class="p">(</span><span class="s2">&quot;nerijs/pixel-art-xl&quot;</span><span class="p">,</span> <span class="n">weight_name</span><span class="o">=</span><span class="s2">&quot;pixel-art-xl.safetensors&quot;</span><span class="p">,</span> <span class="n">adapter_name</span><span class="o">=</span><span class="s2">&quot;pixel&quot;</span><span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">set_adapters</span><span class="p">([</span><span class="s2">&quot;cinematic&quot;</span><span class="p">,</span> <span class="s2">&quot;pixel&quot;</span><span class="p">],</span> <span class="n">adapter_weights</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">])</span>
</code></pre></div>

            <details class="quote">
              <summary>Source code in <code>mindone/diffusers/loaders/unet.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span> <span class="nf">set_adapters</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">adapter_names</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="nb">str</span><span class="p">],</span>
    <span class="n">weights</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">Dict</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="kc">None</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set the currently active adapters for use in the UNet.</span>

<span class="sd">    Args:</span>
<span class="sd">        adapter_names (`List[str]` or `str`):</span>
<span class="sd">            The names of the adapters to use.</span>
<span class="sd">        weights (`Union[List[float], float]`, *optional*):</span>
<span class="sd">            The adapter(s) weights to use with the UNet. If `None`, the weights are set to `1.0` for all the</span>
<span class="sd">            adapters.</span>

<span class="sd">    Example:</span>

<span class="sd">    ```py</span>
<span class="sd">    from mindone.diffusers import AutoPipelineForText2Image</span>
<span class="sd">    import mindspore as ms</span>

<span class="sd">    pipeline = AutoPipelineForText2Image.from_pretrained(</span>
<span class="sd">        &quot;stabilityai/stable-diffusion-xl-base-1.0&quot;, mindspore_dtype=ms.float16</span>
<span class="sd">    )</span>
<span class="sd">    pipeline.load_lora_weights(</span>
<span class="sd">        &quot;jbilcke-hf/sdxl-cinematic-1&quot;, weight_name=&quot;pytorch_lora_weights.safetensors&quot;, adapter_name=&quot;cinematic&quot;</span>
<span class="sd">    )</span>
<span class="sd">    pipeline.load_lora_weights(&quot;nerijs/pixel-art-xl&quot;, weight_name=&quot;pixel-art-xl.safetensors&quot;, adapter_name=&quot;pixel&quot;)</span>
<span class="sd">    pipeline.set_adapters([&quot;cinematic&quot;, &quot;pixel&quot;], adapter_weights=[0.5, 0.5])</span>
<span class="sd">    ```</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">adapter_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">adapter_names</span><span class="p">]</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">adapter_names</span><span class="p">,</span> <span class="nb">str</span><span class="p">)</span> <span class="k">else</span> <span class="n">adapter_names</span>

    <span class="c1"># Expand weights into a list, one entry per adapter</span>
    <span class="c1"># examples for e.g. 2 adapters:  [{...}, 7] -&gt; [7,7] ; None -&gt; [None, None]</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">weights</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">adapter_names</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">adapter_names</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Length of adapter names </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">adapter_names</span><span class="p">)</span><span class="si">}</span><span class="s2"> is not equal to the length of their weights </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Set None values to default of 1.0</span>
    <span class="c1"># e.g. [{...}, 7] -&gt; [{...}, 7] ; [None, None] -&gt; [1.0, 1.0]</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="mf">1.0</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">weights</span><span class="p">]</span>

    <span class="c1"># e.g. [{...}, 7] -&gt; [{expanded dict...}, 7]</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">_maybe_expand_lora_scales</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>

    <span class="n">set_weights_and_activate_adapters</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">adapter_names</span><span class="p">,</span> <span class="n">weights</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 1, 2024</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Created">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">November 1, 2024</span>
  </span>

    
    
      
  
  <span class="md-source-file__fact">
    <span class="md-icon" title="Contributors">
      
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 4a4 4 0 0 1 4 4 4 4 0 0 1-4 4 4 4 0 0 1-4-4 4 4 0 0 1 4-4m0 10c4.42 0 8 1.79 8 4v2H4v-2c0-2.21 3.58-4 8-4"/></svg>
      
    </span>
    <nav>
      
        <a href="mailto:77485245+wcrzlh@users.noreply.github.com">Chaoran Wei</a>
    </nav>
  </span>

    
    
  </aside>





                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../textual_inversion/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Textual Inversion">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Textual Inversion
              </div>
            </div>
          </a>
        
        
          
          <a href="../../models/overview/" class="md-footer__link md-footer__link--next" aria-label="Next: Overview">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Overview
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2023 - 2024 MindSpore Lab
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
    <a href="mailto:mindspore-lab@huawei.com" target="_blank" rel="noopener" title="" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M498.1 5.6c10.1 7 15.4 19.1 13.5 31.2l-64 416c-1.5 9.7-7.4 18.2-16 23s-18.9 5.4-28 1.6L284 427.7l-68.5 74.1c-8.9 9.7-22.9 12.9-35.2 8.1S160 493.2 160 480v-83.6c0-4 1.5-7.8 4.2-10.8l167.6-182.8c5.8-6.3 5.6-16-.4-22s-15.7-6.4-22-.7L106 360.8l-88.3-44.2C7.1 311.3.3 300.7 0 288.9s5.9-22.8 16.1-28.7l448-256c10.7-6.1 23.9-5.5 34 1.4"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://github.com/mindspore-lab/mindone" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.zhihu.com/people/mindsporelab" target="_blank" rel="noopener" title="www.zhihu.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.6.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M170.54 148.13v217.54l23.43.01 7.71 26.37 42.01-26.37h49.53V148.13zm97.75 193.93h-27.94l-27.9 17.51-5.08-17.47-11.9-.04V171.75h72.82zm-118.46-94.39H97.5c1.74-27.1 2.2-51.59 2.2-73.46h51.16s1.97-22.56-8.58-22.31h-88.5c3.49-13.12 7.87-26.66 13.12-40.67 0 0-24.07 0-32.27 21.57-3.39 8.9-13.21 43.14-30.7 78.12 5.89-.64 25.37-1.18 36.84-22.21 2.11-5.89 2.51-6.66 5.14-14.53h28.87c0 10.5-1.2 66.88-1.68 73.44H20.83c-11.74 0-15.56 23.62-15.56 23.62h65.58C66.45 321.1 42.83 363.12 0 396.34c20.49 5.85 40.91-.93 51-9.9 0 0 22.98-20.9 35.59-69.25l53.96 64.94s7.91-26.89-1.24-39.99c-7.58-8.92-28.06-33.06-36.79-41.81L87.9 311.95c4.36-13.98 6.99-27.55 7.87-40.67h61.65s-.09-23.62-7.59-23.62zm412.02-1.6c20.83-25.64 44.98-58.57 44.98-58.57s-18.65-14.8-27.38-4.06c-6 8.15-36.83 48.2-36.83 48.2zm-150.09-59.09c-9.01-8.25-25.91 2.13-25.91 2.13s39.52 55.04 41.12 57.45l19.46-13.73s-25.67-37.61-34.66-45.86h-.01zM640 258.35c-19.78 0-130.91.93-131.06.93v-101c4.81 0 12.42-.4 22.85-1.2 40.88-2.41 70.13-4 87.77-4.81 0 0 12.22-27.19-.59-33.44-3.07-1.18-23.17 4.58-23.17 4.58s-165.22 16.49-232.36 18.05c1.6 8.82 7.62 17.08 15.78 19.55 13.31 3.48 22.69 1.7 49.15.89 24.83-1.6 43.68-2.43 56.51-2.43v99.81H351.41s2.82 22.31 25.51 22.85h107.94v70.92c0 13.97-11.19 21.99-24.48 21.12-14.08.11-26.08-1.15-41.69-1.81 1.99 3.97 6.33 14.39 19.31 21.84 9.88 4.81 16.17 6.57 26.02 6.57 29.56 0 45.67-17.28 44.89-45.31v-73.32h122.36c9.68 0 8.7-23.78 8.7-23.78z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tracking", "navigation.tabs", "navigation.sections", "navigation.top", "navigation.footer", "toc.follow", "search.highlight", "search.share", "search.suggest", "content.action.view", "content.action.edit", "content.tabs.link", "content.code.copy", "content.code.select", "content.code.annotations"], "search": "../../../../assets/javascripts/workers/search.6ce7567c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.83f73b43.min.js"></script>
      
    
  </body>
</html>