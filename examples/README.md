Here we provide various examples for image/video/audio generation models built on MindSpore.

<details open markdown>
<summary> Image Generation </summary>

- [x] [Stable Diffusion](stable_diffusion_v2/README.md) #rich pipelines
- [x] [SDXL](stable_diffusion_xl/README.md)  ðŸ”¥
- [x] [Diffsuion Transformer (DiT)](dit/README.md)
- [x] [Flexible Diffusion Transformer (FiT)](fit/README.md)
- [x] [t2i-adapter](t2i_adapter/README.md) #Controllable
- [x] [ip-adapter](ip_adapter/README.md) #Controllable
- [x] [Pangu Draw v3](pangu_draw_v3/README.md) #Chinese

</details>


<details open markdown>
<summary> Video Generation </summary>

- [x] [AnimateDiff](animatediff/README.md)
- [x] [Stable Video Diffusion](svd/README.md)
- [x] [Video Diffusion Transformer (Latte)](latte/README.md) ðŸ”¥
- [x] [VideoComposer](videocomposer/README.md)
- [x] [Tune-A-Video](tuneavideo/README.md)
- [x] [Text2Video Zero](text2video_zero/README.md)

</details>


<details open markdown>
<summary> Audio Generation </summary>

- [x] [Tango](tango/README.md)

</details>


<details open markdown>
<summary> Sora-like Projects</summary>

- [ ] [PKU Open-Sora-Plan](opensora_pku/README.md)  (coming soon)
- [x] [hpcaitech Open-Sora](opensora_hpcai/README.md)

</details>
