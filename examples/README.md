### multi-modal understanding and generation model examples supported by mindone

| lib  |  hf version | original repo
| :---   |  :--  | :-
| [mindone.diffusers](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/diffusers) | support v0.35| https://github.com/huggingface/diffusers |
| [mindone.transformers](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/transformers) | support v4.50| https://github.com/huggingface/transformers |

| model   |  codebase style | original repo
| :---   |  :--  | :--: |
| [cogview](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/diffusers/cogview) | THUDM official | https://github.com/THUDM/CogView4 |
| [cogvideox](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/diffusers/cogvideox_factory) | THUDM official | https://github.com/THUDM/CogVideo |
| [flux](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/diffusers/dreambooth) | Black Forest Labs official | https://github.com/black-forest-labs/flux |
| [wan2_1](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/wan2_1) | Alibaba Wan Group official|  https://github.com/Wan-Video/Wan2.1 |
| [step_video_t2v](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/step_video_t2v) | StepFun official | https://github.com/stepfun-ai/Step-Video-T2V   |
| [janus](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/janus) | DeepSeek AI official | https://github.com/deepseek-ai/Janus |
| [emu3](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/emu3) | BAAIVision official | https://github.com/baaivision/Emu3 |
| [var](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/var) | ByteDance FoundationVision official | https://github.com/FoundationVision/VAR |
| [hpcai open sora](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/opensora_hpcai)      | HPC-AI Tech official | https://github.com/hpcaitech/Open-Sora
| [open sora plan](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/opensora_pku)      | PKU-YuanGroup official | https://github.com/PKU-YuanGroup/Open-Sora-Plan
| [movie gen](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/moviegen)     | implemented by MindONE team, based on the MovieGen paper by Meta | https://arxiv.org/pdf/2310.05737  |
| [hunyuanvideo](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/hunyuanvideo) | HunyuanVideo official | https://github.com/Tencent/HunyuanVideo |
| [hunyuanvideo-i2v](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/hunyuanvideo-i2v) | Tencent official  | https://github.com/Tencent/HunyuanVideo-I2V  |
| [canny_edit](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/canny_edit) | implemented by MindONE team | https://github.com/VayneXie/CannyEdit |
| [lang_sam](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/lang_sam) | implemented by MindONE team | https://github.com/luca-medeiros/lang-segment-anything |
| [mmada](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/mmada) | Gen-Verse official | https://github.com/Gen-Verse/MMaDA |
| [omnigen](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/omnigen) | VectorVision official | https://github.com/VectorSpaceLab/OmniGen |
| [omnigen2](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/omnigen2) | VectorVision official | https://github.com/VectorSpaceLab/OmniGen |
| [sam2](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/sam2) | Meta official | https://github.com/facebookresearch/sam2 |
| [sparktts](https://github.com/mindspore-lab/mindone/blob/v0.4.0/examples/sparktts) | SparkAudio official | https://github.com/SparkAudio/Spark-TTS |
