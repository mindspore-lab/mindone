experiment:
    type: lrm
    parent: lrm-objaverse
    child: small

model:
    camera_embed_dim: 1024
    rendering_samples_per_ray: 96
    transformer_dim: 512
    transformer_layers: 12
    transformer_heads: 8
    triplane_low_res: 32
    triplane_high_res: 64
    triplane_dim: 32
    encoder_type: dinov2
    encoder_model_name: dinov2_vits14_reg
    encoder_feat_dim: 384
    encoder_freeze: false

dataset:
    subsets:
        -   name: objaverse
            root_dirs:
                - <REPLACE_WITH_RENDERING_ROOT e.g. datasets/openlrm_224x224>
            meta_path:
                train: <TRAIN_UIDS_IN_JSON e.g. datasets/openlrm_224x224/meta_train.json>
                val: <VAL_UIDS_IN_JSON e.g. datasets/openlrm_224x224/meta_val.json>
            sample_rate: 1.0
    sample_side_views: 3
    source_image_res: 224
    render_image:
        low: 64
        high: 192
        region: 64 # transformer_dim/8
    normalize_camera: true
    normed_dist_to_center: auto
    num_train_workers: 8
    num_val_workers: 2
    pin_mem: true

train:
    find_unused_parameters: false
    loss:
        pixel_weight: 1.0
        perceptual_weight: 1.0
        tv_weight: 5e-4
    batch_size: 1

val:
    batch_size: 1
    global_step_period: 1000
    debug_batches: null
