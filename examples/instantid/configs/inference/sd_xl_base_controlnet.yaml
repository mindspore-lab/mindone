base: ../stable_diffusion_xl/configs/inference/sd_xl_base_controlnet.yaml
model:
  params:
    conditioner_config:
      params:
        emb_models:
          # crossattn cond
          - is_trainable: False
            input_key: txt
            target: gm.modules.embedders.modules.FrozenCLIPEmbedder
            params:
              layer: hidden
              layer_idx: 11
              version: openai/clip-vit-large-patch14
          # crossattn and vector cond
          - is_trainable: False
            input_key: txt
            target: gm.modules.embedders.modules.FrozenOpenCLIPEmbedder2
            params:
              arch: ViT-bigG-14-Text
              freeze: True
              layer: penultimate
              always_return_pooled: True
              legacy: False
              require_pretrained: False
          # crossattn cond
          - is_trainable: False
            input_key: clip_img
            target: instantid.common.modules.embedders.modules.InstantIDImageEmbedder
            params:
              freeze: True
              dim: 1280
              depth: 4
              dim_head: 64
              heads: 20
              num_tokens: 16
              image_emb_dim: 512
              unet_cross_attention_dim: 2048
              ff_mult: 4
          # vector cond
          - is_trainable: False
            input_key: original_size_as_tuple
            target: gm.modules.embedders.modules.ConcatTimestepEmbedderND
            params:
              outdim: 256  # multiplied by two
          # vector cond
          - is_trainable: False
            input_key: crop_coords_top_left
            target: gm.modules.embedders.modules.ConcatTimestepEmbedderND
            params:
              outdim: 256  # multiplied by two
          # vector cond
          - is_trainable: False
            input_key: target_size_as_tuple
            target: gm.modules.embedders.modules.ConcatTimestepEmbedderND
            params:
              outdim: 256  # multiplied by two

    network_config:
      target: adapter.controlnet.sdxl_unet.IPAdapterControlNetUnetModel
      params:
        ip_scale: 0.8
        num_tokens: 4
        spatial_transformer_attn_type: vanilla
        strength: 0.8
        context_length: 77
        context_mode: image
