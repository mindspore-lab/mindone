environment:
  mode: 0
  seed: 42
  distributed: False

train:
  epochs: 1000
  temporal_only: True     # train only the temporal layers or the entire UNet
  pretrained: PATH/TO/PRETRAINEDCKPT/svd-d19a808f_embkeychanged_asinsv3d.ckpt  # as in the sv3d paper, finetuning from svd
  output_dir: ./outputs/
  save_interval: 10      # in epochs
  log_interval: 10        # in steps, same as the dataset size (in scenes/steps)
  amp_level: O2
  ckpt_max_keep: 1

  model:
    loss_fn_config:
      target: sgm.modules.diffusionmodules.loss.StandardDiffusionLoss

    sigma_sampler_config:
      target: sgm.modules.diffusionmodules.sigma_sampling.EDMSampling
      params:
        p_mean: 1.0
        p_std: 1.6

  dataset:
    class_path: data.mulvideo_dataset.MulviewVideoDataset
    init_args:
      root_dir: itmh_training_data_9  # for overfitting exp
      metadata: uid_set.pkl
      image_dir: target               # for overfitting w/o pose
      frames: 5                       # to accomodate training with obj-rendering dataset

  dataloader:
    batch_size: 1
    num_workers: 4
    shuffle: False
    drop_remainder: True

  scheduler:
    name: cosine_decay
    lr: 3.0e-5
    end_lr: 1.0e-7
    warmup_steps: 50

  optimizer:
    name: adamw
    betas: [ 0.9, 0.98 ]
    weight_decay: 0.01

  settings:
    drop_overflow_update: True
    gradient_accumulation_steps: 5
    clip_grad: True
    clip_norm: 1.0

LossScale:
  loss_scale_value: 65536
  scale_factor: 2
  scale_window: 1000
