# task
condition: "text"
output_path: outputs/text_ft_video_dit

# model setting
image_size: 256
num_frames: 16
model_name: "DiT-XL/2"
dit_checkpoint: "models/DiT-XL-2-256x256.ckpt"
vae_checkpoint: "models/sd-vae-ft-mse.ckpt"
clip_checkpoint: "../stable_diffusion_v2/models/sd_v1.5-d0ab7146.ckpt"  # sd ckpt to only load text encoder
sd_scale_factor: 0.18215
enable_flash_attention: False
use_fp16: True

# data setting
data_path: imagenet_samples/images/

dataset_sink_mode: True

# training hyper-params
start_learning_rate: 1e-4
scheduler: "constant"
warmup_steps: 10
train_batch_size: 1
gradient_accumulation_steps: 2
weight_decay: 0.01
epochs: 5000

use_ema: False
clip_grad: True
ckpt_max_keep: 3
init_loss_scale: 65536

betas: [0.9, 0.999]
optim_eps: 1.e-6

# training process
log_interval: 1
ckpt_save_interval: 1000  # save ckpt every n epochs
step_mode: False
