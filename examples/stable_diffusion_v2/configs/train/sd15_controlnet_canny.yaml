# system
mode: 0
use_parallel: False
num_workers: 1

# dataset
data_path: "/path/to/data"
train_batch_size: 2
gradient_accumulation_steps: 1 # todo: diff
image_size: 512
image_filter_size: 200

# model
model_config: "configs/v1-train-cldm.yaml"
pretrained_model_path: "/path/to/pretrained_model"
output_path: "/path/to/save/output_data"
ckpt_save_interval: 2
epochs: 14
use_ema: True
clip_grad: False
use_recompute: False

# lr scheduler
scheduler: "constant"
start_learning_rate: 5.e-4
end_learning_rate: 5.e-4
warmup_steps: 0
decay_steps: 0

# optimizer
optim: "adamw"
betas: [0.9, 0.98]
weight_decay: 1.e-2
