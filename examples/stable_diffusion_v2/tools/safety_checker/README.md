### Safety Checker

To validate the safeness of images generated by a model, we implement two safety checkers with interface `eval/{eval_safety, eval_safety_laion}.py`.

`eval_safety.py` applies CLIP to compute the similarity between the given images and a hard-coded list of NSFW concepts. This is consistent with the one used in CompVis's stable diffusion 1.x from `diffusers` implementation. The output is a list of similarity scores, each corresponding to a concept.

`eval_safety_laion.py` trains a NSFW classifier with a supervisied approach, taking image features from CLIP as its input. This is consistent with the one used in StabilityAI's stable diffusion 2.x. The output is a number in 0-1, representing the probability of the generated image being NSFW.

- MindSpore backend
```
python eval/eval_safety.py --load_checkpoint <path-to-model> --image_path_or_dir <path-to-image>
python eval/eval_safety_laion.py --load_checkpoint <path-to-model> --image_path_or_dir <path-to-image>
```
- PyTorch backend
```
python eval/eval_safety.py --backend pt --image_path_or_dir <path-to-image>
python eval/eval_safety_laion.py --backend pt --image_path_or_dir <path-to-image>
```
By default, we use MindSpore backend for CLIP score computing. You may swich to use `torch` and `transformers` by setting `--backend=pt`. The computational difference between these two backends is usually lower than 0.1%, which is neglectable.

For more usage, please run `python eval/eval_clip_score.py -h`.

You need to download the checkpoint file for a CLIP model of your choice. Download links for some models are provided below.

- [clip_vit_b_16](https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/MindFormers/clip/clip_vit_b_16.ckpt)
- [clip_vit_b_32](https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/XFormer_for_mindspore/clip/clip_vit_b_32.ckpt)
- [clip_vit_l_14](https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/MindFormers/clip/clip_vit_l_14.ckpt) (Default)

For other compatible models, e.g., OpenCLIP, you can download `pytorch_model.bin` from HuggingFace (HF) and then convert to `.ckpt` using `eval/clip_score/utils/convert_weight.py`. When using a model other than the default, you should supply the path to your model's config file. Some useful examples are provided in `ldm/models/clip/configs`.

In addition, you should download the default tokenizer file bpe_simple_vocab_16e6.txt.gz [here](https://ascend-repo-modelzoo.obs.cn-east-2.myhuaweicloud.com/XFormer_for_mindspore/clip/bpe_simple_vocab_16e6.txt.gz), and place it in the directory where you run the program or set `tokenizer_path` accordingly.

`image_path_or_dir` should lead to an image file or a directory containing images. If it is a directory, then the images are sorted by their filename in an ascending order.

## Reference

[1] https://github.com/huggingface/diffusers/blob/main/src/diffusers/pipelines/stable_diffusion/safety_checker.py

[2] https://github.com/LAION-AI/CLIP-based-NSFW-Detector
