# task
image_finetune: False
output_path: outputs/mmv2_finetune

# model
model_config: configs/stable_diffusion/v1-train-mmv2.yaml
pretrained_model_path: models/stable_diffusion/sd_v1.5-d0ab7146.ckpt
motion_module_path: models/motion_module/mm_sd_v15_v2.ckpt
unet_initialize_random: False
force_motion_module_amp_O2: True

# data
data_path: ../videocomposer/datasets/webvid5
image_size: 512     # 256 used in paper
num_frames: 16
frame_stride: 4

# training hyper-params
start_learning_rate: 1.e-4
scheduler: constant
warmup_steps: 10
train_batch_size: 1
weight_decay: 0.01
init_loss_scale: 65536
use_ema: False
clip_grad: True
snr_gamma: 5.0
vae_fp16: True  # NOTE: set False to make vae compute in fp32, which may yield better results.

# acc
enable_flash_attention: False  # NOTE: set True for ms2.3 and disable recompute below for higher throughput
use_recompute: True
recompute_strategy: "down_mm_half"

num_parallel_workers: 12
dataset_sink_mode: True
sink_size: 100

# duration
epochs: -1
train_steps: 50000
ckpt_save_steps: 5000
ckpt_max_keep: 10
save_mm_only: True
