env:
  mode: 0
  jit_level: O1
  seed: 42
  distributed: False
  debug: False

model:
  name: "HYVideo-T/2-cfgdistill"
  in_channels: 16
  pretrained_model_path: /ckpt/path/from/stage1
  text_states_dim: 4096
  text_states_dim_2: 768
  enable_ms_amp: False
  amp_level: O2
  factor_kwargs:
    dtype: bf16
    use_conv2d_patchify: True
    attn_mode: flash
    use_recompute: True
    num_no_recompute: 0

vae:
  type: "884-16c-hy"
  precision: fp16
  tiling: True
  trainable: False

dataset:
  csv_path: CSV_PATH
  video_folder: VIDEO_FOLDER
  text_emb_folder: TEXT_EMB_FOLDER
  empty_text_emb: EMPTY_TEXT_EMB_PATH
  deterministic_sample: False
  text_drop_prob: 0.2
  target_size: [ 512, 512 ]
  sample_n_frames: 79
  vae_scale_factor: 0.476986  # must be the same to vae scaling_factor
  vae_latent_folder: datasets/mixkit-100videos/mixkit_latent_512x512/
  output_columns: [ "video", "prompt_embeds", "prompt_mask", "prompt_embeds_2", "freqs_cos", "freqs_sin" ]

dataloader:
  batch_size: 1
  shuffle: True
  num_workers_dataset: 4

train:
  steps: 30000
  output_path: ../../output/stage2_t2v_512px  # the path is relative to this config
  data_sink_mode: True
  data_sink_size: -1 # sink size same to dataset size

  sequence_parallel:
    shards: 8

  lr_scheduler:
    name: constant
    lr: 5.0e-5
    warmup_steps: 1000

  lr_reduce_on_plateau:
    factor: 0.5
    patience: 50  # in the number of validation steps, i.e., valid.frequency * patience steps
    mode: min
    min_delta: 0.01
    min_lr: 1.0e-6

  optimizer:
    name: adamw_bf16
    eps: 1e-15
    betas: [ 0.9, 0.999 ]
    weight_decay: 0.0001

  loss_scaler:
    class_path: mindspore.nn.DynamicLossScaleUpdateCell   # or DynamicLossScaleUpdateCell in FP16
    init_args:
      loss_scale_value: 65536
      scale_factor: 2
      scale_window: 1000
  settings:
    zero_stage: 0
    gradient_accumulation_steps: 1
    clip_grad: True
    clip_norm: 1.0

  save:
    ckpt_save_policy: latest_k
    monitor_metric: "eval_loss_smoothed"
    ckpt_save_interval: &save_interval 1000
    ckpt_max_keep: 10
    log_interval: 1 # with respect to steps
    save_ema_only: False
    record_lr: False

valid:
  sampling_steps: 10
  frequency: *save_interval  # train.save.ckpt_save_interval should be divisible by the frequency

  dataset:
    csv_path: CSV_PATH
    video_folder: VIDEO_FOLDER
    text_emb_folder: TEXT_EMB_FOLDER
    target_size: [ 512, 512 ]
    sample_n_frames: 79
    vae_scale_factor: 0.476986  # must be the same to vae scaling_factor
    vae_latent_folder: datasets/mixkit-100videos/mixkit_latent_512x512/
    output_columns:  [ "video", "prompt_embeds", "prompt_mask", "prompt_embeds_2", "freqs_cos", "freqs_sin"]

  dataloader:
    batch_size: 1
    shuffle: False
    num_workers_dataset: 4
