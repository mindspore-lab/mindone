env:
  mode: 0
  jit_level: O1
  max_device_memory: 59GB
  seed: 42
  distributed: False
  debug: False

model:
  from_pretrained:
  guidance_embed: False
  fused_qkv: False
  use_liger_rope: True
  # model architecture
  in_channels: 64
  vec_in_dim: 768
  context_in_dim: 4096
  hidden_size: 3072
  mlp_ratio: 4.0
  num_heads: 24
  depth: 19
  depth_single_blocks: 38
  axes_dim: [ 16, 56, 56 ]
  theta: 10_000
  qkv_bias: True
  cond_embed: False
  recompute_every_nth_block: 1
  dtype: bf16

ae: ../ae/hunyuan_vae.yaml

dataset:
  v2_pipeline: True
  target_size: [ 256, 256 ]
  sample_n_frames: 5
  csv_path: CSV_PATH
  video_folder: VIDEO_FOLDER
  text_emb_folder:
    t5: UL2_FOLDER
    clip: BYT5_FOLDER
  empty_text_emb:
    t5: EMPTY_TEXT_EMB
    clip: EMPTY_TEXT_EMB
  text_drop_prob:
    t5: 0.31622777
    clip: 0.31622777
  vae_scale_factor: 0.476986
  vae_shift_factor: 0
  max_fps: 24
  apply_transforms_dataset: True
  output_columns: [ "video", "video_ids", "t5_caption", "txt_ids", "clip_caption", "shift_alpha" ]

dataloader:
  batch_size: 1
  shuffle: True
  num_workers_dataset: 4

train:
  pipeline:
    is_causal_vae: True

  sequence_parallel:
    shards: 8   # 1 == no SP

  options:
    steps: 20000

  lr_scheduler:
    name: constant
    lr: 5e-5
    warmup_steps: 0

  optimizer:
    name: adamw_bf16
    eps: 1e-15
    betas: [ 0.9, 0.999 ]
    weight_decay: 0

  loss_scaler:
    class_path: mindspore.nn.FixedLossScaleUpdateCell   # or DynamicLossScaleUpdateCell in FP16
    init_args:
      loss_scale_value: 1

  settings:
    zero_stage: 3
    gradient_accumulation_steps: 1
    clip_grad: True
    clip_norm: 1.0

  save:
    ckpt_save_policy: latest_k
    ckpt_save_interval: 500
    ckpt_max_keep: 10
    log_interval: 1
    save_ema_only: False
    record_lr: False
    ckpt_combine_online: False

save:
  output_path: ../../../output/stage2  # the path is relative to this config
